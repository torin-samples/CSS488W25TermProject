{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSspY0-eIY0Y"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdrRoOe6IY0Z"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiSdfWrrIY0Z"
      },
      "source": [
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNaUdKK4IY0Z"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KI52CJ6IY0Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_vF1wpWIY0Z"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "cf29d39d59a4430b8a3ad3de755d3832",
            "8062b8d1476d4a39ab13b3009ecd6833",
            "90acea9536ee42838c96baf01325c897",
            "b77cd302f8a94c868552f7bba6b451a1",
            "1aeb004472244f94b143c96479ae5ce1",
            "d441c7dda3b24431bebe91a35e64f472",
            "49faf8d3c6e746149b34394ab04dee0f",
            "7290d71f006a4d158b8bdb90f108a60f",
            "4c838f802b2849d0806e6d246c10286a",
            "46a64c011d004602a404958cb851ff46",
            "bd6b5e7430cc4a3a98df5271c2b64214",
            "20b63870f1384f8cbd0fd0d8efcb5c56",
            "94dace842a48465cab27b97fdb571464",
            "dc28cd96454b4aab863ab1136d65d5a5",
            "03fb9538965b4ce0988642387b7482cc",
            "90833d29f5464d8a92ec643314adaa4f",
            "fb24c391d82d404ab44c4c51d4e30f5e",
            "203ec114306f40168efd3ea7fe64db6e",
            "fc9e643fef394678b2b27b710be02c77",
            "e9fbdf519a814f19a6a9e4ecbbe8f53e",
            "0a1517dc939349e9bf1b584053dec892",
            "13784d6215a44125b56cbf74e349267f",
            "212eacf56b4c4deea80fa408f3d02fba",
            "7f8f80e00e9b4e9ebcc3155db47894cf",
            "51618322c6d64d6984e11332d089c73a",
            "65a0f52c9b7a4ba49800cf3758cad2bb",
            "347a88e9470e40d4b503d35e9b7a2376",
            "3a7f946133cd4e7b8180c84b036309d1",
            "a26572a2dd5043c6a014bb79a0e6b016",
            "bb33ff925f924256a6c04987a1106e53",
            "d55c65d67a654960a2c74d172847e1f1",
            "dee8c56007ad489690cb8c4d2cf43520",
            "6194b58307b64760b800a0711d286ed1",
            "5ea467cdf1554a2e825e68fc0ae579ee",
            "c6ec20ed70614a60a97ecafd954ac40f",
            "d2295836be21437f9f69415b72cd6271",
            "e67e56ed4a664e50b4ccb852bd82ebc0",
            "310acca300534061bf84cd22bd553c30",
            "99c36f5026c9420dbd9f339a1b6bc408",
            "bf6db4c854904b1dacf14d1905a119e7",
            "981b9d8d38574fcebba818614502b167",
            "4c149b4e05b145a6a81777e8d1e6b69e",
            "fa145cdea2b54a28ba904bce60e7169d",
            "9ce0844500fd4bd5a9e0865c2d6ba1d4",
            "df2685904b87490b95f28db3984a3402",
            "c06e0affb3284acbad401609bf2e2592",
            "9da6621d86054745af71b1244cbe7b20",
            "336a29c71ffd4b7cac8138db2b9157cc",
            "4213358bef594c5cbcabd6f9a14449eb",
            "421e64d5d9b9443e9cc8b05f15f59e83",
            "124e8ef0aaa641e9b92fddd18877aba5",
            "bf41923583b64a2094b23d433766a2d4",
            "f159bda1256a4731a39604c586291995",
            "51ba0f377b674b17aa3f2be183b73f57",
            "6a3dee5403e04add8bbbee0e193a1570"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "a0953cae-c5f7-4e1a-a139-fcce39e71762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.5.9: Fast Llama patching. Transformers: 4.52.2.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf29d39d59a4430b8a3ad3de755d3832"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20b63870f1384f8cbd0fd0d8efcb5c56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "212eacf56b4c4deea80fa408f3d02fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ea467cdf1554a2e825e68fc0ae579ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df2685904b87490b95f28db3984a3402"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "7fd1ad74-3e92-4775-ecb7-f7d09a5674a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Alpaca.ipynb)\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIf-iwktIsUV",
        "outputId": "544013a4-3884-4e1e-fa51-a347a8eab3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu5vHY4pLtKa"
      },
      "source": [
        "### Check our Pickle Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfSWViMIIrVD",
        "outputId": "31da230c-e057-4245-fc04-2a83b7b35620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 pickle files:\n",
            "--------------------------------------------------\n",
            "\n",
            "1. File: Reddit_entertainment_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (5384, 8)\n",
            "Columns (8):\n",
            "  - post_title\n",
            "  - post_body\n",
            "  - url\n",
            "  - top_5_comments\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - num_comments\n",
            "\n",
            "Data types:\n",
            "post_title        object\n",
            "post_body         object\n",
            "url               object\n",
            "top_5_comments    object\n",
            "subreddit         object\n",
            "category          object\n",
            "score              int64\n",
            "num_comments       int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                          post_title post_body  \\\n",
            "0  David Geffen's Estranged Husband, 32, Requests...             \n",
            "1  Bono Cheekily Weighs in On Springsteen Vs. Tru...             \n",
            "2  Jimmy Kimmel on Trump: ‚ÄòCelebrated the first t...             \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://people.com/david-geffen-estranged-husb...   \n",
            "1  https://www.billboard.com/music/rock/bono-talk...   \n",
            "2  https://www.theguardian.com/culture/2025/may/2...   \n",
            "\n",
            "                                      top_5_comments        subreddit  \\\n",
            "0  [Damn üòî if they can‚Äôt make it, who can?, What ...  r/entertainment   \n",
            "1  [> For the record, Bono said he has never endo...  r/entertainment   \n",
            "2  [Nothing gets past you, Lol, trump puts the ‚ÄúM...  r/entertainment   \n",
            "\n",
            "        category  score  num_comments  \n",
            "0  Entertainment   1287           120  \n",
            "1  Entertainment   2928            58  \n",
            "2  Entertainment   1144            28  \n",
            "----------------------------------------\n",
            "\n",
            "2. File: Reddit_travel_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (4616, 8)\n",
            "Columns (8):\n",
            "  - post_title\n",
            "  - post_body\n",
            "  - url\n",
            "  - top_5_comments\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - num_comments\n",
            "\n",
            "Data types:\n",
            "post_title        object\n",
            "post_body         object\n",
            "url               object\n",
            "top_5_comments    object\n",
            "subreddit         object\n",
            "category          object\n",
            "score              int64\n",
            "num_comments       int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                          post_title  \\\n",
            "0                             NYC Subway for Tourist   \n",
            "1               First time traveling! I need clarity   \n",
            "2  travel advice - where in Europe to visit in Au...   \n",
            "\n",
            "                                           post_body  \\\n",
            "0  My wife and I are travelling to NYC soon. We'v...   \n",
            "1  Hello! I'm traveling for the very first time w...   \n",
            "2  Hello everyone,\\n\\nI am hoping to get some adv...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.reddit.com/r/traveladvice/comments...   \n",
            "1  https://www.reddit.com/r/traveladvice/comments...   \n",
            "2  https://www.reddit.com/r/traveladvice/comments...   \n",
            "\n",
            "                                      top_5_comments       subreddit category  \\\n",
            "0                                         [, , , , ]  r/traveladvice   Travel   \n",
            "1  [Hotel will charge you at the time of checkin,...  r/traveladvice   Travel   \n",
            "2  [You can go for Eastern Europe (Vienna-Prague-...  r/traveladvice   Travel   \n",
            "\n",
            "   score  num_comments  \n",
            "0      1             0  \n",
            "1      1             2  \n",
            "2      1             1  \n",
            "----------------------------------------\n",
            "\n",
            "3. File: Reddit_comedy_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (4986, 8)\n",
            "Columns (8):\n",
            "  - post_title\n",
            "  - post_body\n",
            "  - url\n",
            "  - top_5_comments\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - num_comments\n",
            "\n",
            "Data types:\n",
            "post_title        object\n",
            "post_body         object\n",
            "url               object\n",
            "top_5_comments    object\n",
            "subreddit         object\n",
            "category          object\n",
            "score              int64\n",
            "num_comments       int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                          post_title  \\\n",
            "0  I feel like the quality of pornography has dec...   \n",
            "1  An American, a Mexican, and a Brit walk into a...   \n",
            "2  A blonde walks into a pharmacy and asks for bo...   \n",
            "\n",
            "                                           post_body  \\\n",
            "0                        It all seems so amateur now   \n",
            "1  The Mexican says \"I will have a Corona, the fi...   \n",
            "2  The assistant, a little bemused, explains to t...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.reddit.com/r/Jokes/comments/1kx0rk...   \n",
            "1  https://www.reddit.com/r/Jokes/comments/1kwlsq...   \n",
            "2  https://www.reddit.com/r/Jokes/comments/1kwlrg...   \n",
            "\n",
            "                                      top_5_comments subreddit category  \\\n",
            "0  [I hear you.  Sometimes I just sit there shaki...   r/Jokes   Comedy   \n",
            "1  [*A favorite beer joke:*\\n\\n Woman: Do you dri...   r/Jokes   Comedy   \n",
            "2  [Me:. Can you help me find deodorant? \\nPharma...   r/Jokes   Comedy   \n",
            "\n",
            "   score  num_comments  \n",
            "0    511            23  \n",
            "1   2827           220  \n",
            "2   1019            53  \n",
            "----------------------------------------\n",
            "\n",
            "4. File: Reddit_education_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (4714, 8)\n",
            "Columns (8):\n",
            "  - post_title\n",
            "  - post_body\n",
            "  - url\n",
            "  - top_5_comments\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - num_comments\n",
            "\n",
            "Data types:\n",
            "post_title        object\n",
            "post_body         object\n",
            "url               object\n",
            "top_5_comments    object\n",
            "subreddit         object\n",
            "category          object\n",
            "score              int64\n",
            "num_comments       int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                          post_title  \\\n",
            "0  Careers in the education field that aren‚Äôt nec...   \n",
            "1                  AP English Gamification Schematic   \n",
            "2  What books surprised you and expanded your kno...   \n",
            "\n",
            "                                           post_body  \\\n",
            "0  I‚Äôve taken into consideration the education fi...   \n",
            "1  (This post and unit were written without gener...   \n",
            "2  What‚Äôs a book that unexpectedly expanded your ...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.reddit.com/r/education/comments/1k...   \n",
            "1  https://www.reddit.com/r/education/comments/1k...   \n",
            "2  https://www.reddit.com/r/education/comments/1k...   \n",
            "\n",
            "                                      top_5_comments    subreddit   category  \\\n",
            "0  [Social worker, counselor, psychologist, physi...  r/education  education   \n",
            "1                                         [, , , , ]  r/education  education   \n",
            "2  [I have several books I‚Äôve read that have been...  r/education  education   \n",
            "\n",
            "   score  num_comments  \n",
            "0     16            47  \n",
            "1      2             0  \n",
            "2      5             6  \n",
            "----------------------------------------\n",
            "\n",
            "5. File: Reddit_professional_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (11902, 8)\n",
            "Columns (8):\n",
            "  - post_title\n",
            "  - post_body\n",
            "  - url\n",
            "  - top_5_comments\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - num_comments\n",
            "\n",
            "Data types:\n",
            "post_title        object\n",
            "post_body         object\n",
            "url               object\n",
            "top_5_comments    object\n",
            "subreddit         object\n",
            "category          object\n",
            "score              int64\n",
            "num_comments       int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                          post_title  \\\n",
            "0  How do I professionally say \"I'll follow the r...   \n",
            "1  28 with a useless degree and muddled work history   \n",
            "2  I just realized that I wasted many opportuniti...   \n",
            "\n",
            "                                           post_body  \\\n",
            "0  This is a bit complicated. I started a new job...   \n",
            "1  I‚Äôm 28 years old and have a social work degree...   \n",
            "2  For the past months looking for a job I had a ...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.reddit.com/r/careeradvice/comments...   \n",
            "1  https://www.reddit.com/r/careeradvice/comments...   \n",
            "2  https://www.reddit.com/r/careeradvice/comments...   \n",
            "\n",
            "                                      top_5_comments       subreddit  \\\n",
            "0  [‚ÄúI‚Äôm committed to adhering to the established...  r/CareerAdvice   \n",
            "1  [Daughter-In-Law has a masters in fine arts de...  r/CareerAdvice   \n",
            "2  [As a project manager that used to have terrib...  r/CareerAdvice   \n",
            "\n",
            "       category  score  num_comments  \n",
            "0  Professional     11            17  \n",
            "1  Professional     74            39  \n",
            "2  Professional     46            14  \n",
            "----------------------------------------\n",
            "\n",
            "6. File: Reddit_health_original.pkl\n",
            "========================================\n",
            "Data type: <class 'pandas.core.frame.DataFrame'>\n",
            "Shape: (1819, 6)\n",
            "Columns (6):\n",
            "  - text\n",
            "  - type\n",
            "  - subreddit\n",
            "  - category\n",
            "  - score\n",
            "  - url\n",
            "\n",
            "Data types:\n",
            "text          object\n",
            "type          object\n",
            "subreddit     object\n",
            "category      object\n",
            "score        float64\n",
            "url           object\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                                                text       type  \\\n",
            "0  Please check on your quiet friends. Seriously....       post   \n",
            "1         ***caution***\\n***trigger warning***\\n\\...  comment_1   \n",
            "2  I don't consider caring about someone I love a...  comment_2   \n",
            "\n",
            "        subreddit category  score  \\\n",
            "0  r/mentalhealth   Health  182.0   \n",
            "1  r/mentalhealth   Health    NaN   \n",
            "2  r/mentalhealth   Health    NaN   \n",
            "\n",
            "                                                 url  \n",
            "0  https://www.reddit.com/r/mentalhealth/comments...  \n",
            "1  https://www.reddit.com/r/mentalhealth/comments...  \n",
            "2  https://www.reddit.com/r/mentalhealth/comments...  \n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set the path to your pickle files\n",
        "pkl_path = \"/content/drive/MyDrive/488-data/large\"\n",
        "\n",
        "# Get all pickle files in the directory\n",
        "pkl_files = [f for f in os.listdir(pkl_path) if f.endswith('.pkl')]\n",
        "\n",
        "print(f\"Found {len(pkl_files)} pickle files:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Loop through each pickle file and examine its structure\n",
        "for i, filename in enumerate(pkl_files, 1):\n",
        "    file_path = os.path.join(pkl_path, filename)\n",
        "\n",
        "    print(f\"\\n{i}. File: {filename}\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    try:\n",
        "        # Load the pickle file\n",
        "        with open(file_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        # Check the type of data\n",
        "        print(f\"Data type: {type(data)}\")\n",
        "\n",
        "        # If it's a DataFrame, show column info\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            print(f\"Shape: {data.shape}\")\n",
        "            print(f\"Columns ({len(data.columns)}):\")\n",
        "            for col in data.columns:\n",
        "                print(f\"  - {col}\")\n",
        "            print(f\"\\nData types:\")\n",
        "            print(data.dtypes)\n",
        "            print(f\"\\nFirst few rows:\")\n",
        "            print(data.head(3))\n",
        "\n",
        "        # If it's a dictionary, show keys\n",
        "        elif isinstance(data, dict):\n",
        "            print(f\"Dictionary with {len(data)} keys:\")\n",
        "            for key in list(data.keys())[:10]:  # Show first 10 keys\n",
        "                print(f\"  - {key}: {type(data[key])}\")\n",
        "            if len(data) > 10:\n",
        "                print(f\"  ... and {len(data) - 10} more keys\")\n",
        "\n",
        "        # If it's a list, show structure\n",
        "        elif isinstance(data, list):\n",
        "            print(f\"List with {len(data)} items\")\n",
        "            if len(data) > 0:\n",
        "                print(f\"First item type: {type(data[0])}\")\n",
        "                if hasattr(data[0], 'shape'):\n",
        "                    print(f\"First item shape: {data[0].shape}\")\n",
        "\n",
        "        # For other types, show basic info\n",
        "        else:\n",
        "            print(f\"Data structure: {data}\")\n",
        "            if hasattr(data, 'shape'):\n",
        "                print(f\"Shape: {data.shape}\")\n",
        "            if hasattr(data, '__len__'):\n",
        "                print(f\"Length: {len(data)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {filename}: {str(e)}\")\n",
        "\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7FObRqMLyMK"
      },
      "source": [
        "### Format our data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a73baa0529454c8a8b8de7e811652c05",
            "fe0260f08ad5417ebb64c81e95743696",
            "5e3562c43d844961a04fa5890fdd8938",
            "7c58d90bfeee48a6ba918dd14df1e123",
            "45555874afaa45cfbe15a0e230360f9b",
            "da13980d4c0c4cba8ae8ab2176b97560",
            "42f68c6958d7458caa6e5c8994acdb43",
            "7a8f9a9b8da3464da81115a0ddff785b",
            "b2f39b3ee1204b359ed46f7cb2c0b296",
            "fdc5ac0342e9499eac166999885519cc",
            "a3d136251fac4baaab88c6c3a202128a"
          ],
          "height": 1000
        },
        "id": "uOMhV3xScH8t",
        "outputId": "eb1642cb-0acd-4bcb-c614-2b7bac59b5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pickle files...\n",
            "Loaded Reddit_entertainment_original.pkl: 5384 rows -> limited to 5000 rows\n",
            "Loaded Reddit_travel_original.pkl: 4616 rows (no limit needed)\n",
            "Loaded Reddit_comedy_original.pkl: 4986 rows (no limit needed)\n",
            "Loaded Reddit_education_original.pkl: 4714 rows (no limit needed)\n",
            "Loaded Reddit_professional_original.pkl: 11902 rows -> limited to 5000 rows\n",
            "Loaded Reddit_health_original.pkl: 1819 rows (no limit needed)\n",
            "\n",
            "Total combined rows: 26135\n",
            "Data shuffled successfully\n",
            "\n",
            "Standardizing dataframe structures...\n",
            "Standardizing Reddit_entertainment_original.pkl...\n",
            "Standardizing Reddit_travel_original.pkl...\n",
            "Standardizing Reddit_comedy_original.pkl...\n",
            "Standardizing Reddit_education_original.pkl...\n",
            "Standardizing Reddit_professional_original.pkl...\n",
            "Standardizing Reddit_health_original.pkl...\n",
            "Total standardized rows: 24804\n",
            "Final data shuffled successfully\n",
            "\n",
            "Formatting data for Alpaca structure...\n",
            "Created dataset with 24804 examples\n",
            "\n",
            "Category distribution:\n",
            "  Entertainment: 5000 (20.2%)\n",
            "  Professional: 5000 (20.2%)\n",
            "  Comedy: 4986 (20.1%)\n",
            "  education: 4714 (19.0%)\n",
            "  Travel: 4616 (18.6%)\n",
            "  Health: 488 (2.0%)\n",
            "\n",
            "================================================================================\n",
            "SAMPLE FORMATTED EXAMPLE:\n",
            "================================================================================\n",
            "Instruction: Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, and top comments.\n",
            "\n",
            "Input: Post Title: First Time Solo Traveler, Advice Needed for Week in Europe After Study Abroad!\n",
            "\n",
            "Post Content: Hi everyone! I‚Äôm looking for advice on planning my first ever solo travel adventure in Europe. I‚Äôll be finishing a study abroad program in Nice, France on June 23, and my return flight to the U.S. is from Paris on July 1, so I‚Äôve got about one free week to explore, and I really want to make the most of it!\n",
            "\n",
            "I‚Äôm hoping to visit the Swiss Alps, particularly Zermatt and the Matterhorn, and then...\n",
            "\n",
            "Output: Travel\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/24804 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a73baa0529454c8a8b8de7e811652c05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset ready for training!\n",
            "Final dataset size: 24804 examples\n",
            "\n",
            "Summary of data sources:\n",
            "  - Reddit_entertainment_original.pkl: up to 5000 rows\n",
            "  - Reddit_travel_original.pkl: up to 5000 rows\n",
            "  - Reddit_comedy_original.pkl: up to 5000 rows\n",
            "  - Reddit_education_original.pkl: up to 5000 rows\n",
            "  - Reddit_professional_original.pkl: up to 5000 rows\n",
            "  - Reddit_health_original.pkl: up to 5000 rows\n",
            "\n",
            "Next steps:\n",
            "1. Add your tokenizer and uncomment EOS_TOKEN line\n",
            "2. Split into train/validation sets if needed\n",
            "3. Use formatted_dataset for training\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from datasets import Dataset\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Set the path to your pickle files\n",
        "pkl_path = \"/content/drive/MyDrive/488-data/large\"\n",
        "\n",
        "# Load and combine all pickle files with 5000 row limit per file\n",
        "all_dataframes = []\n",
        "pkl_files = [f for f in os.listdir(pkl_path) if f.endswith('.pkl')]\n",
        "MAX_ROWS_PER_FILE = 5000\n",
        "\n",
        "print(\"Loading pickle files...\")\n",
        "for filename in pkl_files:\n",
        "    file_path = os.path.join(pkl_path, filename)\n",
        "    with open(file_path, 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "\n",
        "        # Limit to 5000 rows per file\n",
        "        original_rows = len(df)\n",
        "        if len(df) > MAX_ROWS_PER_FILE:\n",
        "            # Shuffle before taking the first 5000 to get random sampling\n",
        "            df = shuffle(df, random_state=42).reset_index(drop=True)\n",
        "            df = df.head(MAX_ROWS_PER_FILE)\n",
        "            print(f\"Loaded {filename}: {original_rows} rows -> limited to {len(df)} rows\")\n",
        "        else:\n",
        "            print(f\"Loaded {filename}: {len(df)} rows (no limit needed)\")\n",
        "\n",
        "        all_dataframes.append(df)\n",
        "\n",
        "# Combine all dataframes\n",
        "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "print(f\"\\nTotal combined rows: {len(combined_df)}\")\n",
        "\n",
        "# Shuffle the combined data\n",
        "combined_df = shuffle(combined_df, random_state=42).reset_index(drop=True)\n",
        "print(\"Data shuffled successfully\")\n",
        "\n",
        "# Function to clean and format comments (handle string representations of lists)\n",
        "def format_comments(comments):\n",
        "    # Handle None values\n",
        "    if comments is None:\n",
        "        return \"No comments available.\"\n",
        "\n",
        "    # If it's already a list or array\n",
        "    if isinstance(comments, (list, tuple, np.ndarray)):\n",
        "        try:\n",
        "            # Convert to list and filter out empty/None values\n",
        "            comments_list = list(comments)\n",
        "            clean_comments = []\n",
        "            for c in comments_list:\n",
        "                if c is not None and str(c).strip() and str(c).strip().lower() not in ['', 'nan', 'none']:\n",
        "                    clean_comments.append(str(c).strip())\n",
        "\n",
        "            if not clean_comments:\n",
        "                return \"No comments available.\"\n",
        "            return \"\\n\".join([f\"Comment {i+1}: {comment}\" for i, comment in enumerate(clean_comments[:5])])\n",
        "        except:\n",
        "            return \"No comments available.\"\n",
        "\n",
        "    # If it's a string\n",
        "    if isinstance(comments, str):\n",
        "        # Check if it's a NaN string\n",
        "        if comments.strip().lower() in ['nan', 'none', '']:\n",
        "            return \"No comments available.\"\n",
        "\n",
        "        # Try to parse as list\n",
        "        try:\n",
        "            if comments.startswith('[') and comments.endswith(']'):\n",
        "                comments_list = ast.literal_eval(comments)\n",
        "                clean_comments = []\n",
        "                for c in comments_list:\n",
        "                    if c is not None and str(c).strip() and str(c).strip().lower() not in ['', 'nan', 'none']:\n",
        "                        clean_comments.append(str(c).strip())\n",
        "\n",
        "                if not clean_comments:\n",
        "                    return \"No comments available.\"\n",
        "                return \"\\n\".join([f\"Comment {i+1}: {comment}\" for i, comment in enumerate(clean_comments[:5])])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # If it's just a regular string, treat as single comment\n",
        "        if comments.strip():\n",
        "            return f\"Comment 1: {comments.strip()}\"\n",
        "\n",
        "    # For any other type (including pandas NaN)\n",
        "    try:\n",
        "        if pd.isna(comments):\n",
        "            return \"No comments available.\"\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return \"No comments available.\"\n",
        "\n",
        "# Handle different data structures between files\n",
        "def standardize_dataframe(df):\n",
        "    \"\"\"Standardize dataframes to have consistent columns\"\"\"\n",
        "\n",
        "    # Check if this is the health dataset (has 'text' column instead of post_title/post_body)\n",
        "    if 'text' in df.columns and 'post_title' not in df.columns:\n",
        "        # This is the health dataset - convert it to standard format\n",
        "        standardized_df = pd.DataFrame()\n",
        "\n",
        "        # Filter only posts (not comments)\n",
        "        posts_df = df[df['type'] == 'post'].copy() if 'type' in df.columns else df.copy()\n",
        "\n",
        "        standardized_df['post_title'] = posts_df['text'].str[:100] + '...'  # Use first 100 chars as title\n",
        "        standardized_df['post_body'] = posts_df['text']\n",
        "        standardized_df['url'] = posts_df['url'] if 'url' in posts_df.columns else ''\n",
        "        standardized_df['top_5_comments'] = 'No comments available.'  # Health data doesn't have comment structure\n",
        "        standardized_df['subreddit'] = posts_df['subreddit'] if 'subreddit' in posts_df.columns else ''\n",
        "        standardized_df['category'] = posts_df['category'] if 'category' in posts_df.columns else 'Health'\n",
        "        standardized_df['score'] = posts_df['score'] if 'score' in posts_df.columns else 0\n",
        "        standardized_df['num_comments'] = 0  # Health data doesn't have this info\n",
        "\n",
        "        return standardized_df\n",
        "    else:\n",
        "        # Standard format - ensure all required columns exist\n",
        "        required_columns = ['post_title', 'post_body', 'url', 'top_5_comments', 'subreddit', 'category', 'score', 'num_comments']\n",
        "        for col in required_columns:\n",
        "            if col not in df.columns:\n",
        "                df[col] = '' if col in ['post_title', 'post_body', 'url', 'subreddit', 'category'] else 0\n",
        "\n",
        "        return df[required_columns]\n",
        "\n",
        "# Standardize all dataframes\n",
        "print(\"\\nStandardizing dataframe structures...\")\n",
        "standardized_dataframes = []\n",
        "for i, df in enumerate(all_dataframes):\n",
        "    filename = pkl_files[i]\n",
        "    print(f\"Standardizing {filename}...\")\n",
        "    standardized_df = standardize_dataframe(df)\n",
        "    standardized_dataframes.append(standardized_df)\n",
        "\n",
        "# Combine standardized dataframes\n",
        "combined_df = pd.concat(standardized_dataframes, ignore_index=True)\n",
        "print(f\"Total standardized rows: {len(combined_df)}\")\n",
        "\n",
        "# Shuffle the combined data again\n",
        "combined_df = shuffle(combined_df, random_state=42).reset_index(drop=True)\n",
        "print(\"Final data shuffled successfully\")\n",
        "\n",
        "# Create the formatted dataset\n",
        "def create_alpaca_format(df):\n",
        "    instructions = []\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Instruction (consistent task description)\n",
        "        instruction = \"Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, and top comments.\"\n",
        "\n",
        "        # Input (post data)\n",
        "        post_title = str(row['post_title']).strip() if pd.notna(row['post_title']) else \"No title\"\n",
        "        post_body = str(row['post_body']).strip() if pd.notna(row['post_body']) else \"No content\"\n",
        "        comments = format_comments(row['top_5_comments'])\n",
        "\n",
        "        input_text = f\"\"\"Post Title: {post_title}\n",
        "\n",
        "Post Content: {post_body}\n",
        "\n",
        "Top Comments:\n",
        "{comments}\"\"\"\n",
        "\n",
        "        # Output (category)\n",
        "        output = str(row['category']).strip() if pd.notna(row['category']) else \"Unknown\"\n",
        "\n",
        "        # Standardize category names\n",
        "        output = output.title()  # Convert to title case\n",
        "        # Keep Entertainment as separate category - don't map to Comedy!\n",
        "\n",
        "        instructions.append(instruction)\n",
        "        inputs.append(input_text)\n",
        "        outputs.append(output)\n",
        "\n",
        "    return {\n",
        "        'instruction': instructions,\n",
        "        'input': inputs,\n",
        "        'output': outputs\n",
        "    }\n",
        "\n",
        "\n",
        "# Create the formatted data\n",
        "print(\"\\nFormatting data for Alpaca structure...\")\n",
        "formatted_data = create_alpaca_format(combined_df)\n",
        "\n",
        "# Create Hugging Face dataset\n",
        "dataset = Dataset.from_dict(formatted_data)\n",
        "print(f\"Created dataset with {len(dataset)} examples\")\n",
        "\n",
        "# Display some statistics\n",
        "print(f\"\\nCategory distribution:\")\n",
        "category_counts = combined_df['category'].value_counts()\n",
        "for category, count in category_counts.items():\n",
        "    print(f\"  {category}: {count} ({count/len(combined_df)*100:.1f}%)\")\n",
        "\n",
        "# Show a sample\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE FORMATTED EXAMPLE:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Instruction: {formatted_data['instruction'][0]}\")\n",
        "print(f\"\\nInput: {formatted_data['input'][0][:500]}...\")\n",
        "print(f\"\\nOutput: {formatted_data['output'][0]}\")\n",
        "\n",
        "# Alpaca prompt template and formatting function\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "# Define EOS_TOKEN from your tokenizer\n",
        "EOS_TOKEN = tokenizer.eos_token  # For LLaMA 3.1, this will be \"<|eot_id|>\"\n",
        "# Uncomment the line above and make sure tokenizer is defined\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        #text = alpaca_prompt.format(instruction, input, output)  # Temporary without EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Apply formatting\n",
        "formatted_dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "print(f\"\\nDataset ready for training!\")\n",
        "print(f\"Final dataset size: {len(formatted_dataset)} examples\")\n",
        "print(\"\\nSummary of data sources:\")\n",
        "for filename in pkl_files:\n",
        "    print(f\"  - {filename}: up to {MAX_ROWS_PER_FILE} rows\")\n",
        "\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Add your tokenizer and uncomment EOS_TOKEN line\")\n",
        "print(\"2. Split into train/validation sets if needed\")\n",
        "print(\"3. Use formatted_dataset for training\")\n",
        "\n",
        "# Optional: Save the formatted dataset\n",
        "# formatted_dataset.save_to_disk(\"/content/drive/MyDrive/reddit_classification_dataset\")\n",
        "# print(\"Dataset saved to disk!\")\n",
        "\n",
        "# Optional: Create train/validation split\n",
        "# train_test_split = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "# train_dataset = train_test_split['train']\n",
        "# eval_dataset = train_test_split['test']\n",
        "# print(f\"\\nTrain dataset: {len(train_dataset)} examples\")\n",
        "# print(f\"Validation dataset: {len(eval_dataset)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j5b-mbsMvKA",
        "outputId": "199f1950-0466-4d96-ed41-fde4022ff7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 19843\n",
            "Evaluation dataset size: 2480\n",
            "Test dataset size: 2481\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into training, evaluation, and test sets\n",
        "train_testvalid = formatted_dataset.train_test_split(test_size=0.2, seed=42) # 20% for test+validation\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42) # Split test+validation 50/50\n",
        "\n",
        "train_dataset = train_testvalid['train']\n",
        "eval_dataset = test_valid['train']\n",
        "test_dataset = test_valid['test']\n",
        "\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Data"
      ],
      "metadata": {
        "id": "UeT_FTNXenge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_reddit_dataset(train_dataset, eval_dataset, test_dataset, tokenizer):\n",
        "    \"\"\"Comprehensive analysis of the Reddit classification dataset\"\"\"\n",
        "\n",
        "    print(\"üîç REDDIT DATASET ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Basic dataset info\n",
        "    print(f\"üìä Dataset Sizes:\")\n",
        "    print(f\"‚Ä¢ Training: {len(train_dataset):,} examples\")\n",
        "    print(f\"‚Ä¢ Validation: {len(eval_dataset):,} examples\")\n",
        "    print(f\"‚Ä¢ Test: {len(test_dataset):,} examples\")\n",
        "    print(f\"‚Ä¢ Total: {len(train_dataset) + len(eval_dataset) + len(test_dataset):,} examples\")\n",
        "\n",
        "    # Analyze text lengths\n",
        "    print(f\"\\nüìè TEXT LENGTH ANALYSIS:\")\n",
        "\n",
        "    def get_text_stats(dataset, name):\n",
        "        texts = [example['text'] for example in dataset]\n",
        "        char_lengths = [len(text) for text in texts]\n",
        "\n",
        "        # Tokenize a sample to estimate token lengths\n",
        "        sample_size = min(1000, len(texts))\n",
        "        sample_texts = texts[:sample_size]\n",
        "        token_lengths = []\n",
        "\n",
        "        for text in sample_texts:\n",
        "            try:\n",
        "                tokens = tokenizer(text, truncation=False, add_special_tokens=True)\n",
        "                token_lengths.append(len(tokens['input_ids']))\n",
        "            except:\n",
        "                # Fallback estimation if tokenizer fails\n",
        "                token_lengths.append(len(text.split()) * 1.3)  # Rough estimate\n",
        "\n",
        "        # Extrapolate token stats\n",
        "        avg_tokens = np.mean(token_lengths)\n",
        "\n",
        "        print(f\"\\n{name} Dataset:\")\n",
        "        print(f\"  Character lengths:\")\n",
        "        print(f\"    ‚Ä¢ Mean: {np.mean(char_lengths):.0f} chars\")\n",
        "        print(f\"    ‚Ä¢ Median: {np.median(char_lengths):.0f} chars\")\n",
        "        print(f\"    ‚Ä¢ Min: {np.min(char_lengths):.0f} chars\")\n",
        "        print(f\"    ‚Ä¢ Max: {np.max(char_lengths):.0f} chars\")\n",
        "        print(f\"    ‚Ä¢ 95th percentile: {np.percentile(char_lengths, 95):.0f} chars\")\n",
        "\n",
        "        print(f\"  Estimated token lengths (from {sample_size} samples):\")\n",
        "        print(f\"    ‚Ä¢ Mean: {avg_tokens:.0f} tokens\")\n",
        "        print(f\"    ‚Ä¢ Median: {np.median(token_lengths):.0f} tokens\")\n",
        "        print(f\"    ‚Ä¢ Min: {np.min(token_lengths):.0f} tokens\")\n",
        "        print(f\"    ‚Ä¢ Max: {np.max(token_lengths):.0f} tokens\")\n",
        "        print(f\"    ‚Ä¢ 95th percentile: {np.percentile(token_lengths, 95):.0f} tokens\")\n",
        "\n",
        "        # Check how many exceed common sequence lengths\n",
        "        over_512 = sum(1 for t in token_lengths if t > 512)\n",
        "        over_1024 = sum(1 for t in token_lengths if t > 1024)\n",
        "        over_2048 = sum(1 for t in token_lengths if t > 2048)\n",
        "\n",
        "        print(f\"  Sequence length distribution:\")\n",
        "        print(f\"    ‚Ä¢ >512 tokens: {over_512}/{len(token_lengths)} ({over_512/len(token_lengths)*100:.1f}%)\")\n",
        "        print(f\"    ‚Ä¢ >1024 tokens: {over_1024}/{len(token_lengths)} ({over_1024/len(token_lengths)*100:.1f}%)\")\n",
        "        print(f\"    ‚Ä¢ >2048 tokens: {over_2048}/{len(token_lengths)} ({over_2048/len(token_lengths)*100:.1f}%)\")\n",
        "\n",
        "        return char_lengths, token_lengths, avg_tokens\n",
        "\n",
        "    # Analyze each split\n",
        "    train_chars, train_tokens, train_avg_tokens = get_text_stats(train_dataset, \"Training\")\n",
        "    eval_chars, eval_tokens, eval_avg_tokens = get_text_stats(eval_dataset, \"Validation\")\n",
        "\n",
        "    # Category distribution analysis\n",
        "    print(f\"\\nüìà CATEGORY DISTRIBUTION:\")\n",
        "\n",
        "    def analyze_categories(dataset, name):\n",
        "        # Extract categories from the formatted text\n",
        "        categories = []\n",
        "        for example in dataset:\n",
        "            text = example['text']\n",
        "            # Extract the response/category from the formatted text\n",
        "            if \"### Response:\" in text:\n",
        "                response = text.split(\"### Response:\")[-1].strip()\n",
        "                categories.append(response)\n",
        "\n",
        "        category_counts = Counter(categories)\n",
        "        total = len(categories)\n",
        "\n",
        "        print(f\"\\n{name} Categories:\")\n",
        "        for category, count in category_counts.most_common():\n",
        "            percentage = (count / total) * 100\n",
        "            print(f\"  ‚Ä¢ {category}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "        return category_counts\n",
        "\n",
        "    train_categories = analyze_categories(train_dataset, \"Training\")\n",
        "    eval_categories = analyze_categories(eval_dataset, \"Validation\")\n",
        "\n",
        "    # Memory and speed implications\n",
        "    print(f\"\\n‚ö° PERFORMANCE IMPLICATIONS:\")\n",
        "\n",
        "    avg_tokens_all = (train_avg_tokens + eval_avg_tokens) / 2\n",
        "\n",
        "    print(f\"‚Ä¢ Average tokens per example: {avg_tokens_all:.0f}\")\n",
        "    print(f\"‚Ä¢ Current max_seq_length: 2048\")\n",
        "    print(f\"‚Ä¢ Padding waste: ~{((2048 - avg_tokens_all) / 2048) * 100:.1f}% per example\")\n",
        "\n",
        "    # Calculate memory usage estimates\n",
        "    batch_sizes = [8, 16, 32, 64, 128]\n",
        "    seq_lengths = [512, 1024, 2048]\n",
        "\n",
        "    print(f\"\\nüíæ MEMORY USAGE ESTIMATES (4-bit model):\")\n",
        "    print(f\"Batch Size | 512 tokens | 1024 tokens | 2048 tokens\")\n",
        "    print(f\"-----------|------------|-------------|------------\")\n",
        "\n",
        "    for bs in batch_sizes:\n",
        "        mem_512 = bs * 512 * 4 / (1024**3) * 8  # Rough estimate in GB\n",
        "        mem_1024 = bs * 1024 * 4 / (1024**3) * 8\n",
        "        mem_2048 = bs * 2048 * 4 / (1024**3) * 8\n",
        "        print(f\"    {bs:2d}     |   {mem_512:.1f} GB    |    {mem_1024:.1f} GB    |    {mem_2048:.1f} GB\")\n",
        "\n",
        "    # Speed optimization recommendations\n",
        "    print(f\"\\nüöÄ OPTIMIZATION RECOMMENDATIONS:\")\n",
        "\n",
        "    if avg_tokens_all < 512:\n",
        "        print(f\"‚úÖ MAJOR SPEEDUP AVAILABLE:\")\n",
        "        print(f\"   ‚Ä¢ Most examples fit in 512 tokens\")\n",
        "        print(f\"   ‚Ä¢ Reduce max_seq_length to 512 for 4x speedup\")\n",
        "        print(f\"   ‚Ä¢ Can increase batch size significantly\")\n",
        "    elif avg_tokens_all < 1024:\n",
        "        print(f\"‚ö° GOOD SPEEDUP AVAILABLE:\")\n",
        "        print(f\"   ‚Ä¢ Most examples fit in 1024 tokens\")\n",
        "        print(f\"   ‚Ä¢ Reduce max_seq_length to 1024 for 2x speedup\")\n",
        "        print(f\"   ‚Ä¢ Can increase batch size moderately\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  LONG SEQUENCES:\")\n",
        "        print(f\"   ‚Ä¢ Many examples need >1024 tokens\")\n",
        "        print(f\"   ‚Ä¢ Consider text truncation or A100 upgrade\")\n",
        "\n",
        "    # Dataset quality insights\n",
        "    print(f\"\\nüìã DATASET QUALITY INSIGHTS:\")\n",
        "\n",
        "    # Check for class imbalance\n",
        "    category_counts = list(train_categories.values())\n",
        "    max_count = max(category_counts)\n",
        "    min_count = min(category_counts)\n",
        "    imbalance_ratio = max_count / min_count\n",
        "\n",
        "    print(f\"‚Ä¢ Class imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
        "    if imbalance_ratio > 3:\n",
        "        print(f\"  ‚ö†Ô∏è  Significant class imbalance detected\")\n",
        "        print(f\"  üí° Consider class weights or balanced sampling\")\n",
        "    else:\n",
        "        print(f\"  ‚úÖ Good class balance\")\n",
        "\n",
        "    return {\n",
        "        'avg_tokens': avg_tokens_all,\n",
        "        'train_categories': train_categories,\n",
        "        'eval_categories': eval_categories,\n",
        "        'imbalance_ratio': imbalance_ratio\n",
        "    }\n",
        "\n",
        "# Run the analysis\n",
        "print(\"Starting dataset analysis...\")\n",
        "analysis_results = analyze_reddit_dataset(train_dataset, eval_dataset, test_dataset, tokenizer)\n",
        "\n",
        "# Additional quick tokenization test\n",
        "print(f\"\\nüß™ TOKENIZATION SPEED TEST:\")\n",
        "sample_texts = [train_dataset[i]['text'] for i in range(min(10, len(train_dataset)))]\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "for text in sample_texts:\n",
        "    tokens = tokenizer(text, max_length=2048, truncation=True, padding='max_length')\n",
        "tokenization_time = time.time() - start_time\n",
        "\n",
        "print(f\"‚Ä¢ Tokenized {len(sample_texts)} examples in {tokenization_time:.3f}s\")\n",
        "print(f\"‚Ä¢ Average: {tokenization_time/len(sample_texts)*1000:.1f}ms per example\")\n",
        "\n",
        "if tokenization_time/len(sample_texts) > 0.1:\n",
        "    print(f\"  ‚ö†Ô∏è  Slow tokenization detected (>{0.1*1000:.0f}ms per example)\")\n",
        "    print(f\"  üí° This could be contributing to slow training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfrAqYMVJAis",
        "outputId": "e61b6508-4f15-4b8e-9299-2f8edcdee7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dataset analysis...\n",
            "üîç REDDIT DATASET ANALYSIS\n",
            "==================================================\n",
            "üìä Dataset Sizes:\n",
            "‚Ä¢ Training: 19,843 examples\n",
            "‚Ä¢ Validation: 2,480 examples\n",
            "‚Ä¢ Test: 2,481 examples\n",
            "‚Ä¢ Total: 24,804 examples\n",
            "\n",
            "üìè TEXT LENGTH ANALYSIS:\n",
            "\n",
            "Training Dataset:\n",
            "  Character lengths:\n",
            "    ‚Ä¢ Mean: 1748 chars\n",
            "    ‚Ä¢ Median: 1195 chars\n",
            "    ‚Ä¢ Min: 480 chars\n",
            "    ‚Ä¢ Max: 41189 chars\n",
            "    ‚Ä¢ 95th percentile: 4590 chars\n",
            "  Estimated token lengths (from 1000 samples):\n",
            "    ‚Ä¢ Mean: 384 tokens\n",
            "    ‚Ä¢ Median: 259 tokens\n",
            "    ‚Ä¢ Min: 93 tokens\n",
            "    ‚Ä¢ Max: 4398 tokens\n",
            "    ‚Ä¢ 95th percentile: 1044 tokens\n",
            "  Sequence length distribution:\n",
            "    ‚Ä¢ >512 tokens: 223/1000 (22.3%)\n",
            "    ‚Ä¢ >1024 tokens: 51/1000 (5.1%)\n",
            "    ‚Ä¢ >2048 tokens: 5/1000 (0.5%)\n",
            "\n",
            "Validation Dataset:\n",
            "  Character lengths:\n",
            "    ‚Ä¢ Mean: 1744 chars\n",
            "    ‚Ä¢ Median: 1245 chars\n",
            "    ‚Ä¢ Min: 490 chars\n",
            "    ‚Ä¢ Max: 23465 chars\n",
            "    ‚Ä¢ 95th percentile: 4373 chars\n",
            "  Estimated token lengths (from 1000 samples):\n",
            "    ‚Ä¢ Mean: 383 tokens\n",
            "    ‚Ä¢ Median: 271 tokens\n",
            "    ‚Ä¢ Min: 94 tokens\n",
            "    ‚Ä¢ Max: 5714 tokens\n",
            "    ‚Ä¢ 95th percentile: 971 tokens\n",
            "  Sequence length distribution:\n",
            "    ‚Ä¢ >512 tokens: 216/1000 (21.6%)\n",
            "    ‚Ä¢ >1024 tokens: 43/1000 (4.3%)\n",
            "    ‚Ä¢ >2048 tokens: 9/1000 (0.9%)\n",
            "\n",
            "üìà CATEGORY DISTRIBUTION:\n",
            "\n",
            "Training Categories:\n",
            "  ‚Ä¢ Entertainment<|end_of_text|>: 4,010 (20.2%)\n",
            "  ‚Ä¢ Comedy<|end_of_text|>: 4,008 (20.2%)\n",
            "  ‚Ä¢ Professional<|end_of_text|>: 3,973 (20.0%)\n",
            "  ‚Ä¢ Education<|end_of_text|>: 3,811 (19.2%)\n",
            "  ‚Ä¢ Travel<|end_of_text|>: 3,640 (18.3%)\n",
            "  ‚Ä¢ Health<|end_of_text|>: 401 (2.0%)\n",
            "\n",
            "Validation Categories:\n",
            "  ‚Ä¢ Professional<|end_of_text|>: 520 (21.0%)\n",
            "  ‚Ä¢ Entertainment<|end_of_text|>: 497 (20.0%)\n",
            "  ‚Ä¢ Travel<|end_of_text|>: 490 (19.8%)\n",
            "  ‚Ä¢ Comedy<|end_of_text|>: 480 (19.4%)\n",
            "  ‚Ä¢ Education<|end_of_text|>: 449 (18.1%)\n",
            "  ‚Ä¢ Health<|end_of_text|>: 44 (1.8%)\n",
            "\n",
            "‚ö° PERFORMANCE IMPLICATIONS:\n",
            "‚Ä¢ Average tokens per example: 383\n",
            "‚Ä¢ Current max_seq_length: 2048\n",
            "‚Ä¢ Padding waste: ~81.3% per example\n",
            "\n",
            "üíæ MEMORY USAGE ESTIMATES (4-bit model):\n",
            "Batch Size | 512 tokens | 1024 tokens | 2048 tokens\n",
            "-----------|------------|-------------|------------\n",
            "     8     |   0.0 GB    |    0.0 GB    |    0.0 GB\n",
            "    16     |   0.0 GB    |    0.0 GB    |    0.0 GB\n",
            "    32     |   0.0 GB    |    0.0 GB    |    0.0 GB\n",
            "    64     |   0.0 GB    |    0.0 GB    |    0.0 GB\n",
            "    128     |   0.0 GB    |    0.0 GB    |    0.0 GB\n",
            "\n",
            "üöÄ OPTIMIZATION RECOMMENDATIONS:\n",
            "‚úÖ MAJOR SPEEDUP AVAILABLE:\n",
            "   ‚Ä¢ Most examples fit in 512 tokens\n",
            "   ‚Ä¢ Reduce max_seq_length to 512 for 4x speedup\n",
            "   ‚Ä¢ Can increase batch size significantly\n",
            "\n",
            "üìã DATASET QUALITY INSIGHTS:\n",
            "‚Ä¢ Class imbalance ratio: 10.0:1\n",
            "  ‚ö†Ô∏è  Significant class imbalance detected\n",
            "  üí° Consider class weights or balanced sampling\n",
            "\n",
            "üß™ TOKENIZATION SPEED TEST:\n",
            "‚Ä¢ Tokenized 10 examples in 0.024s\n",
            "‚Ä¢ Average: 2.4ms per example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DUe5VgpRAV5"
      },
      "source": [
        "### Optional download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "pNhlVoqTRCcg",
        "outputId": "ad832197-deb0-4f0f-a6c8-0811101a5af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting datasets to CSV format...\n",
            "Processing train dataset (19843 examples)...\n",
            "‚úÖ Train dataset saved as 'reddit_classification_train.csv'\n",
            "Processing eval dataset (2480 examples)...\n",
            "‚úÖ Eval dataset saved as 'reddit_classification_eval.csv'\n",
            "Processing test dataset (2481 examples)...\n",
            "‚úÖ Test dataset saved as 'reddit_classification_test.csv'\n",
            "\n",
            "üìä DATASET SUMMARY:\n",
            "--------------------------------------------------\n",
            "Train set: 19,843 examples\n",
            "Eval set:  2,480 examples\n",
            "Test set:  2,481 examples\n",
            "Total:     24,804 examples\n",
            "\n",
            "Columns in each CSV:\n",
            "  - instruction\n",
            "  - input\n",
            "  - output\n",
            "  - text\n",
            "\n",
            "üîΩ DOWNLOADING FILES...\n",
            "Files will download to your local machine:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_afa99e5a-3f2e-430a-b0da-9273e05986f6\", \"reddit_classification_train.csv\", 65593172)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train dataset downloaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2e32e69b-4311-40af-a4b0-e9cefdd89c6a\", \"reddit_classification_eval.csv\", 8183514)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Eval dataset downloaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_981e5ab1-c64a-4862-bfeb-1e4dbe8e313d\", \"reddit_classification_test.csv\", 8298072)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Test dataset downloaded\n",
            "\n",
            "üéØ DATASET READY FOR:\n",
            "‚úÖ Further model training\n",
            "‚úÖ Sharing with team members\n",
            "‚úÖ Production deployment\n",
            "‚úÖ Academic research\n",
            "‚úÖ Model reproducibility\n",
            "\n",
            "üìã SAMPLE DATA PREVIEW:\n",
            "============================================================\n",
            "TRAIN DATASET SAMPLE:\n",
            "                                         instruction  output\n",
            "0  Classify the following Reddit post into one of...  Travel\n",
            "1  Classify the following Reddit post into one of...  Travel\n",
            "\n",
            "EVAL DATASET SAMPLE:\n",
            "                                         instruction        output\n",
            "0  Classify the following Reddit post into one of...        Travel\n",
            "1  Classify the following Reddit post into one of...  Professional\n",
            "\n",
            "TEST DATASET SAMPLE:\n",
            "                                         instruction  output\n",
            "0  Classify the following Reddit post into one of...  Travel\n",
            "1  Classify the following Reddit post into one of...  Comedy\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Convert datasets to pandas DataFrames and save as CSV\n",
        "def download_datasets():\n",
        "    \"\"\"\n",
        "    Convert and download train, eval, and test datasets as CSV files\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Converting datasets to CSV format...\")\n",
        "\n",
        "    # Convert train dataset\n",
        "    print(f\"Processing train dataset ({len(train_dataset)} examples)...\")\n",
        "    train_df = pd.DataFrame(train_dataset)\n",
        "    train_df.to_csv('/content/reddit_classification_train.csv', index=False)\n",
        "    print(\"‚úÖ Train dataset saved as 'reddit_classification_train.csv'\")\n",
        "\n",
        "    # Convert eval dataset\n",
        "    print(f\"Processing eval dataset ({len(eval_dataset)} examples)...\")\n",
        "    eval_df = pd.DataFrame(eval_dataset)\n",
        "    eval_df.to_csv('/content/reddit_classification_eval.csv', index=False)\n",
        "    print(\"‚úÖ Eval dataset saved as 'reddit_classification_eval.csv'\")\n",
        "\n",
        "    # Convert test dataset\n",
        "    print(f\"Processing test dataset ({len(test_dataset)} examples)...\")\n",
        "    test_df = pd.DataFrame(test_dataset)\n",
        "    test_df.to_csv('/content/reddit_classification_test.csv', index=False)\n",
        "    print(\"‚úÖ Test dataset saved as 'reddit_classification_test.csv'\")\n",
        "\n",
        "    # Show dataset info\n",
        "    print(\"\\nüìä DATASET SUMMARY:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Train set: {len(train_dataset):,} examples\")\n",
        "    print(f\"Eval set:  {len(eval_dataset):,} examples\")\n",
        "    print(f\"Test set:  {len(test_dataset):,} examples\")\n",
        "    print(f\"Total:     {len(train_dataset) + len(eval_dataset) + len(test_dataset):,} examples\")\n",
        "\n",
        "    # Show column structure\n",
        "    print(f\"\\nColumns in each CSV:\")\n",
        "    for col in train_df.columns:\n",
        "        print(f\"  - {col}\")\n",
        "\n",
        "    print(\"\\nüîΩ DOWNLOADING FILES...\")\n",
        "    print(\"Files will download to your local machine:\")\n",
        "\n",
        "    # Download the files\n",
        "    try:\n",
        "        files.download('/content/reddit_classification_train.csv')\n",
        "        print(\"‚úÖ Train dataset downloaded\")\n",
        "    except:\n",
        "        print(\"‚ùå Train dataset download failed\")\n",
        "\n",
        "    try:\n",
        "        files.download('/content/reddit_classification_eval.csv')\n",
        "        print(\"‚úÖ Eval dataset downloaded\")\n",
        "    except:\n",
        "        print(\"‚ùå Eval dataset download failed\")\n",
        "\n",
        "    try:\n",
        "        files.download('/content/reddit_classification_test.csv')\n",
        "        print(\"‚úÖ Test dataset downloaded\")\n",
        "    except:\n",
        "        print(\"‚ùå Test dataset download failed\")\n",
        "\n",
        "    print(\"\\nüéØ DATASET READY FOR:\")\n",
        "    print(\"‚úÖ Further model training\")\n",
        "    print(\"‚úÖ Sharing with team members\")\n",
        "    print(\"‚úÖ Production deployment\")\n",
        "    print(\"‚úÖ Academic research\")\n",
        "    print(\"‚úÖ Model reproducibility\")\n",
        "\n",
        "    return train_df, eval_df, test_df\n",
        "\n",
        "# Run the download\n",
        "train_df, eval_df, test_df = download_datasets()\n",
        "\n",
        "# Optional: Show a sample of each dataset\n",
        "print(\"\\nüìã SAMPLE DATA PREVIEW:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAIN DATASET SAMPLE:\")\n",
        "print(train_df[['instruction', 'output']].head(2))\n",
        "print(\"\\nEVAL DATASET SAMPLE:\")\n",
        "print(eval_df[['instruction', 'output']].head(2))\n",
        "print(\"\\nTEST DATASET SAMPLE:\")\n",
        "print(test_df[['instruction', 'output']].head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de09f4e2e203485a9df7a40579f4f7e5",
            "5acdb8868d77498682e47455592374f3",
            "7d2956212c864e68a4eae8089d560fc8",
            "13b77ac9ea0846ac9b25d59e489bed9d",
            "29b04953d17a4f40b9b694121b30d2de",
            "538939042e254262a40e23c694613546",
            "0f1faa3b2bb249cface6c0074caf4baf",
            "1b59c63d4b6744969bd73a4a14278806",
            "1613d0df04844bf6bf8212e9dba9f76c",
            "efa92f60256a45c8959be371a94b27d7",
            "282658b7f9d94d649671e84c7560396f",
            "7d65b26996bb4516a4bbe7f85963889a",
            "e1439359f5e64bfb869574109173aa3f",
            "cac4872dd1794ed89c9bcbef29f4269c",
            "e89e15874b71486cb0c3df6f2cedc080",
            "ab9b9a2a33664173a68f2347a80ec277",
            "ccf3148cff6c461f8193cf727904ee3c",
            "7e6bf85541ea428594b9efc395ea2038",
            "2e096814ff9d4907ae4fde7cf2f321bc",
            "6852da25691f4d97b90ac06de29b4d00",
            "d5b88d8eeb274382ac2cbc8a9b61d3d6",
            "f23921ab27be4ae897a8621fa85f0639"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "307c9302-f5bf-419b-9209-e1cfd77c18db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 19843\n",
            "Evaluation dataset size: 2480\n",
            "Test dataset size: 2481\n",
            "Effective batch size: 12\n",
            "Steps per epoch: 1653\n",
            "Total training steps: 4959\n",
            "Eval every 275 steps (6x per epoch)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">A100-OPTIMIZED-seq512-bs64</strong> at: <a href='https://wandb.ai/yaamin6236/reddit-classification-sft/runs/xuh8lhme' target=\"_blank\">https://wandb.ai/yaamin6236/reddit-classification-sft/runs/xuh8lhme</a><br> View project at: <a href='https://wandb.ai/yaamin6236/reddit-classification-sft' target=\"_blank\">https://wandb.ai/yaamin6236/reddit-classification-sft</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_062302-xuh8lhme/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_062321-8qcooxx8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yaamin6236/reddit-classification-sft/runs/8qcooxx8' target=\"_blank\">unsloth-llama31-8b-bs12-lr5e5-ep3</a></strong> to <a href='https://wandb.ai/yaamin6236/reddit-classification-sft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yaamin6236/reddit-classification-sft' target=\"_blank\">https://wandb.ai/yaamin6236/reddit-classification-sft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yaamin6236/reddit-classification-sft/runs/8qcooxx8' target=\"_blank\">https://wandb.ai/yaamin6236/reddit-classification-sft/runs/8qcooxx8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/19843 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de09f4e2e203485a9df7a40579f4f7e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/2480 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d65b26996bb4516a4bbe7f85963889a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ UNSLOTH + L4 GPU OPTIMIZED Configuration:\n",
            "‚Ä¢ Model: LLaMA-3.1-8B (4-bit quantized)\n",
            "‚Ä¢ VRAM usage: ~8-12GB (4-bit quantization is very efficient!)\n",
            "‚Ä¢ Batch size: 12 (no gradient accumulation needed)\n",
            "‚Ä¢ Effective batch size: 12\n",
            "‚Ä¢ Training epochs: 3\n",
            "‚Ä¢ Total steps: 4959\n",
            "‚Ä¢ Steps per epoch: 1653\n",
            "‚Ä¢ Eval frequency: Every 275 steps (6x per epoch)\n",
            "‚Ä¢ Expected training time: ~1-2 hours (Unsloth is FAST!)\n",
            "‚Ä¢ Speed boost: ~3-4x faster than standard fine-tuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 19,843 | Num Epochs = 3 | Total steps = 4,962\n",
            "O^O/ \\_/ \\    Batch size per device = 12 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (12 x 1 x 1) = 12\n",
            " \"-____-\"     Trainable parameters = 167,772,160/8,000,000,000 (2.10% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1658' max='4962' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1658/4962 59:42 < 1:59:08, 0.46 it/s, Epoch 1.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.621100</td>\n",
              "      <td>1.633559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.583000</td>\n",
              "      <td>1.618192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.595700</td>\n",
              "      <td>1.605017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.559300</td>\n",
              "      <td>1.599717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.541200</td>\n",
              "      <td>1.595331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.570500</td>\n",
              "      <td>1.591890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 550 that is less than the current step 551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1650 that is less than the current step 1651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1650 that is less than the current step 1651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1650 that is less than the current step 1651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1650 that is less than the current step 1651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1650 that is less than the current step 1651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b4a691c35f71>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;31m# Final logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         outputs = super().compute_loss(\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         )\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3810\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3811\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m ):\n\u001b[0;32m-> 1207\u001b[0;31m     return self.base_model(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                 loss = fused_linear_cross_entropy(\n\u001b[0m\u001b[1;32m   1105\u001b[0m                     \u001b[0mhidden_states\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                     \u001b[0mlm_weight\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mlm_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/loss_utils.py\u001b[0m in \u001b[0;36mfused_linear_cross_entropy\u001b[0;34m(hidden_states, lm_weight, labels, num_items_in_batch, ignore_index, reduction, logit_softcapping, accuracy_threshold)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mtorch_cuda_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m def fused_linear_cross_entropy(\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mhidden_states\u001b[0m      \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlm_weight\u001b[0m          \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, TrainerCallback, TrainerState, TrainerControl\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Calculate dataset sizes dynamically\n",
        "train_size = len(train_dataset)\n",
        "eval_size = len(eval_dataset)\n",
        "test_size = len(test_dataset) if 'test_dataset' in locals() else 0\n",
        "\n",
        "# Optimized hyperparameters for L4 GPU + Unsloth 4-bit quantization\n",
        "batch_size = 12  # VERY aggressive - 4-bit model uses much less VRAM!\n",
        "grad_accum = 1   # No accumulation needed with this batch size\n",
        "effective_batch_size = batch_size * grad_accum\n",
        "steps_per_epoch = train_size // effective_batch_size\n",
        "total_epochs = 3  # Keep at 3 - still optimal\n",
        "\n",
        "print(f\"Training dataset size: {train_size}\")\n",
        "print(f\"Evaluation dataset size: {eval_size}\")\n",
        "if test_size > 0:\n",
        "    print(f\"Test dataset size: {test_size}\")\n",
        "print(f\"Effective batch size: {effective_batch_size}\")\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Total training steps: {steps_per_epoch * total_epochs}\")\n",
        "print(f\"Eval every {steps_per_epoch // 6} steps (6x per epoch)\")\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(\n",
        "    project=\"reddit-classification-sft\",\n",
        "    name=f\"unsloth-llama31-8b-bs{effective_batch_size}-lr5e5-ep{total_epochs}\",\n",
        "    config={\n",
        "        \"model_name\": \"unsloth/Meta-Llama-3.1-8B\",\n",
        "        \"quantization\": \"4-bit\",\n",
        "        \"framework\": \"unsloth\",\n",
        "        \"dataset\": \"reddit-posts\",\n",
        "        \"task\": \"text-classification\",\n",
        "        \"categories\": [\"Comedy\", \"Entertainment\", \"Education\", \"Health\", \"Professional\", \"Travel\"],\n",
        "        \"train_samples\": train_size,\n",
        "        \"eval_samples\": eval_size,\n",
        "        \"test_samples\": test_size,\n",
        "        \"max_seq_length\": 2048,  # From your config\n",
        "        \"architecture\": \"SFT-LoRA-4bit\",\n",
        "        \"effective_batch_size\": effective_batch_size,\n",
        "        \"total_epochs\": total_epochs,\n",
        "        \"total_steps\": steps_per_epoch * total_epochs,\n",
        "    },\n",
        "    tags=[\"sft\", \"llama-3.1\", \"unsloth\", \"4-bit\", \"reddit\", \"classification\"]\n",
        ")\n",
        "\n",
        "# Add custom metrics tracking callback\n",
        "class WandBCallback(TrainerCallback):\n",
        "    \"\"\"Custom callback to track additional metrics in W&B\"\"\"\n",
        "    def on_train_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called just before the training loop starts.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_step_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called at the beginning of a training step.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_step_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called at the end of a training step.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_epoch_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called at the beginning of an epoch.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_epoch_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called at the end of an epoch.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, model=None, logs=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called after logging is performed.\n",
        "        \"\"\"\n",
        "        if logs:\n",
        "            # Log learning rate\n",
        "            if \"learning_rate\" in logs:\n",
        "                wandb.log({\"learning_rate\": logs[\"learning_rate\"]}, step=state.global_step)\n",
        "\n",
        "            # Log training metrics\n",
        "            if \"loss\" in logs: # Use \"loss\" which is the actual training loss key in TRL logs\n",
        "                wandb.log({\"train_loss\": logs[\"loss\"]}, step=state.global_step)\n",
        "\n",
        "            # Log evaluation metrics\n",
        "            if \"eval_loss\" in logs:\n",
        "                wandb.log({\"eval_loss\": logs[\"eval_loss\"]}, step=state.global_step)\n",
        "\n",
        "            # Calculate and log perplexity if available\n",
        "            if \"eval_loss\" in logs:\n",
        "                perplexity = torch.exp(torch.tensor(logs[\"eval_loss\"]))\n",
        "                wandb.log({\"eval_perplexity\": perplexity.item()}, step=state.global_step)\n",
        "\n",
        "            # Log other metrics\n",
        "            # Filter out keys that are already handled or not relevant\n",
        "            ignored_keys = [\"learning_rate\", \"loss\", \"eval_loss\", \"epoch\"]\n",
        "            for key, value in logs.items():\n",
        "                if key not in ignored_keys and isinstance(value, (int, float)):\n",
        "                    wandb.log({key: value}, step=state.global_step)\n",
        "\n",
        "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
        "        \"\"\"\n",
        "        Event called just at the end of training.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        # UPDATED: Very aggressive batch size for 4-bit quantized model\n",
        "        per_device_train_batch_size = 12,  # 4-bit uses much less VRAM!\n",
        "        gradient_accumulation_steps = 1,   # No accumulation needed\n",
        "\n",
        "        # UPDATED: Reduced epochs significantly\n",
        "        num_train_epochs = 3,  # Down from 20\n",
        "\n",
        "        # Learning rate - keep as is, it's good\n",
        "        learning_rate = 5e-5,\n",
        "\n",
        "        # Warmup - adjust for shorter training\n",
        "        warmup_steps = 100,  # ~8% of total steps\n",
        "        # Alternative: warmup_ratio = 0.08,\n",
        "\n",
        "        # Scheduler\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "\n",
        "        # Precision - use bf16 for better performance on L4\n",
        "        fp16 = False,  # Disable fp16\n",
        "        bf16 = True,   # Force bf16 for L4 GPU (better than fp16)\n",
        "\n",
        "        # UPDATED: More frequent evaluation due to fewer total steps\n",
        "        logging_steps = 50,\n",
        "        eval_strategy = \"steps\",\n",
        "        eval_steps = steps_per_epoch // 6,     # 6x per epoch for close monitoring\n",
        "\n",
        "        # UPDATED: Save checkpoints at evaluation points (must be multiple of eval_steps)\n",
        "        save_strategy = \"steps\",\n",
        "        save_steps = steps_per_epoch // 6,  # Ensure save_steps is a multiple of eval_steps\n",
        "\n",
        "        # Regularization\n",
        "        weight_decay = 0.01,  # Reduced since we're training for fewer epochs\n",
        "\n",
        "        # Optimizer - use standard AdamW with 4-bit quantized model\n",
        "        optim = \"adamw_torch\",  # Standard AdamW works great with Unsloth\n",
        "        # Note: Unsloth handles memory optimization internally\n",
        "\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "\n",
        "        # W&B Integration\n",
        "        report_to = \"wandb\",\n",
        "        run_name = f\"reddit-sft-bs{effective_batch_size}-lr5e5-ep{total_epochs}\",\n",
        "\n",
        "        # Performance optimizations for L4\n",
        "        dataloader_num_workers = 4,        # Parallel data loading\n",
        "        dataloader_pin_memory = True,      # Faster CPU->GPU transfer\n",
        "        group_by_length = True,            # More efficient batching\n",
        "\n",
        "        # Advanced settings for L4\n",
        "        tf32 = True,                       # Enable TF32 for faster matmul on Ampere\n",
        "        dataloader_persistent_workers = True,  # Keep workers alive between epochs\n",
        "\n",
        "        logging_first_step = True,\n",
        "        load_best_model_at_end = True,\n",
        "        metric_for_best_model = \"eval_loss\",\n",
        "        greater_is_better = False,\n",
        "        save_total_limit = 2,  # Keep only 2 checkpoints since training is shorter\n",
        "\n",
        "        # Early stopping (optional but recommended)\n",
        "        # early_stopping_patience = 3,  # Uncomment if you want early stopping\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Add the custom callback\n",
        "trainer.add_callback(WandBCallback())\n",
        "\n",
        "print(\"üöÄ UNSLOTH + A100 GPU OPTIMIZED Configuration:\")\n",
        "print(f\"‚Ä¢ Model: LLaMA-3.1-8B (4-bit quantized)\")\n",
        "print(f\"‚Ä¢ VRAM usage: ~8-12GB (4-bit quantization is very efficient!)\")\n",
        "print(f\"‚Ä¢ Batch size: {batch_size} (no gradient accumulation needed)\")\n",
        "print(f\"‚Ä¢ Effective batch size: {effective_batch_size}\")\n",
        "print(f\"‚Ä¢ Training epochs: {total_epochs}\")\n",
        "print(f\"‚Ä¢ Total steps: {steps_per_epoch * total_epochs}\")\n",
        "print(f\"‚Ä¢ Steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"‚Ä¢ Eval frequency: Every {steps_per_epoch // 6} steps (6x per epoch)\")\n",
        "print(f\"‚Ä¢ Expected training time: ~1-2 hours (Unsloth is FAST!)\")\n",
        "print(f\"‚Ä¢ Speed boost: ~3-4x faster than standard fine-tuning\")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Final logging\n",
        "wandb.log({\n",
        "    \"training_completed\": True,\n",
        "    \"final_epoch\": trainer.state.epoch,\n",
        "    \"total_steps_completed\": trainer.state.global_step\n",
        "})\n",
        "\n",
        "print(\"Training completed!\")\n",
        "print(f\"View results at: {wandb.run.url}\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "ebfa1c9a-17ca-445a-c808-92f2d54ad068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = NVIDIA L4. Max memory = 22.161 GB.\n",
            "7.654 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "e97de480-385e-4604-844a-1e0efe7f1ffc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 2,129 | Num Epochs = 20 | Total steps = 5,320\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 167,772,160/8,000,000,000 (2.10% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2414' max='5320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2414/5320 4:29:47 < 5:25:02, 0.15 it/s, Epoch 9.04/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>1.948200</td>\n",
              "      <td>1.834770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>1.960800</td>\n",
              "      <td>1.823274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>399</td>\n",
              "      <td>1.963000</td>\n",
              "      <td>1.818654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>532</td>\n",
              "      <td>1.938800</td>\n",
              "      <td>1.816472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>665</td>\n",
              "      <td>1.842200</td>\n",
              "      <td>1.833740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>798</td>\n",
              "      <td>1.864600</td>\n",
              "      <td>1.831825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>931</td>\n",
              "      <td>1.745500</td>\n",
              "      <td>1.883374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1064</td>\n",
              "      <td>1.721200</td>\n",
              "      <td>1.870746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1197</td>\n",
              "      <td>1.605600</td>\n",
              "      <td>1.928957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>1.638400</td>\n",
              "      <td>1.931466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1463</td>\n",
              "      <td>1.564900</td>\n",
              "      <td>2.014158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1596</td>\n",
              "      <td>1.522100</td>\n",
              "      <td>2.010449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1729</td>\n",
              "      <td>1.355000</td>\n",
              "      <td>2.106889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1862</td>\n",
              "      <td>1.392100</td>\n",
              "      <td>2.121580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1995</td>\n",
              "      <td>1.246300</td>\n",
              "      <td>2.205915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2128</td>\n",
              "      <td>1.238700</td>\n",
              "      <td>2.214548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2261</td>\n",
              "      <td>1.028600</td>\n",
              "      <td>2.326314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2394</td>\n",
              "      <td>1.024400</td>\n",
              "      <td>2.361134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLuc86eVM_Ww"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ9n8f6dLrHr",
        "outputId": "5b00aed4-fa27-47a3-c028-011d75cb5119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ DEBUGGING WITH SMALL SAMPLE\n",
            "==================================================\n",
            "Running classification evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 4075.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä ANALYZING ACTUAL LABELS IN DATASET:\n",
            "Found labels: Counter({'Travel': 4, 'Comedy': 4, 'Professional': 1, 'Education': 1})\n",
            "Using class names: ['Travel', 'Comedy', 'Professional', 'Education']\n",
            "\n",
            "Running predictions on 10 examples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:   0%|          | 0/10 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 1/10 [00:00<00:04,  1.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 2/10 [00:00<00:03,  2.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:01<00:02,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:01<00:01,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:01<00:01,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:01<00:01,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:02<00:00,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:02<00:00,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:02<00:00,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä PREDICTION ANALYSIS:\n",
            "Predicted label distribution: Counter({'Comedy': 4, 'Travel': 2, 'words': 1, 'Professional': 1, 'Education': 1, 'used': 1})\n",
            "\n",
            "‚úÖ Valid predictions: 8/10\n",
            "\n",
            "============================================================\n",
            "CLASSIFICATION EVALUATION RESULTS\n",
            "============================================================\n",
            "Overall Accuracy: 1.0000 (100.00%)\n",
            "Valid examples: 8\n",
            "\n",
            "Per-Class Metrics:\n",
            "------------------------------------------------------------\n",
            "Travel       | Precision: 1.000 | Recall: 1.000 | F1: 1.000 | Support: 2.0\n",
            "Comedy       | Precision: 1.000 | Recall: 1.000 | F1: 1.000 | Support: 4.0\n",
            "Professional | Precision: 1.000 | Recall: 1.000 | F1: 1.000 | Support: 1.0\n",
            "Education    | Precision: 1.000 | Recall: 1.000 | F1: 1.000 | Support: 1.0\n",
            "\n",
            "Macro Average F1-Score: 1.0000\n",
            "Weighted Average F1-Score: 1.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------------------------------------\n",
            "              Travel  Comedy  Professional  Education\n",
            "Travel             2       0             0          0\n",
            "Comedy             0       4             0          0\n",
            "Professional       0       0             1          0\n",
            "Education          0       0             0          1\n",
            "\n",
            "Sample Predictions:\n",
            "------------------------------------------------------------\n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Professional | Predicted: Professional\n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Travel       | Predicted: Travel      \n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Education    | Predicted: Education   \n",
            "‚úì True: Travel       | Predicted: Travel      \n",
            "\n",
            "‚úÖ Debug successful! Running full evaluation...\n",
            "\n",
            "üéØ FINAL TEST SET EVALUATION\n",
            "================================================================================\n",
            "Test set size: 2481\n",
            "This is the FINAL evaluation on completely unseen data\n",
            "================================================================================\n",
            "Running classification evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2481/2481 [00:00<00:00, 10616.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä ANALYZING ACTUAL LABELS IN DATASET:\n",
            "Found labels: Counter({'Professional': 507, 'Comedy': 498, 'Entertainment': 493, 'Travel': 486, 'Education': 454, 'Health': 43})\n",
            "Using class names: ['Professional', 'Comedy', 'Entertainment', 'Travel', 'Education', 'Health']\n",
            "\n",
            "Running predictions on 2481 examples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:   0%|          | 0/2481 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 1/2481 [00:00<22:05,  1.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 2/2481 [00:00<15:45,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 3/2481 [00:01<14:16,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 4/2481 [00:01<13:16,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 5/2481 [00:01<12:28,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 6/2481 [00:01<11:03,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 7/2481 [00:02<12:18,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 8/2481 [00:02<11:04,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 9/2481 [00:02<13:58,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 10/2481 [00:03<12:11,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 11/2481 [00:03<14:34,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   0%|          | 12/2481 [00:03<13:25,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 13/2481 [00:04<11:54,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 14/2481 [00:04<14:27,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 15/2481 [00:04<13:23,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 16/2481 [00:05<12:38,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 17/2481 [00:05<14:58,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 18/2481 [00:05<13:40,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 19/2481 [00:06<12:00,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 20/2481 [00:06<13:31,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 21/2481 [00:06<11:57,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 22/2481 [00:07<14:35,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 23/2481 [00:07<15:09,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 24/2481 [00:07<15:35,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 25/2481 [00:08<14:32,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 26/2481 [00:08<13:41,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 27/2481 [00:08<12:52,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 28/2481 [00:09<15:07,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 29/2481 [00:09<13:04,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 30/2481 [00:09<11:37,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|          | 31/2481 [00:09<10:31,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 32/2481 [00:10<10:59,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 33/2481 [00:10<10:16,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 34/2481 [00:10<12:05,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 35/2481 [00:11<14:31,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 36/2481 [00:11<12:34,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   1%|‚ñè         | 37/2481 [00:11<11:17,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 38/2481 [00:11<10:18,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 39/2481 [00:12<11:36,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 40/2481 [00:12<13:09,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 41/2481 [00:12<12:25,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 42/2481 [00:13<12:20,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 43/2481 [00:13<12:16,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 44/2481 [00:13<13:32,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 45/2481 [00:14<12:03,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 46/2481 [00:14<13:13,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 47/2481 [00:14<12:28,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 48/2481 [00:15<11:58,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 49/2481 [00:15<14:32,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 50/2481 [00:15<12:36,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 51/2481 [00:16<11:15,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 52/2481 [00:16<10:24,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 53/2481 [00:16<11:36,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 54/2481 [00:16<10:31,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 55/2481 [00:16<09:48,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 56/2481 [00:17<12:50,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 57/2481 [00:17<13:37,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 58/2481 [00:18<11:53,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 59/2481 [00:18<10:39,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 60/2481 [00:18<09:49,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 61/2481 [00:18<11:37,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   2%|‚ñè         | 62/2481 [00:19<14:04,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 63/2481 [00:19<12:19,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 64/2481 [00:19<11:03,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 65/2481 [00:19<10:09,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 66/2481 [00:20<11:29,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 67/2481 [00:20<12:32,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 68/2481 [00:21<13:28,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 69/2481 [00:21<15:22,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 70/2481 [00:21<14:08,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 71/2481 [00:22<13:10,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 72/2481 [00:22<12:48,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 73/2481 [00:22<13:25,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 74/2481 [00:22<11:48,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 75/2481 [00:23<12:01,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 76/2481 [00:23<12:51,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 77/2481 [00:23<11:21,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 78/2481 [00:24<12:43,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 79/2481 [00:24<13:38,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 80/2481 [00:24<11:55,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 81/2481 [00:25<10:41,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 82/2481 [00:25<11:45,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 83/2481 [00:25<11:24,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 84/2481 [00:26<13:51,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 85/2481 [00:26<12:07,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   3%|‚ñé         | 86/2481 [00:26<10:56,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 87/2481 [00:26<12:29,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 88/2481 [00:27<12:17,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 89/2481 [00:27<13:24,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 90/2481 [00:28<15:17,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 91/2481 [00:28<14:05,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 92/2481 [00:28<13:16,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñé         | 93/2481 [00:29<15:17,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 94/2481 [00:29<15:01,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 95/2481 [00:29<12:55,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 96/2481 [00:30<11:23,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 97/2481 [00:30<10:23,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 98/2481 [00:30<09:38,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 99/2481 [00:30<11:07,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 100/2481 [00:31<10:55,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 100/2481 examples\n",
            "Sample - True: Comedy, Predicted: Comedy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:   4%|‚ñç         | 101/2481 [00:31<13:28,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 102/2481 [00:31<11:48,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 103/2481 [00:31<10:39,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 104/2481 [00:32<10:40,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 105/2481 [00:32<11:10,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 106/2481 [00:32<12:26,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 107/2481 [00:33<13:18,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 108/2481 [00:33<13:52,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 109/2481 [00:33<12:06,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 110/2481 [00:34<10:53,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   4%|‚ñç         | 111/2481 [00:34<10:00,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 112/2481 [00:34<10:34,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 113/2481 [00:34<09:49,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 114/2481 [00:34<09:20,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 115/2481 [00:35<09:42,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 116/2481 [00:35<11:16,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 117/2481 [00:35<10:19,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 118/2481 [00:36<09:36,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 119/2481 [00:36<09:02,  4.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 120/2481 [00:36<10:35,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 121/2481 [00:36<09:46,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 122/2481 [00:37<09:58,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 123/2481 [00:37<10:04,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñç         | 124/2481 [00:37<10:31,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 125/2481 [00:37<10:23,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 126/2481 [00:38<09:34,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 127/2481 [00:38<09:00,  4.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 128/2481 [00:38<10:31,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 129/2481 [00:39<12:04,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 130/2481 [00:39<10:50,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 131/2481 [00:39<13:45,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 132/2481 [00:40<12:45,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 133/2481 [00:40<12:04,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 134/2481 [00:40<12:39,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 135/2481 [00:40<11:58,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   5%|‚ñå         | 136/2481 [00:41<10:44,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 137/2481 [00:41<12:03,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 138/2481 [00:41<10:44,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 139/2481 [00:42<12:29,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 140/2481 [00:42<12:11,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 141/2481 [00:42<14:14,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 142/2481 [00:43<13:04,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 143/2481 [00:43<13:23,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 144/2481 [00:43<11:42,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 145/2481 [00:43<10:33,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 146/2481 [00:44<09:46,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 147/2481 [00:44<11:13,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 148/2481 [00:44<12:29,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 149/2481 [00:45<11:03,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 150/2481 [00:45<11:57,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 151/2481 [00:45<10:43,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 152/2481 [00:45<09:46,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 153/2481 [00:46<09:09,  4.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 154/2481 [00:46<08:45,  4.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñå         | 155/2481 [00:46<09:40,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 156/2481 [00:46<09:04,  4.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 157/2481 [00:47<09:22,  4.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 158/2481 [00:47<11:08,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 159/2481 [00:47<10:17,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 160/2481 [00:47<09:37,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   6%|‚ñã         | 161/2481 [00:48<10:13,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 162/2481 [00:48<10:28,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 163/2481 [00:48<12:15,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 164/2481 [00:49<12:02,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 165/2481 [00:49<11:29,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 166/2481 [00:49<12:12,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 167/2481 [00:50<10:49,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 168/2481 [00:50<10:36,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 169/2481 [00:50<11:31,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 170/2481 [00:51<12:37,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 171/2481 [00:51<11:21,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 172/2481 [00:51<12:12,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 173/2481 [00:51<10:50,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 174/2481 [00:52<09:52,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 175/2481 [00:52<12:35,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 176/2481 [00:52<11:48,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 177/2481 [00:52<10:30,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 178/2481 [00:53<09:41,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 179/2481 [00:53<09:01,  4.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 180/2481 [00:53<09:19,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 181/2481 [00:53<08:48,  4.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 182/2481 [00:54<09:11,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 183/2481 [00:54<09:59,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 184/2481 [00:54<10:08,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 185/2481 [00:54<09:28,  4.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   7%|‚ñã         | 186/2481 [00:55<10:03,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 187/2481 [00:55<10:25,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 188/2481 [00:55<09:32,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 189/2481 [00:55<09:35,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 190/2481 [00:56<08:57,  4.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 191/2481 [00:56<11:53,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 192/2481 [00:56<11:13,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 193/2481 [00:57<10:45,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 194/2481 [00:57<09:52,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 195/2481 [00:57<09:08,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 196/2481 [00:57<08:42,  4.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 197/2481 [00:58<11:52,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 198/2481 [00:58<11:20,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 199/2481 [00:58<12:27,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 200/2481 [00:59<12:07,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 200/2481 examples\n",
            "Sample - True: Professional, Predicted: Professional\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:   8%|‚ñä         | 201/2481 [00:59<11:06,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 202/2481 [00:59<13:19,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 203/2481 [01:00<12:19,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 204/2481 [01:00<14:12,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 205/2481 [01:01<14:28,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 206/2481 [01:01<13:09,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 207/2481 [01:01<12:40,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 208/2481 [01:01<11:06,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 209/2481 [01:02<09:59,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   8%|‚ñä         | 210/2481 [01:02<09:14,  4.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 211/2481 [01:02<12:00,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 212/2481 [01:02<11:17,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 213/2481 [01:03<12:24,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 214/2481 [01:03<11:45,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 215/2481 [01:04<12:40,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 216/2481 [01:04<12:52,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñä         | 217/2481 [01:04<13:29,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 218/2481 [01:05<13:28,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 219/2481 [01:05<12:33,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 220/2481 [01:05<13:20,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 221/2481 [01:05<11:36,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 222/2481 [01:06<12:10,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 223/2481 [01:06<11:45,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 224/2481 [01:06<11:15,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 225/2481 [01:07<11:19,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 226/2481 [01:07<13:33,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 227/2481 [01:07<11:41,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 228/2481 [01:08<11:06,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 229/2481 [01:08<11:54,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 230/2481 [01:08<11:18,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 231/2481 [01:09<10:53,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 232/2481 [01:09<09:49,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 233/2481 [01:09<10:57,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 234/2481 [01:09<10:34,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:   9%|‚ñâ         | 235/2481 [01:10<09:37,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 236/2481 [01:10<09:04,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 237/2481 [01:10<11:50,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 238/2481 [01:10<10:28,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 239/2481 [01:11<09:31,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 240/2481 [01:11<09:37,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 241/2481 [01:11<11:02,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 242/2481 [01:12<10:42,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 243/2481 [01:12<13:21,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 244/2481 [01:13<13:53,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 245/2481 [01:13<12:00,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 246/2481 [01:13<12:34,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 247/2481 [01:13<11:11,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñâ         | 248/2481 [01:14<10:05,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 249/2481 [01:14<10:05,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 250/2481 [01:14<10:19,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 251/2481 [01:14<09:23,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 252/2481 [01:15<09:26,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 253/2481 [01:15<09:26,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 254/2481 [01:15<09:47,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 255/2481 [01:15<09:47,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 256/2481 [01:16<10:51,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 257/2481 [01:16<09:49,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 258/2481 [01:16<11:17,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 259/2481 [01:16<10:07,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  10%|‚ñà         | 260/2481 [01:17<10:21,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 261/2481 [01:17<10:32,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 262/2481 [01:17<11:41,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 263/2481 [01:18<12:29,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 264/2481 [01:18<11:43,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 265/2481 [01:18<10:26,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 266/2481 [01:19<09:33,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 267/2481 [01:19<12:07,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 268/2481 [01:19<10:40,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 269/2481 [01:19<09:41,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 270/2481 [01:20<12:25,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 271/2481 [01:20<13:12,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 272/2481 [01:21<12:34,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 273/2481 [01:21<10:58,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 274/2481 [01:21<11:36,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 275/2481 [01:22<12:24,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 276/2481 [01:22<11:39,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 277/2481 [01:22<12:10,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 278/2481 [01:23<12:54,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà         | 279/2481 [01:23<12:02,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 280/2481 [01:23<11:41,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 281/2481 [01:23<11:05,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 282/2481 [01:24<10:44,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 283/2481 [01:24<10:58,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 284/2481 [01:24<12:01,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  11%|‚ñà‚ñè        | 285/2481 [01:25<11:22,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 286/2481 [01:25<13:23,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 287/2481 [01:25<12:15,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 288/2481 [01:26<10:51,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 289/2481 [01:26<13:03,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 290/2481 [01:26<11:16,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 291/2481 [01:27<10:43,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 292/2481 [01:27<12:48,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 293/2481 [01:27<11:50,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 294/2481 [01:28<10:29,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 295/2481 [01:28<12:50,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 296/2481 [01:28<11:08,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 297/2481 [01:29<12:05,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 298/2481 [01:29<10:38,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 299/2481 [01:29<10:38,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 300/2481 [01:29<10:17,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 300/2481 examples\n",
            "Sample - True: Comedy, Predicted: Comedy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  12%|‚ñà‚ñè        | 301/2481 [01:30<09:31,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 302/2481 [01:30<10:37,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 303/2481 [01:30<11:36,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 304/2481 [01:31<10:12,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 305/2481 [01:31<09:18,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 306/2481 [01:31<08:42,  4.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 307/2481 [01:31<08:19,  4.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 308/2481 [01:31<08:40,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 309/2481 [01:32<11:29,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  12%|‚ñà‚ñè        | 310/2481 [01:32<10:12,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 311/2481 [01:32<10:00,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 312/2481 [01:33<10:12,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 313/2481 [01:33<11:02,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 314/2481 [01:33<10:44,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 315/2481 [01:34<10:20,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 316/2481 [01:34<12:41,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 317/2481 [01:34<13:03,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 318/2481 [01:35<11:54,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 319/2481 [01:35<11:10,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 320/2481 [01:35<10:40,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 321/2481 [01:36<12:54,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 322/2481 [01:36<13:24,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 323/2481 [01:36<12:15,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 324/2481 [01:37<12:35,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 325/2481 [01:37<10:58,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 326/2481 [01:37<10:32,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 327/2481 [01:38<11:14,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 328/2481 [01:38<10:02,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 329/2481 [01:38<11:27,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 330/2481 [01:39<13:32,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 331/2481 [01:39<13:30,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 332/2481 [01:39<12:13,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 333/2481 [01:40<11:24,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  13%|‚ñà‚ñé        | 334/2481 [01:40<12:03,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 335/2481 [01:40<10:40,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 336/2481 [01:40<09:40,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 337/2481 [01:41<11:10,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 338/2481 [01:41<11:33,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 339/2481 [01:41<10:50,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 340/2481 [01:42<09:40,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñé        | 341/2481 [01:42<11:06,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 342/2481 [01:42<10:36,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 343/2481 [01:43<12:44,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 344/2481 [01:43<11:03,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 345/2481 [01:43<09:52,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 346/2481 [01:43<09:00,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 347/2481 [01:44<09:24,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 348/2481 [01:44<08:42,  4.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 349/2481 [01:44<09:14,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 350/2481 [01:44<08:34,  4.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 351/2481 [01:45<08:09,  4.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 352/2481 [01:45<08:30,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 353/2481 [01:45<09:46,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 354/2481 [01:45<08:55,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 355/2481 [01:46<08:19,  4.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 356/2481 [01:46<07:57,  4.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 357/2481 [01:46<09:26,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 358/2481 [01:46<09:23,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  14%|‚ñà‚ñç        | 359/2481 [01:47<08:44,  4.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 360/2481 [01:47<10:00,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 361/2481 [01:47<09:48,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 362/2481 [01:48<09:01,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 363/2481 [01:48<09:08,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 364/2481 [01:48<11:41,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 365/2481 [01:49<12:30,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 366/2481 [01:49<12:42,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 367/2481 [01:49<13:04,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 368/2481 [01:50<13:20,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 369/2481 [01:50<13:32,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 370/2481 [01:50<11:34,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 371/2481 [01:51<13:25,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñç        | 372/2481 [01:51<12:11,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 373/2481 [01:52<12:25,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 374/2481 [01:52<12:41,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 375/2481 [01:52<11:36,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 376/2481 [01:53<10:53,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 377/2481 [01:53<09:43,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 378/2481 [01:53<11:11,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 379/2481 [01:54<12:07,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 380/2481 [01:54<11:38,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 381/2481 [01:54<12:25,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 382/2481 [01:55<11:29,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 383/2481 [01:55<11:52,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  15%|‚ñà‚ñå        | 384/2481 [01:55<13:25,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 385/2481 [01:56<11:27,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 386/2481 [01:56<12:08,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 387/2481 [01:56<12:46,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 388/2481 [01:57<11:07,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 389/2481 [01:57<11:33,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 390/2481 [01:57<12:17,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 391/2481 [01:58<12:25,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 392/2481 [01:58<12:34,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 393/2481 [01:58<12:53,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 394/2481 [01:59<11:49,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 395/2481 [01:59<11:02,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 396/2481 [01:59<10:36,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 397/2481 [02:00<10:22,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 398/2481 [02:00<10:23,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 399/2481 [02:00<10:02,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 400/2481 [02:00<09:50,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 400/2481 examples\n",
            "Sample - True: Comedy, Predicted: Comedy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  16%|‚ñà‚ñå        | 401/2481 [02:01<13:06,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 402/2481 [02:01<13:12,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñå        | 403/2481 [02:02<11:20,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 404/2481 [02:02<13:10,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 405/2481 [02:02<11:22,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 406/2481 [02:03<10:40,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 407/2481 [02:03<09:31,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 408/2481 [02:03<08:45,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  16%|‚ñà‚ñã        | 409/2481 [02:03<10:23,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 410/2481 [02:04<10:26,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 411/2481 [02:04<12:45,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 412/2481 [02:04<11:03,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 413/2481 [02:05<09:47,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 414/2481 [02:05<09:34,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 415/2481 [02:05<10:28,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 416/2481 [02:06<11:22,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 417/2481 [02:06<10:02,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 418/2481 [02:06<10:05,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 419/2481 [02:06<09:07,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 420/2481 [02:07<10:32,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 421/2481 [02:07<09:26,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 422/2481 [02:07<11:38,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 423/2481 [02:08<12:12,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 424/2481 [02:08<11:37,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 425/2481 [02:08<10:49,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 426/2481 [02:09<09:36,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 427/2481 [02:09<09:27,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 428/2481 [02:09<09:35,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 429/2481 [02:09<08:43,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 430/2481 [02:10<08:05,  4.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 431/2481 [02:10<09:42,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 432/2481 [02:10<10:55,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 433/2481 [02:11<12:37,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  17%|‚ñà‚ñã        | 434/2481 [02:11<11:33,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 435/2481 [02:11<10:12,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 436/2481 [02:12<12:10,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 437/2481 [02:12<11:14,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 438/2481 [02:12<11:51,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 439/2481 [02:13<13:22,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 440/2481 [02:13<14:21,  2.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 441/2481 [02:14<12:49,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 442/2481 [02:14<12:44,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 443/2481 [02:14<11:35,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 444/2481 [02:15<10:52,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 445/2481 [02:15<12:37,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 446/2481 [02:15<10:51,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 447/2481 [02:15<09:37,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 448/2481 [02:16<09:29,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 449/2481 [02:16<09:41,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 450/2481 [02:16<10:48,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 451/2481 [02:17<10:15,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 452/2481 [02:17<10:21,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 453/2481 [02:17<11:15,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 454/2481 [02:18<10:04,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 455/2481 [02:18<09:04,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 456/2481 [02:18<09:22,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 457/2481 [02:18<09:15,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  18%|‚ñà‚ñä        | 458/2481 [02:19<10:33,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 459/2481 [02:19<10:24,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 460/2481 [02:19<09:54,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 461/2481 [02:20<09:32,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 462/2481 [02:20<08:41,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 463/2481 [02:20<09:03,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 464/2481 [02:20<08:57,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñä        | 465/2481 [02:21<08:57,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 466/2481 [02:21<11:20,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 467/2481 [02:21<10:35,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 468/2481 [02:22<09:26,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 469/2481 [02:22<09:18,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 470/2481 [02:22<09:25,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 471/2481 [02:22<08:34,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 472/2481 [02:23<08:01,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 473/2481 [02:23<07:37,  4.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 474/2481 [02:23<08:19,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 475/2481 [02:23<07:48,  4.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 476/2481 [02:23<07:24,  4.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 477/2481 [02:24<07:10,  4.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 478/2481 [02:24<07:06,  4.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 479/2481 [02:24<06:59,  4.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 480/2481 [02:24<07:30,  4.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 481/2481 [02:25<07:16,  4.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 482/2481 [02:25<08:03,  4.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  19%|‚ñà‚ñâ        | 483/2481 [02:25<07:40,  4.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 484/2481 [02:25<09:26,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 485/2481 [02:26<09:34,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 486/2481 [02:26<09:44,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 487/2481 [02:26<08:48,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 488/2481 [02:26<08:08,  4.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 489/2481 [02:27<08:17,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 490/2481 [02:27<09:50,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 491/2481 [02:27<09:41,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 492/2481 [02:28<08:53,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 493/2481 [02:28<09:17,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 494/2481 [02:28<09:10,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 495/2481 [02:29<11:23,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñâ        | 496/2481 [02:29<10:04,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 497/2481 [02:29<10:44,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 498/2481 [02:30<10:13,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 499/2481 [02:30<12:10,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 500/2481 [02:30<12:30,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 500/2481 examples\n",
            "Sample - True: Education, Predicted: to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  20%|‚ñà‚ñà        | 501/2481 [02:31<12:42,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 502/2481 [02:31<12:37,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 503/2481 [02:32<12:49,  2.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 504/2481 [02:32<12:34,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 505/2481 [02:32<10:46,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 506/2481 [02:33<11:26,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 507/2481 [02:33<10:38,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  20%|‚ñà‚ñà        | 508/2481 [02:33<11:03,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 509/2481 [02:34<11:41,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 510/2481 [02:34<13:08,  2.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 511/2481 [02:35<13:10,  2.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 512/2481 [02:35<12:05,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 513/2481 [02:35<12:01,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 514/2481 [02:35<11:01,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 515/2481 [02:36<11:40,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 516/2481 [02:36<13:02,  2.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 517/2481 [02:37<13:00,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 518/2481 [02:37<12:44,  2.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 519/2481 [02:37<10:52,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 520/2481 [02:38<10:07,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 521/2481 [02:38<09:41,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 522/2481 [02:38<09:24,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 523/2481 [02:39<10:28,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 524/2481 [02:39<10:14,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 525/2481 [02:39<09:10,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 526/2481 [02:39<08:24,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà        | 527/2481 [02:40<10:46,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 528/2481 [02:40<09:33,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 529/2481 [02:40<08:42,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 530/2481 [02:41<10:00,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 531/2481 [02:41<11:49,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 532/2481 [02:41<10:10,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  21%|‚ñà‚ñà‚ñè       | 533/2481 [02:41<09:06,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 534/2481 [02:42<09:18,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 535/2481 [02:42<09:15,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 536/2481 [02:42<08:27,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 537/2481 [02:42<08:33,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 538/2481 [02:43<10:45,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 539/2481 [02:43<11:24,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 540/2481 [02:44<10:51,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 541/2481 [02:44<10:12,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 542/2481 [02:44<09:43,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 543/2481 [02:44<09:22,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 544/2481 [02:45<12:13,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 545/2481 [02:45<12:24,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 546/2481 [02:46<10:36,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 547/2481 [02:46<10:09,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 548/2481 [02:46<10:35,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 549/2481 [02:47<11:15,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 550/2481 [02:47<11:22,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 551/2481 [02:47<09:54,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 552/2481 [02:47<08:51,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 553/2481 [02:48<10:07,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 554/2481 [02:48<10:38,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 555/2481 [02:48<09:21,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 556/2481 [02:49<08:29,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 557/2481 [02:49<08:37,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  22%|‚ñà‚ñà‚ñè       | 558/2481 [02:49<09:27,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 559/2481 [02:50<09:09,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 560/2481 [02:50<08:54,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 561/2481 [02:50<09:39,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 562/2481 [02:50<09:14,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 563/2481 [02:51<08:20,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 564/2481 [02:51<08:23,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 565/2481 [02:51<09:17,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 566/2481 [02:51<09:02,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 567/2481 [02:52<08:50,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 568/2481 [02:52<11:05,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 569/2481 [02:53<10:23,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 570/2481 [02:53<09:51,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 571/2481 [02:53<10:24,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 572/2481 [02:54<11:08,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 573/2481 [02:54<10:26,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 574/2481 [02:54<10:15,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 575/2481 [02:54<09:06,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 576/2481 [02:55<08:16,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 577/2481 [02:55<08:18,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 578/2481 [02:55<10:29,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 579/2481 [02:56<09:12,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 580/2481 [02:56<08:54,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 581/2481 [02:56<08:48,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 582/2481 [02:56<08:04,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  23%|‚ñà‚ñà‚ñé       | 583/2481 [02:57<09:04,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 584/2481 [02:57<08:14,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 585/2481 [02:57<08:27,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 586/2481 [02:58<09:44,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 587/2481 [02:58<10:12,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 588/2481 [02:58<10:57,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñé       | 589/2481 [02:59<12:19,  2.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 590/2481 [02:59<12:24,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 591/2481 [03:00<13:17,  2.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 592/2481 [03:00<11:10,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 593/2481 [03:00<11:43,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 594/2481 [03:00<10:04,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 595/2481 [03:01<10:24,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 596/2481 [03:01<10:38,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 597/2481 [03:02<11:10,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 598/2481 [03:02<10:22,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 599/2481 [03:02<10:11,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 600/2481 [03:03<10:54,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 601/2481 [03:03<09:29,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 600/2481 examples\n",
            "Sample - True: Professional, Predicted: the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 602/2481 [03:03<11:23,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 603/2481 [03:04<11:44,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 604/2481 [03:04<10:07,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 605/2481 [03:04<10:31,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 606/2481 [03:04<09:47,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  24%|‚ñà‚ñà‚ñç       | 607/2481 [03:05<08:39,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 608/2481 [03:05<08:33,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 609/2481 [03:05<07:54,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 610/2481 [03:05<08:08,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 611/2481 [03:06<08:29,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 612/2481 [03:06<09:50,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 613/2481 [03:06<08:47,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 614/2481 [03:07<11:51,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 615/2481 [03:07<10:48,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 616/2481 [03:08<11:29,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 617/2481 [03:08<11:37,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 618/2481 [03:08<11:48,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 619/2481 [03:09<10:02,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñç       | 620/2481 [03:09<09:29,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 621/2481 [03:09<09:05,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 622/2481 [03:10<11:01,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 623/2481 [03:10<09:35,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 624/2481 [03:10<09:11,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 625/2481 [03:10<08:54,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 626/2481 [03:11<10:59,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 627/2481 [03:11<09:32,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 628/2481 [03:11<09:06,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 629/2481 [03:12<10:59,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 630/2481 [03:12<09:37,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 631/2481 [03:12<09:12,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  25%|‚ñà‚ñà‚ñå       | 632/2481 [03:13<09:09,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 633/2481 [03:13<10:07,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 634/2481 [03:13<10:48,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 635/2481 [03:14<10:18,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 636/2481 [03:14<09:04,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 637/2481 [03:14<08:15,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 638/2481 [03:14<07:39,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 639/2481 [03:15<09:57,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 640/2481 [03:15<09:27,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 641/2481 [03:16<11:06,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 642/2481 [03:16<09:37,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 643/2481 [03:16<09:26,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 644/2481 [03:16<08:25,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 645/2481 [03:17<07:43,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 646/2481 [03:17<07:49,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 647/2481 [03:17<08:51,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 648/2481 [03:18<09:51,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 649/2481 [03:18<09:19,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 650/2481 [03:18<09:22,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñå       | 651/2481 [03:18<08:26,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 652/2481 [03:19<07:48,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 653/2481 [03:19<07:55,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 654/2481 [03:19<08:51,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 655/2481 [03:20<09:53,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 656/2481 [03:20<08:43,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  26%|‚ñà‚ñà‚ñã       | 657/2481 [03:20<09:26,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 658/2481 [03:21<10:17,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 659/2481 [03:21<09:35,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 660/2481 [03:21<09:30,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 661/2481 [03:21<09:00,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 662/2481 [03:22<09:51,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 663/2481 [03:22<08:46,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 664/2481 [03:22<08:02,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 665/2481 [03:22<07:26,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 666/2481 [03:23<07:55,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 667/2481 [03:23<09:07,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 668/2481 [03:23<08:47,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 669/2481 [03:24<07:59,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 670/2481 [03:24<08:52,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 671/2481 [03:24<08:37,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 672/2481 [03:24<07:51,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 673/2481 [03:25<08:52,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 674/2481 [03:25<09:50,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 675/2481 [03:26<11:32,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 676/2481 [03:26<09:54,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 677/2481 [03:26<08:44,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 678/2481 [03:26<08:29,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 679/2481 [03:27<10:20,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 680/2481 [03:27<09:37,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 681/2481 [03:27<08:32,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  27%|‚ñà‚ñà‚ñã       | 682/2481 [03:28<09:14,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 683/2481 [03:28<08:52,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 684/2481 [03:28<09:24,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 685/2481 [03:29<08:55,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 686/2481 [03:29<09:51,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 687/2481 [03:29<10:06,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 688/2481 [03:30<10:38,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 689/2481 [03:30<10:40,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 690/2481 [03:30<09:49,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 691/2481 [03:31<09:17,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 692/2481 [03:31<08:53,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 693/2481 [03:31<09:32,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 694/2481 [03:32<10:14,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 695/2481 [03:32<11:41,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 696/2481 [03:32<10:01,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 697/2481 [03:33<10:38,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 698/2481 [03:33<10:44,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 699/2481 [03:33<09:53,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 700/2481 [03:34<09:23,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 700/2481 examples\n",
            "Sample - True: Comedy, Predicted: Comedy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 701/2481 [03:34<09:22,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 702/2481 [03:34<08:19,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 703/2481 [03:34<07:33,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 704/2481 [03:35<07:37,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 705/2481 [03:35<07:42,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 706/2481 [03:35<07:11,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  28%|‚ñà‚ñà‚ñä       | 707/2481 [03:35<06:49,  4.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 708/2481 [03:36<08:00,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 709/2481 [03:36<08:01,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 710/2481 [03:36<08:11,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 711/2481 [03:36<07:29,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 712/2481 [03:37<06:58,  4.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñä       | 713/2481 [03:37<07:11,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 714/2481 [03:37<09:23,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 715/2481 [03:38<10:03,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 716/2481 [03:38<10:12,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 717/2481 [03:38<08:52,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 718/2481 [03:39<07:56,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 719/2481 [03:39<07:52,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 720/2481 [03:39<08:08,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 721/2481 [03:39<07:26,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 722/2481 [03:39<06:57,  4.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 723/2481 [03:40<07:13,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 724/2481 [03:40<09:18,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 725/2481 [03:40<08:44,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 726/2481 [03:41<09:33,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 727/2481 [03:41<10:10,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 728/2481 [03:42<10:16,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 729/2481 [03:42<10:52,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 730/2481 [03:42<09:54,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  29%|‚ñà‚ñà‚ñâ       | 731/2481 [03:43<11:13,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 732/2481 [03:43<10:26,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 733/2481 [03:43<09:05,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 734/2481 [03:44<09:32,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 735/2481 [03:44<08:34,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 736/2481 [03:44<07:46,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 737/2481 [03:44<07:45,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 738/2481 [03:45<09:58,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 739/2481 [03:45<10:33,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 740/2481 [03:46<09:10,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 741/2481 [03:46<09:02,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 742/2481 [03:46<08:40,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 743/2481 [03:46<09:32,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñâ       | 744/2481 [03:47<09:54,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 745/2481 [03:47<09:13,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 746/2481 [03:48<09:52,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 747/2481 [03:48<09:27,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 748/2481 [03:48<08:55,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 749/2481 [03:48<07:58,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 750/2481 [03:49<09:54,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 751/2481 [03:49<10:11,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 752/2481 [03:50<10:38,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 753/2481 [03:50<11:43,  2.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 754/2481 [03:50<09:55,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 755/2481 [03:51<09:11,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  30%|‚ñà‚ñà‚ñà       | 756/2481 [03:51<08:44,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 757/2481 [03:51<08:40,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 758/2481 [03:51<08:19,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 759/2481 [03:52<07:31,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 760/2481 [03:52<09:35,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 761/2481 [03:52<08:24,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 762/2481 [03:52<08:07,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 763/2481 [03:53<09:55,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 764/2481 [03:53<08:38,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 765/2481 [03:53<08:17,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 766/2481 [03:54<08:01,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 767/2481 [03:54<07:21,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 768/2481 [03:54<08:11,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 769/2481 [03:55<07:57,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 770/2481 [03:55<09:03,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 771/2481 [03:55<08:49,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 772/2481 [03:56<09:29,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 773/2481 [03:56<08:54,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 774/2481 [03:56<10:30,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà       | 775/2481 [03:57<09:37,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 776/2481 [03:57<11:00,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 777/2481 [03:57<09:59,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 778/2481 [03:58<09:17,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 779/2481 [03:58<09:37,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 780/2481 [03:58<08:56,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  31%|‚ñà‚ñà‚ñà‚ñè      | 781/2481 [03:59<07:57,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 782/2481 [03:59<07:17,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 783/2481 [03:59<08:10,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 784/2481 [03:59<07:22,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 785/2481 [04:00<07:23,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 786/2481 [04:00<08:30,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 787/2481 [04:00<08:14,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 788/2481 [04:00<08:06,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 789/2481 [04:01<08:10,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 790/2481 [04:01<09:05,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 791/2481 [04:01<08:35,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 792/2481 [04:02<08:32,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 793/2481 [04:02<07:42,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 794/2481 [04:02<07:47,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 795/2481 [04:02<07:08,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 796/2481 [04:03<07:33,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 797/2481 [04:03<07:31,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 798/2481 [04:03<08:34,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 799/2481 [04:04<09:02,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 800/2481 [04:04<09:46,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 800/2481 examples\n",
            "Sample - True: Education, Predicted: 't\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 801/2481 [04:05<11:02,  2.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 802/2481 [04:05<09:23,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 803/2481 [04:05<09:57,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 804/2481 [04:05<08:37,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 805/2481 [04:06<10:16,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  32%|‚ñà‚ñà‚ñà‚ñè      | 806/2481 [04:06<08:51,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 807/2481 [04:06<08:23,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 808/2481 [04:07<09:58,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 809/2481 [04:07<09:28,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 810/2481 [04:07<08:52,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 811/2481 [04:08<07:55,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 812/2481 [04:08<07:14,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 813/2481 [04:08<08:07,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 814/2481 [04:08<07:23,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 815/2481 [04:09<07:29,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 816/2481 [04:09<08:22,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 817/2481 [04:09<07:34,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 818/2481 [04:10<07:32,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 819/2481 [04:10<09:26,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 820/2481 [04:11<10:03,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 821/2481 [04:11<09:18,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 822/2481 [04:11<09:36,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 823/2481 [04:12<10:02,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 824/2481 [04:12<08:38,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 825/2481 [04:12<07:46,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 826/2481 [04:12<07:38,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 827/2481 [04:13<07:32,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 828/2481 [04:13<07:48,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 829/2481 [04:13<07:06,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 830/2481 [04:13<07:08,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  33%|‚ñà‚ñà‚ñà‚ñé      | 831/2481 [04:14<07:10,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 832/2481 [04:14<07:58,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 833/2481 [04:14<07:46,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 834/2481 [04:14<07:45,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 835/2481 [04:15<07:51,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 836/2481 [04:15<07:39,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñé      | 837/2481 [04:15<08:33,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 838/2481 [04:16<08:54,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 839/2481 [04:16<07:51,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 840/2481 [04:16<07:09,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 841/2481 [04:17<09:05,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 842/2481 [04:17<09:23,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 843/2481 [04:17<08:10,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 844/2481 [04:18<08:53,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 845/2481 [04:18<07:51,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 846/2481 [04:18<09:44,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 847/2481 [04:19<09:00,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 848/2481 [04:19<08:26,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 849/2481 [04:19<09:56,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 850/2481 [04:20<10:11,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 851/2481 [04:20<11:08,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 852/2481 [04:21<10:58,  2.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 853/2481 [04:21<09:56,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 854/2481 [04:21<09:24,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  34%|‚ñà‚ñà‚ñà‚ñç      | 855/2481 [04:22<09:51,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 856/2481 [04:22<08:34,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 857/2481 [04:22<08:34,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 858/2481 [04:22<07:38,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 859/2481 [04:23<07:31,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 860/2481 [04:23<06:53,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 861/2481 [04:23<07:15,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 862/2481 [04:23<06:41,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 863/2481 [04:24<06:49,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 864/2481 [04:24<08:55,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 865/2481 [04:24<07:50,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 866/2481 [04:25<07:34,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 867/2481 [04:25<07:26,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñç      | 868/2481 [04:25<07:23,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 869/2481 [04:25<07:18,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 870/2481 [04:26<06:44,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 871/2481 [04:26<07:06,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 872/2481 [04:26<06:36,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 873/2481 [04:26<06:43,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 874/2481 [04:27<07:05,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 875/2481 [04:27<06:36,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 876/2481 [04:27<07:02,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 877/2481 [04:27<08:05,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 878/2481 [04:28<07:44,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 879/2481 [04:28<08:19,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  35%|‚ñà‚ñà‚ñà‚ñå      | 880/2481 [04:28<07:23,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 881/2481 [04:29<07:13,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 882/2481 [04:29<07:16,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 883/2481 [04:29<06:41,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 884/2481 [04:29<07:55,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 885/2481 [04:30<08:24,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 886/2481 [04:30<07:59,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 887/2481 [04:30<07:11,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 888/2481 [04:31<08:57,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 889/2481 [04:31<08:23,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 890/2481 [04:31<09:01,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 891/2481 [04:32<08:41,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 892/2481 [04:32<07:41,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 893/2481 [04:32<08:31,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 894/2481 [04:33<07:56,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 895/2481 [04:33<08:03,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 896/2481 [04:33<07:43,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 897/2481 [04:33<07:28,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 898/2481 [04:34<09:09,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñå      | 899/2481 [04:34<09:41,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 900/2481 [04:35<10:43,  2.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 900/2481 examples\n",
            "Sample - True: Professional, Predicted: like\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 901/2481 [04:35<09:05,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 902/2481 [04:35<08:27,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 903/2481 [04:36<09:47,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 904/2481 [04:36<08:27,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  36%|‚ñà‚ñà‚ñà‚ñã      | 905/2481 [04:36<08:05,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 906/2481 [04:36<07:15,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 907/2481 [04:37<07:57,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 908/2481 [04:37<07:56,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 909/2481 [04:37<07:10,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 910/2481 [04:38<06:37,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 911/2481 [04:38<06:44,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 912/2481 [04:38<08:35,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 913/2481 [04:39<07:36,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 914/2481 [04:39<08:30,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 915/2481 [04:39<08:16,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 916/2481 [04:39<07:21,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 917/2481 [04:40<08:16,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 918/2481 [04:40<08:06,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 919/2481 [04:40<07:43,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 920/2481 [04:41<06:57,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 921/2481 [04:41<06:25,  4.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 922/2481 [04:41<07:18,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 923/2481 [04:41<06:37,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 924/2481 [04:42<06:38,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 925/2481 [04:42<06:09,  4.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 926/2481 [04:42<05:52,  4.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 927/2481 [04:42<06:13,  4.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 928/2481 [04:43<06:27,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 929/2481 [04:43<06:46,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  37%|‚ñà‚ñà‚ñà‚ñã      | 930/2481 [04:43<07:48,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 931/2481 [04:43<07:00,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 932/2481 [04:44<07:08,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 933/2481 [04:44<08:05,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 934/2481 [04:44<07:12,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 935/2481 [04:45<06:35,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 936/2481 [04:45<07:22,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 937/2481 [04:45<07:26,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 938/2481 [04:45<07:14,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 939/2481 [04:46<07:08,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 940/2481 [04:46<06:32,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 941/2481 [04:46<06:50,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 942/2481 [04:46<06:18,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 943/2481 [04:47<07:26,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 944/2481 [04:47<08:06,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 945/2481 [04:47<07:43,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 946/2481 [04:48<07:25,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 947/2481 [04:48<07:59,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 948/2481 [04:48<07:07,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 949/2481 [04:48<06:30,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 950/2481 [04:49<06:04,  4.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 951/2481 [04:49<05:49,  4.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 952/2481 [04:49<06:17,  4.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 953/2481 [04:49<06:26,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 954/2481 [04:50<06:53,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  38%|‚ñà‚ñà‚ñà‚ñä      | 955/2481 [04:50<07:58,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 956/2481 [04:50<07:36,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 957/2481 [04:51<09:03,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 958/2481 [04:51<08:21,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 959/2481 [04:52<09:38,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 960/2481 [04:52<09:45,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñä      | 961/2481 [04:52<08:23,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 962/2481 [04:53<08:35,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 963/2481 [04:53<09:05,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 964/2481 [04:53<09:23,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 965/2481 [04:54<09:16,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 966/2481 [04:54<09:33,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 967/2481 [04:54<08:11,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 968/2481 [04:55<09:27,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 969/2481 [04:55<08:50,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 970/2481 [04:55<07:41,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 971/2481 [04:56<08:28,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 972/2481 [04:56<08:12,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 973/2481 [04:56<07:14,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 974/2481 [04:57<07:03,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 975/2481 [04:57<06:55,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 976/2481 [04:57<07:06,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 977/2481 [04:57<06:29,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 978/2481 [04:58<06:32,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  39%|‚ñà‚ñà‚ñà‚ñâ      | 979/2481 [04:58<06:06,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 980/2481 [04:58<07:00,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 981/2481 [04:59<07:50,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 982/2481 [04:59<07:01,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 983/2481 [04:59<07:39,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 984/2481 [04:59<07:18,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 985/2481 [05:00<06:35,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 986/2481 [05:00<06:06,  4.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 987/2481 [05:00<06:32,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 988/2481 [05:00<06:31,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 989/2481 [05:01<06:02,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 990/2481 [05:01<06:15,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 991/2481 [05:01<07:01,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñâ      | 992/2481 [05:02<07:47,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 993/2481 [05:02<09:17,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 994/2481 [05:02<07:58,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 995/2481 [05:02<07:06,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 996/2481 [05:03<06:26,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 997/2481 [05:03<06:29,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 998/2481 [05:03<06:48,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 999/2481 [05:04<07:44,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 1000/2481 [05:04<06:54,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1000/2481 examples\n",
            "Sample - True: Travel, Predicted: Travel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 1001/2481 [05:04<07:01,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 1002/2481 [05:05<07:49,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 1003/2481 [05:05<09:09,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  40%|‚ñà‚ñà‚ñà‚ñà      | 1004/2481 [05:05<08:20,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1005/2481 [05:06<07:19,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1006/2481 [05:06<06:36,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1007/2481 [05:06<08:19,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1008/2481 [05:06<07:17,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1009/2481 [05:07<07:06,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1010/2481 [05:07<07:37,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1011/2481 [05:07<07:14,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1012/2481 [05:07<06:30,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1013/2481 [05:08<06:29,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1014/2481 [05:08<06:33,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1015/2481 [05:08<06:04,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1016/2481 [05:09<07:53,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1017/2481 [05:09<06:59,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1018/2481 [05:09<06:21,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1019/2481 [05:09<05:54,  4.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1020/2481 [05:10<06:24,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1021/2481 [05:10<07:22,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1022/2481 [05:10<07:04,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà      | 1023/2481 [05:11<06:25,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1024/2481 [05:11<07:10,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1025/2481 [05:11<07:11,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1026/2481 [05:11<06:56,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1027/2481 [05:12<06:18,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1028/2481 [05:12<06:22,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1029/2481 [05:12<07:03,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1030/2481 [05:13<06:53,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1031/2481 [05:13<08:31,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1032/2481 [05:13<08:50,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1033/2481 [05:14<09:05,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1034/2481 [05:14<09:01,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1035/2481 [05:15<09:12,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1036/2481 [05:15<07:53,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1037/2481 [05:15<08:07,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1038/2481 [05:15<07:34,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1039/2481 [05:16<07:12,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1040/2481 [05:16<07:36,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1041/2481 [05:16<08:07,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1042/2481 [05:17<07:32,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1043/2481 [05:17<07:52,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1044/2481 [05:17<07:20,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1045/2481 [05:18<07:54,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1046/2481 [05:18<08:13,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1047/2481 [05:18<07:09,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1048/2481 [05:18<06:25,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1049/2481 [05:19<05:56,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1050/2481 [05:19<07:43,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1051/2481 [05:20<08:16,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1052/2481 [05:20<07:12,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1053/2481 [05:20<07:42,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1054/2481 [05:20<07:16,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1055/2481 [05:21<06:32,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1056/2481 [05:21<06:03,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1057/2481 [05:21<07:44,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1058/2481 [05:22<06:46,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1059/2481 [05:22<06:33,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1060/2481 [05:22<06:27,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1061/2481 [05:22<07:16,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1062/2481 [05:23<08:33,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1063/2481 [05:23<08:48,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1064/2481 [05:24<09:39,  2.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1065/2481 [05:24<08:41,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1066/2481 [05:24<07:29,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1067/2481 [05:25<08:44,  2.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1068/2481 [05:25<07:59,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1069/2481 [05:25<07:34,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1070/2481 [05:26<08:48,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1071/2481 [05:26<09:43,  2.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1072/2481 [05:27<08:42,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1073/2481 [05:27<07:30,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1074/2481 [05:27<07:20,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1075/2481 [05:27<07:00,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1076/2481 [05:28<06:48,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1077/2481 [05:28<08:22,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1078/2481 [05:28<07:12,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1079/2481 [05:29<07:44,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1080/2481 [05:29<06:47,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1081/2481 [05:29<06:35,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1082/2481 [05:29<06:26,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1083/2481 [05:30<07:03,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1084/2481 [05:30<06:21,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1085/2481 [05:30<06:18,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1086/2481 [05:31<06:29,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1087/2481 [05:31<05:55,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1088/2481 [05:31<06:12,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1089/2481 [05:31<06:06,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1090/2481 [05:32<06:05,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1091/2481 [05:32<05:37,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1092/2481 [05:32<07:23,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1093/2481 [05:32<06:32,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1094/2481 [05:33<07:18,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1095/2481 [05:33<06:35,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1096/2481 [05:33<06:03,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1097/2481 [05:33<05:39,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1098/2481 [05:34<06:01,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1099/2481 [05:34<05:36,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1100/2481 [05:34<05:43,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1100/2481 examples\n",
            "Sample - True: Entertainment, Predicted: Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1101/2481 [05:35<05:49,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1102/2481 [05:35<06:07,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1103/2481 [05:35<06:06,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1104/2481 [05:35<05:39,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1105/2481 [05:36<07:21,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1106/2481 [05:36<06:30,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1107/2481 [05:36<06:21,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1108/2481 [05:36<05:48,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1109/2481 [05:37<06:06,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1110/2481 [05:37<07:00,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1111/2481 [05:38<07:38,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1112/2481 [05:38<07:23,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1113/2481 [05:38<07:02,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1114/2481 [05:38<06:19,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1115/2481 [05:39<07:51,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1116/2481 [05:39<08:12,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1117/2481 [05:39<07:33,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1118/2481 [05:40<07:16,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1119/2481 [05:40<06:55,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1120/2481 [05:40<06:15,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1121/2481 [05:40<05:44,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1122/2481 [05:41<06:04,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1123/2481 [05:41<05:36,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1124/2481 [05:41<05:17,  4.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1125/2481 [05:41<05:04,  4.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1126/2481 [05:42<06:59,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1127/2481 [05:42<06:18,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1128/2481 [05:42<06:11,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1129/2481 [05:43<07:40,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1130/2481 [05:43<06:43,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1131/2481 [05:43<06:30,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1132/2481 [05:43<05:55,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1133/2481 [05:44<06:35,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1134/2481 [05:44<07:55,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1135/2481 [05:45<08:16,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1136/2481 [05:45<07:45,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1137/2481 [05:45<07:11,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1138/2481 [05:46<06:22,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1139/2481 [05:46<05:47,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1140/2481 [05:46<06:29,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1141/2481 [05:46<05:53,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1142/2481 [05:47<05:52,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1143/2481 [05:47<05:52,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1144/2481 [05:47<06:05,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1145/2481 [05:47<05:35,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1146/2481 [05:47<05:12,  4.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1147/2481 [05:48<06:59,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1148/2481 [05:48<06:11,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1149/2481 [05:48<05:37,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1150/2481 [05:49<05:39,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1151/2481 [05:49<05:46,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1152/2481 [05:49<06:41,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1153/2481 [05:50<06:42,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1154/2481 [05:50<06:01,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1155/2481 [05:50<06:49,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1156/2481 [05:50<06:30,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1157/2481 [05:51<07:51,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1158/2481 [05:51<06:49,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1159/2481 [05:51<06:05,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1160/2481 [05:52<06:14,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1161/2481 [05:52<07:01,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1162/2481 [05:52<06:41,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1163/2481 [05:53<06:37,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1164/2481 [05:53<05:59,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1165/2481 [05:53<05:37,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1166/2481 [05:53<06:36,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1167/2481 [05:54<07:00,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1168/2481 [05:54<06:17,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1169/2481 [05:54<05:45,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1170/2481 [05:54<05:23,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1171/2481 [05:55<06:06,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1172/2481 [05:55<06:01,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1173/2481 [05:55<05:58,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1174/2481 [05:56<06:08,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1175/2481 [05:56<05:36,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1176/2481 [05:56<05:51,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1177/2481 [05:56<05:26,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1178/2481 [05:57<06:25,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1179/2481 [05:57<06:24,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1180/2481 [05:57<06:14,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1181/2481 [05:58<05:39,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1182/2481 [05:58<05:40,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1183/2481 [05:58<05:58,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1184/2481 [05:58<05:55,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1185/2481 [05:59<05:53,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1186/2481 [05:59<07:19,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1187/2481 [05:59<06:25,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1188/2481 [06:00<05:47,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1189/2481 [06:00<05:45,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1190/2481 [06:00<06:21,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1191/2481 [06:00<05:42,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1192/2481 [06:01<05:13,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1193/2481 [06:01<06:11,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1194/2481 [06:01<06:02,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1195/2481 [06:01<05:56,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1196/2481 [06:02<06:25,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1197/2481 [06:02<05:47,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1198/2481 [06:02<05:44,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1199/2481 [06:03<06:18,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1200/2481 [06:03<06:07,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1200/2481 examples\n",
            "Sample - True: Entertainment, Predicted: Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1201/2481 [06:03<06:51,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1202/2481 [06:04<07:14,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1203/2481 [06:04<06:47,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1204/2481 [06:04<06:02,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1205/2481 [06:04<05:29,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1206/2481 [06:05<05:43,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1207/2481 [06:05<06:34,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1208/2481 [06:05<05:52,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1209/2481 [06:05<05:26,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1210/2481 [06:06<06:07,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1211/2481 [06:06<06:00,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1212/2481 [06:06<05:52,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1213/2481 [06:07<06:00,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1214/2481 [06:07<05:30,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1215/2481 [06:07<06:21,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1216/2481 [06:08<06:46,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1217/2481 [06:08<06:00,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1218/2481 [06:08<06:47,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1219/2481 [06:09<07:00,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1220/2481 [06:09<07:26,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1221/2481 [06:09<06:30,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1222/2481 [06:10<06:15,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1223/2481 [06:10<07:30,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1224/2481 [06:10<06:54,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1225/2481 [06:10<06:04,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1226/2481 [06:11<06:07,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1227/2481 [06:11<06:46,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1228/2481 [06:11<06:24,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1229/2481 [06:12<07:36,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1230/2481 [06:12<07:37,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1231/2481 [06:13<07:00,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1232/2481 [06:13<06:09,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1233/2481 [06:13<06:10,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1234/2481 [06:13<05:34,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1235/2481 [06:14<06:25,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1236/2481 [06:14<07:36,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1237/2481 [06:14<07:01,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1238/2481 [06:15<06:36,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1239/2481 [06:15<06:51,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1240/2481 [06:16<09:08,  2.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1241/2481 [06:16<08:05,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1242/2481 [06:16<06:58,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1243/2481 [06:16<06:05,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1244/2481 [06:17<07:19,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1245/2481 [06:17<06:29,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1246/2481 [06:17<05:49,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1247/2481 [06:18<07:14,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1248/2481 [06:18<06:18,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1249/2481 [06:19<06:54,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1250/2481 [06:19<07:55,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1251/2481 [06:19<06:47,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1252/2481 [06:19<06:25,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1253/2481 [06:20<06:43,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1254/2481 [06:20<05:57,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1255/2481 [06:20<05:49,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1256/2481 [06:21<07:10,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1257/2481 [06:21<07:28,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1258/2481 [06:21<06:51,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1259/2481 [06:22<07:00,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1260/2481 [06:22<07:05,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1261/2481 [06:22<06:33,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1262/2481 [06:23<05:48,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1263/2481 [06:23<05:17,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1264/2481 [06:23<06:42,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1265/2481 [06:24<06:19,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1266/2481 [06:24<05:39,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1267/2481 [06:24<06:11,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1268/2481 [06:24<05:33,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1269/2481 [06:25<05:34,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1270/2481 [06:25<06:09,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1271/2481 [06:25<05:33,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1272/2481 [06:26<05:30,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1273/2481 [06:26<05:04,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1274/2481 [06:26<05:45,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1275/2481 [06:27<06:26,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1276/2481 [06:27<05:45,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1277/2481 [06:27<05:18,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1278/2481 [06:27<06:41,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1279/2481 [06:28<05:58,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1280/2481 [06:28<05:46,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1281/2481 [06:28<07:02,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1282/2481 [06:29<06:09,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1283/2481 [06:29<05:32,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1284/2481 [06:29<06:07,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1285/2481 [06:29<05:52,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1286/2481 [06:30<05:20,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1287/2481 [06:30<05:32,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1288/2481 [06:30<05:27,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1289/2481 [06:31<05:23,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1290/2481 [06:31<04:57,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1291/2481 [06:31<04:41,  4.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1292/2481 [06:31<04:33,  4.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1293/2481 [06:31<04:23,  4.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1294/2481 [06:32<06:00,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1295/2481 [06:32<05:23,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1296/2481 [06:32<05:20,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1297/2481 [06:32<04:55,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1298/2481 [06:33<05:10,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1299/2481 [06:33<05:23,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1300/2481 [06:33<06:04,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1300/2481 examples\n",
            "Sample - True: Education, Predicted: shoes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1301/2481 [06:34<06:32,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1302/2481 [06:34<05:46,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1303/2481 [06:34<05:15,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1304/2481 [06:34<04:53,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1305/2481 [06:35<05:34,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1306/2481 [06:35<05:05,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1307/2481 [06:35<05:53,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1308/2481 [06:36<05:51,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1309/2481 [06:36<05:53,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1310/2481 [06:36<05:39,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1311/2481 [06:37<06:15,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1312/2481 [06:37<05:32,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1313/2481 [06:37<05:59,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1314/2481 [06:38<05:46,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1315/2481 [06:38<05:36,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1316/2481 [06:38<05:39,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1317/2481 [06:38<05:29,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1318/2481 [06:39<06:08,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1319/2481 [06:39<06:21,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1320/2481 [06:40<06:45,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1321/2481 [06:40<05:53,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1322/2481 [06:40<05:17,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1323/2481 [06:40<05:25,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1324/2481 [06:40<05:21,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1325/2481 [06:41<06:37,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1326/2481 [06:41<05:46,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1327/2481 [06:41<05:09,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1328/2481 [06:42<05:07,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1329/2481 [06:42<04:47,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1330/2481 [06:42<04:52,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1331/2481 [06:43<05:42,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1332/2481 [06:43<06:08,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1333/2481 [06:43<05:28,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1334/2481 [06:43<06:08,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1335/2481 [06:44<06:27,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1336/2481 [06:44<05:43,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1337/2481 [06:44<05:31,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1338/2481 [06:45<05:35,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1339/2481 [06:45<05:04,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1340/2481 [06:45<05:15,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1341/2481 [06:45<04:47,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1342/2481 [06:46<04:30,  4.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1343/2481 [06:46<04:40,  4.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1344/2481 [06:46<04:56,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1345/2481 [06:46<04:36,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1346/2481 [06:47<04:43,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1347/2481 [06:47<06:04,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1348/2481 [06:47<05:43,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1349/2481 [06:48<05:07,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1350/2481 [06:48<05:51,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1351/2481 [06:48<05:48,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1352/2481 [06:48<05:11,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1353/2481 [06:49<05:08,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1354/2481 [06:49<06:26,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1355/2481 [06:50<06:46,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1356/2481 [06:50<06:14,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1357/2481 [06:50<06:01,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1358/2481 [06:50<05:41,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1359/2481 [06:51<05:05,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1360/2481 [06:51<04:41,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1361/2481 [06:51<05:19,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1362/2481 [06:51<05:11,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1363/2481 [06:52<05:52,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1364/2481 [06:52<05:46,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1365/2481 [06:52<05:29,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1366/2481 [06:53<04:56,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1367/2481 [06:53<04:33,  4.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1368/2481 [06:53<04:19,  4.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1369/2481 [06:53<04:08,  4.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1370/2481 [06:54<05:40,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1371/2481 [06:54<05:28,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1372/2481 [06:54<05:21,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1373/2481 [06:54<04:57,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1374/2481 [06:55<05:29,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1375/2481 [06:55<04:58,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1376/2481 [06:55<05:02,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1377/2481 [06:56<05:10,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1378/2481 [06:56<05:11,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1379/2481 [06:56<05:53,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1380/2481 [06:57<05:47,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1381/2481 [06:57<05:32,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1382/2481 [06:57<05:00,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1383/2481 [06:57<05:00,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1384/2481 [06:58<05:30,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1385/2481 [06:58<05:24,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1386/2481 [06:58<05:15,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1387/2481 [06:59<06:24,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1388/2481 [06:59<05:36,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1389/2481 [06:59<05:02,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1390/2481 [06:59<04:59,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1391/2481 [07:00<05:28,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1392/2481 [07:00<05:28,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1393/2481 [07:00<05:16,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1394/2481 [07:01<04:45,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1395/2481 [07:01<04:47,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1396/2481 [07:01<04:28,  4.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1397/2481 [07:01<04:15,  4.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1398/2481 [07:02<05:00,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1399/2481 [07:02<05:00,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1400/2481 [07:02<05:07,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1400/2481 examples\n",
            "Sample - True: Professional, Predicted: Professional\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1401/2481 [07:03<05:02,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1402/2481 [07:03<04:59,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1403/2481 [07:03<06:11,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1404/2481 [07:04<05:24,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1405/2481 [07:04<05:59,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1406/2481 [07:04<05:47,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1407/2481 [07:05<06:14,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1408/2481 [07:05<05:27,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1409/2481 [07:05<05:25,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1410/2481 [07:05<05:14,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1411/2481 [07:06<04:46,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1412/2481 [07:06<04:25,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1413/2481 [07:06<04:39,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1414/2481 [07:06<05:23,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1415/2481 [07:07<04:51,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1416/2481 [07:07<05:22,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1417/2481 [07:07<05:13,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1418/2481 [07:08<05:50,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1419/2481 [07:08<06:03,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1420/2481 [07:09<06:22,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1421/2481 [07:09<05:51,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1422/2481 [07:09<06:02,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1423/2481 [07:09<05:18,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1424/2481 [07:10<04:47,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1425/2481 [07:10<04:26,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1426/2481 [07:10<04:59,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1427/2481 [07:10<04:50,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1428/2481 [07:11<04:44,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1429/2481 [07:11<04:21,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1430/2481 [07:11<04:56,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1431/2481 [07:11<04:50,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1432/2481 [07:12<05:30,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1433/2481 [07:12<06:27,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1434/2481 [07:13<05:34,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1435/2481 [07:13<05:17,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1436/2481 [07:13<06:17,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1437/2481 [07:14<05:47,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1438/2481 [07:14<06:36,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1439/2481 [07:14<05:59,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1440/2481 [07:15<06:18,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1441/2481 [07:15<06:55,  2.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1442/2481 [07:16<06:49,  2.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1443/2481 [07:16<06:09,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1444/2481 [07:16<06:23,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1445/2481 [07:17<06:21,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1446/2481 [07:17<05:52,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1447/2481 [07:17<05:31,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1448/2481 [07:17<04:54,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1449/2481 [07:18<04:58,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1450/2481 [07:18<06:09,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1451/2481 [07:18<05:21,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1452/2481 [07:19<04:46,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1453/2481 [07:19<04:43,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1454/2481 [07:19<05:08,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1455/2481 [07:20<04:57,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1456/2481 [07:20<04:31,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1457/2481 [07:20<04:42,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1458/2481 [07:20<04:39,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1459/2481 [07:21<05:20,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1460/2481 [07:21<05:37,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1461/2481 [07:21<05:15,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1462/2481 [07:22<04:39,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1463/2481 [07:22<04:15,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1464/2481 [07:22<04:03,  4.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1465/2481 [07:22<03:52,  4.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1466/2481 [07:23<04:46,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1467/2481 [07:23<05:12,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1468/2481 [07:23<04:59,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1469/2481 [07:23<04:29,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1470/2481 [07:24<04:40,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1471/2481 [07:24<04:47,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1472/2481 [07:24<05:20,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1473/2481 [07:25<05:04,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1474/2481 [07:25<04:34,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1475/2481 [07:25<04:40,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1476/2481 [07:26<05:13,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1477/2481 [07:26<04:38,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1478/2481 [07:26<05:22,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1479/2481 [07:26<05:07,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1480/2481 [07:27<05:24,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1481/2481 [07:27<05:47,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1482/2481 [07:27<05:03,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1483/2481 [07:28<05:20,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1484/2481 [07:28<05:47,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1485/2481 [07:28<05:21,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1486/2481 [07:29<05:14,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1487/2481 [07:29<05:39,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1488/2481 [07:29<04:56,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1489/2481 [07:30<05:55,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1490/2481 [07:30<05:37,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1491/2481 [07:30<05:16,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1492/2481 [07:31<05:44,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1493/2481 [07:31<05:31,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1494/2481 [07:31<04:52,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1495/2481 [07:32<04:25,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1496/2481 [07:32<05:32,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1497/2481 [07:32<05:12,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1498/2481 [07:33<04:59,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1499/2481 [07:33<04:48,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1500/2481 [07:33<05:09,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1500/2481 examples\n",
            "Sample - True: Entertainment, Predicted: Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1501/2481 [07:33<04:53,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1502/2481 [07:34<05:21,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1503/2481 [07:34<04:45,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1504/2481 [07:34<04:19,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1505/2481 [07:35<04:21,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1506/2481 [07:35<04:50,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1507/2481 [07:35<04:22,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1508/2481 [07:35<04:01,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1509/2481 [07:36<04:35,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1510/2481 [07:36<04:41,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1511/2481 [07:36<04:33,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1512/2481 [07:37<04:25,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1513/2481 [07:37<04:05,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1514/2481 [07:37<03:48,  4.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1515/2481 [07:37<03:38,  4.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1516/2481 [07:37<03:49,  4.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1517/2481 [07:38<04:27,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1518/2481 [07:38<04:23,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1519/2481 [07:38<04:01,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1520/2481 [07:39<05:11,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1521/2481 [07:39<06:03,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1522/2481 [07:40<06:06,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1523/2481 [07:40<05:13,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1524/2481 [07:40<05:25,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1525/2481 [07:40<04:45,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1526/2481 [07:41<05:15,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1527/2481 [07:41<06:00,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1528/2481 [07:42<05:26,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1529/2481 [07:42<04:46,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1530/2481 [07:42<04:44,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1531/2481 [07:42<04:36,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1532/2481 [07:43<05:07,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1533/2481 [07:43<05:18,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1534/2481 [07:43<04:40,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1535/2481 [07:44<04:32,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1536/2481 [07:44<05:31,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1537/2481 [07:44<04:48,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1538/2481 [07:44<04:19,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1539/2481 [07:45<04:15,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1540/2481 [07:45<05:27,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1541/2481 [07:46<05:43,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1542/2481 [07:46<05:43,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1543/2481 [07:46<05:49,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1544/2481 [07:47<05:54,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1545/2481 [07:47<05:23,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1546/2481 [07:47<04:44,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1547/2481 [07:47<04:21,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1548/2481 [07:48<04:45,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1549/2481 [07:48<04:36,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1550/2481 [07:48<04:28,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1551/2481 [07:49<04:32,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1552/2481 [07:49<04:26,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1553/2481 [07:49<04:57,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1554/2481 [07:50<04:52,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1555/2481 [07:50<04:39,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1556/2481 [07:50<04:10,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1557/2481 [07:50<04:08,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1558/2481 [07:51<05:10,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1559/2481 [07:51<05:01,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1560/2481 [07:51<04:25,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1561/2481 [07:52<04:19,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1562/2481 [07:52<03:57,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1563/2481 [07:52<05:02,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1564/2481 [07:53<04:44,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1565/2481 [07:53<04:14,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1566/2481 [07:53<04:38,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1567/2481 [07:53<04:27,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1568/2481 [07:54<04:21,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1569/2481 [07:54<05:20,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1570/2481 [07:55<05:32,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1571/2481 [07:55<05:05,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1572/2481 [07:55<05:48,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1573/2481 [07:56<05:16,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1574/2481 [07:56<05:21,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1575/2481 [07:56<04:39,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1576/2481 [07:56<04:09,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1577/2481 [07:57<04:06,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1578/2481 [07:57<04:31,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1579/2481 [07:57<04:04,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1580/2481 [07:57<03:45,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1581/2481 [07:58<03:33,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1582/2481 [07:58<03:53,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1583/2481 [07:58<03:36,  4.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1584/2481 [07:59<04:15,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1585/2481 [07:59<03:51,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1586/2481 [07:59<03:55,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1587/2481 [07:59<03:39,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1588/2481 [08:00<03:47,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1589/2481 [08:00<04:53,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1590/2481 [08:00<04:38,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1591/2481 [08:01<04:53,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1592/2481 [08:01<04:46,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1593/2481 [08:01<04:13,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1594/2481 [08:01<04:06,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1595/2481 [08:02<03:46,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1596/2481 [08:02<04:15,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1597/2481 [08:02<04:08,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1598/2481 [08:02<03:46,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1599/2481 [08:03<03:48,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1600/2481 [08:03<03:51,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1600/2481 examples\n",
            "Sample - True: Entertainment, Predicted: Entertainment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1601/2481 [08:03<03:54,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1602/2481 [08:03<03:38,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1603/2481 [08:04<03:52,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1604/2481 [08:04<03:53,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1605/2481 [08:04<03:37,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1606/2481 [08:04<03:25,  4.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1607/2481 [08:05<03:42,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1608/2481 [08:05<03:28,  4.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1609/2481 [08:05<03:19,  4.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1610/2481 [08:05<03:28,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1611/2481 [08:06<03:44,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1612/2481 [08:06<03:46,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1613/2481 [08:06<03:33,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1614/2481 [08:06<03:39,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1615/2481 [08:07<03:49,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1616/2481 [08:07<04:53,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1617/2481 [08:08<05:06,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1618/2481 [08:08<05:45,  2.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1619/2481 [08:08<05:12,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1620/2481 [08:09<04:30,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1621/2481 [08:09<04:01,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1622/2481 [08:09<04:04,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1623/2481 [08:09<03:58,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1624/2481 [08:10<04:31,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1625/2481 [08:10<04:26,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1626/2481 [08:10<04:16,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1627/2481 [08:11<03:52,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1628/2481 [08:11<04:04,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1629/2481 [08:11<03:59,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1630/2481 [08:11<03:55,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1631/2481 [08:12<03:52,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1632/2481 [08:12<03:36,  3.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1633/2481 [08:12<03:23,  4.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1634/2481 [08:13<04:35,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1635/2481 [08:13<04:23,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1636/2481 [08:13<04:11,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1637/2481 [08:14<05:02,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1638/2481 [08:14<04:24,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1639/2481 [08:14<04:17,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1640/2481 [08:14<04:08,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1641/2481 [08:15<05:26,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1642/2481 [08:15<04:56,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1643/2481 [08:16<04:19,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1644/2481 [08:16<04:08,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1645/2481 [08:16<04:57,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1646/2481 [08:17<05:08,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1647/2481 [08:17<05:41,  2.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1648/2481 [08:17<04:49,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1649/2481 [08:18<04:28,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1650/2481 [08:18<03:58,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1651/2481 [08:18<04:50,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1652/2481 [08:19<04:13,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1653/2481 [08:19<05:01,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1654/2481 [08:19<04:19,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1655/2481 [08:20<03:51,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1656/2481 [08:20<03:32,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1657/2481 [08:20<03:17,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1658/2481 [08:20<04:21,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1659/2481 [08:21<03:53,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1660/2481 [08:21<04:12,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1661/2481 [08:21<03:46,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1662/2481 [08:21<03:28,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1663/2481 [08:22<03:13,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1664/2481 [08:22<03:03,  4.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1665/2481 [08:22<02:58,  4.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1666/2481 [08:22<03:11,  4.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1667/2481 [08:23<03:17,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1668/2481 [08:23<03:46,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1669/2481 [08:23<03:28,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1670/2481 [08:23<03:16,  4.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1671/2481 [08:24<03:44,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1672/2481 [08:24<03:26,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1673/2481 [08:24<03:30,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1674/2481 [08:24<03:30,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1675/2481 [08:25<03:55,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1676/2481 [08:25<03:33,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1677/2481 [08:25<03:17,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1678/2481 [08:25<03:07,  4.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1679/2481 [08:26<03:39,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1680/2481 [08:26<03:22,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1681/2481 [08:26<03:09,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1682/2481 [08:27<03:47,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1683/2481 [08:27<03:48,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1684/2481 [08:27<03:28,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1685/2481 [08:27<04:00,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1686/2481 [08:28<03:58,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1687/2481 [08:28<03:36,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1688/2481 [08:28<03:19,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1689/2481 [08:28<03:07,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1690/2481 [08:29<03:38,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1691/2481 [08:29<03:20,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1692/2481 [08:29<03:55,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1693/2481 [08:29<03:31,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1694/2481 [08:30<04:25,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1695/2481 [08:30<04:38,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1696/2481 [08:31<04:39,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1697/2481 [08:31<04:19,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1698/2481 [08:31<04:04,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1699/2481 [08:32<04:17,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1700/2481 [08:32<04:35,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1700/2481 examples\n",
            "Sample - True: Professional, Predicted: ‚Äôs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1701/2481 [08:32<04:46,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1702/2481 [08:33<04:30,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1703/2481 [08:33<05:05,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1704/2481 [08:34<04:36,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1705/2481 [08:34<04:01,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1706/2481 [08:34<03:36,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1707/2481 [08:34<03:55,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1708/2481 [08:35<03:47,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1709/2481 [08:35<03:41,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1710/2481 [08:35<03:59,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1711/2481 [08:35<03:34,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1712/2481 [08:36<04:03,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1713/2481 [08:36<03:59,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1714/2481 [08:36<03:48,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1715/2481 [08:37<03:41,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1716/2481 [08:37<03:21,  3.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1717/2481 [08:37<03:45,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1718/2481 [08:38<03:38,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1719/2481 [08:38<04:06,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1720/2481 [08:38<04:17,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1721/2481 [08:39<04:00,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1722/2481 [08:39<03:48,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1723/2481 [08:39<03:48,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1724/2481 [08:39<03:26,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1725/2481 [08:40<03:09,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1726/2481 [08:40<02:58,  4.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1727/2481 [08:40<03:28,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1728/2481 [08:40<03:24,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1729/2481 [08:41<03:08,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1730/2481 [08:41<02:57,  4.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1731/2481 [08:41<03:27,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1732/2481 [08:41<03:12,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1733/2481 [08:42<03:47,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1734/2481 [08:42<04:01,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1735/2481 [08:42<03:35,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1736/2481 [08:43<03:30,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1737/2481 [08:43<03:12,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1738/2481 [08:43<03:21,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1739/2481 [08:43<03:03,  4.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1740/2481 [08:44<03:36,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1741/2481 [08:44<03:30,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1742/2481 [08:44<03:47,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1743/2481 [08:45<04:10,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1744/2481 [08:45<03:40,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1745/2481 [08:45<03:40,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1746/2481 [08:45<03:18,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1747/2481 [08:46<03:17,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1748/2481 [08:46<03:02,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1749/2481 [08:46<03:27,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1750/2481 [08:47<03:22,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1751/2481 [08:47<03:05,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1752/2481 [08:47<03:16,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1753/2481 [08:47<03:43,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1754/2481 [08:48<03:34,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1755/2481 [08:48<03:50,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1756/2481 [08:48<03:38,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1757/2481 [08:49<04:02,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1758/2481 [08:49<04:09,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1759/2481 [08:50<04:22,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1760/2481 [08:50<04:02,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1761/2481 [08:50<03:54,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1762/2481 [08:50<03:27,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1763/2481 [08:51<03:22,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1764/2481 [08:51<03:05,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1765/2481 [08:51<03:31,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1766/2481 [08:51<03:10,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1767/2481 [08:52<02:55,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1768/2481 [08:52<03:27,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1769/2481 [08:52<03:28,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1770/2481 [08:53<03:50,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1771/2481 [08:53<04:27,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1772/2481 [08:53<04:03,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1773/2481 [08:54<03:47,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1774/2481 [08:54<03:56,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1775/2481 [08:54<03:27,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1776/2481 [08:55<03:21,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1777/2481 [08:55<03:04,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1778/2481 [08:55<02:52,  4.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1779/2481 [08:55<03:03,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1780/2481 [08:55<02:49,  4.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1781/2481 [08:56<03:23,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1782/2481 [08:56<03:38,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1783/2481 [08:56<03:15,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1784/2481 [08:57<03:11,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1785/2481 [08:57<03:31,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1786/2481 [08:57<03:50,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1787/2481 [08:58<03:22,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1788/2481 [08:58<04:05,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1789/2481 [08:58<03:32,  3.25it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1790/2481 [08:59<03:09,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1791/2481 [08:59<03:36,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1792/2481 [08:59<03:13,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1793/2481 [08:59<02:56,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1794/2481 [09:00<03:18,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1795/2481 [09:00<03:13,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1796/2481 [09:00<02:56,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1797/2481 [09:00<02:57,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1798/2481 [09:01<03:04,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1799/2481 [09:01<03:24,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1800/2481 [09:01<03:04,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1800/2481 examples\n",
            "Sample - True: Education, Predicted: Education\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1801/2481 [09:01<02:49,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1802/2481 [09:02<02:51,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1803/2481 [09:02<03:41,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1804/2481 [09:03<03:27,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1805/2481 [09:03<03:18,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1806/2481 [09:03<03:14,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1807/2481 [09:03<02:58,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1808/2481 [09:04<03:01,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1809/2481 [09:04<03:21,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1810/2481 [09:04<03:40,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1811/2481 [09:05<03:36,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1812/2481 [09:05<03:32,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1813/2481 [09:05<03:21,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1814/2481 [09:05<03:14,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1815/2481 [09:06<03:15,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1816/2481 [09:06<02:57,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1817/2481 [09:06<03:16,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1818/2481 [09:07<03:10,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1819/2481 [09:07<02:53,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1820/2481 [09:07<03:00,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1821/2481 [09:07<02:59,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1822/2481 [09:08<02:45,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1823/2481 [09:08<02:48,  3.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1824/2481 [09:08<03:36,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1825/2481 [09:09<03:23,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1826/2481 [09:09<03:01,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1827/2481 [09:09<03:27,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1828/2481 [09:09<03:06,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1829/2481 [09:10<03:09,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1830/2481 [09:10<03:23,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1831/2481 [09:10<03:01,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1832/2481 [09:10<02:45,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1833/2481 [09:11<02:47,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1834/2481 [09:11<03:07,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1835/2481 [09:11<03:03,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1836/2481 [09:12<02:59,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1837/2481 [09:12<02:44,  3.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1838/2481 [09:12<03:32,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1839/2481 [09:13<03:20,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1840/2481 [09:13<02:59,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1841/2481 [09:13<03:15,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1842/2481 [09:13<03:06,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1843/2481 [09:14<03:01,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1844/2481 [09:14<02:46,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1845/2481 [09:14<02:56,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1846/2481 [09:15<03:22,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1847/2481 [09:15<03:14,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1848/2481 [09:15<03:07,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1849/2481 [09:15<02:49,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1850/2481 [09:16<03:06,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1851/2481 [09:16<03:45,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1852/2481 [09:17<03:55,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1853/2481 [09:17<03:24,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1854/2481 [09:17<03:30,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1855/2481 [09:18<03:17,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1856/2481 [09:18<03:08,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1857/2481 [09:18<03:20,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1858/2481 [09:19<03:34,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1859/2481 [09:19<03:06,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1860/2481 [09:19<03:18,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1861/2481 [09:20<03:32,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1862/2481 [09:20<03:07,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1863/2481 [09:20<03:19,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1864/2481 [09:20<03:33,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1865/2481 [09:21<03:19,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1866/2481 [09:21<03:15,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1867/2481 [09:21<03:28,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1868/2481 [09:22<03:13,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1869/2481 [09:22<03:28,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1870/2481 [09:23<03:56,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1871/2481 [09:23<03:35,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1872/2481 [09:23<03:07,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1873/2481 [09:23<02:58,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1874/2481 [09:24<02:59,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1875/2481 [09:24<03:35,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1876/2481 [09:24<03:17,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1877/2481 [09:25<03:30,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1878/2481 [09:25<03:56,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1879/2481 [09:26<03:33,  2.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1880/2481 [09:26<03:58,  2.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1881/2481 [09:26<03:22,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1882/2481 [09:26<02:57,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1883/2481 [09:27<02:52,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1884/2481 [09:27<02:55,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1885/2481 [09:27<03:15,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1886/2481 [09:28<02:52,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1887/2481 [09:28<03:32,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1888/2481 [09:28<03:17,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1889/2481 [09:29<02:53,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1890/2481 [09:29<03:30,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1891/2481 [09:29<03:14,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1892/2481 [09:30<03:26,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1893/2481 [09:30<03:17,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1894/2481 [09:30<02:54,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1895/2481 [09:31<02:50,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1896/2481 [09:31<02:47,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1897/2481 [09:31<02:49,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1898/2481 [09:32<03:09,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1899/2481 [09:32<02:46,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1900/2481 [09:32<02:49,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1900/2481 examples\n",
            "Sample - True: Travel, Predicted: Travel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1901/2481 [09:32<02:45,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1902/2481 [09:33<02:42,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1903/2481 [09:33<03:19,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1904/2481 [09:33<02:54,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1905/2481 [09:34<03:10,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1906/2481 [09:34<02:59,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1907/2481 [09:34<02:51,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1908/2481 [09:35<02:45,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1909/2481 [09:35<02:58,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1910/2481 [09:35<02:50,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1911/2481 [09:35<02:44,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1912/2481 [09:36<02:45,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1913/2481 [09:36<02:47,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1914/2481 [09:36<02:41,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1915/2481 [09:37<02:36,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1916/2481 [09:37<03:14,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1917/2481 [09:37<03:22,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1918/2481 [09:38<03:05,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1919/2481 [09:38<03:17,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1920/2481 [09:38<02:53,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1921/2481 [09:39<03:26,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1922/2481 [09:39<02:58,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1923/2481 [09:39<02:38,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1924/2481 [09:39<02:36,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1925/2481 [09:40<02:39,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1926/2481 [09:40<02:43,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1927/2481 [09:41<03:03,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1928/2481 [09:41<03:34,  2.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1929/2481 [09:41<03:13,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1930/2481 [09:42<03:00,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1931/2481 [09:42<03:27,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1932/2481 [09:42<03:07,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1933/2481 [09:43<02:53,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1934/2481 [09:43<02:35,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1935/2481 [09:43<03:09,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1936/2481 [09:44<02:54,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1937/2481 [09:44<02:35,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1938/2481 [09:44<03:09,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1939/2481 [09:44<02:44,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1940/2481 [09:45<02:27,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1941/2481 [09:45<02:15,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1942/2481 [09:45<02:32,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1943/2481 [09:45<02:18,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1944/2481 [09:46<02:19,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1945/2481 [09:46<02:09,  4.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1946/2481 [09:46<02:18,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1947/2481 [09:46<02:08,  4.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1948/2481 [09:47<02:01,  4.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1949/2481 [09:47<02:07,  4.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1950/2481 [09:47<02:27,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1951/2481 [09:47<02:24,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1952/2481 [09:48<02:23,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1953/2481 [09:48<02:12,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1954/2481 [09:48<02:29,  3.52it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1955/2481 [09:49<02:47,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1956/2481 [09:49<02:53,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1957/2481 [09:49<02:33,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1958/2481 [09:50<02:49,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1959/2481 [09:50<02:30,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1960/2481 [09:50<03:00,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1961/2481 [09:51<02:46,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1962/2481 [09:51<02:37,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1963/2481 [09:51<02:23,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1964/2481 [09:51<02:43,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1965/2481 [09:52<03:25,  2.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1966/2481 [09:52<03:05,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1967/2481 [09:53<02:41,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1968/2481 [09:53<02:35,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1969/2481 [09:53<02:47,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1970/2481 [09:53<02:38,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1971/2481 [09:54<02:32,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1972/2481 [09:54<02:33,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1973/2481 [09:54<02:28,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1974/2481 [09:55<02:25,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1975/2481 [09:55<02:12,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1976/2481 [09:55<02:17,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1977/2481 [09:56<02:37,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1978/2481 [09:56<02:30,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1979/2481 [09:56<02:30,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1980/2481 [09:56<02:16,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1981/2481 [09:57<02:35,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1982/2481 [09:57<02:43,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1983/2481 [09:57<02:33,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1984/2481 [09:58<02:16,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1985/2481 [09:58<02:15,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1986/2481 [09:58<02:35,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1987/2481 [09:58<02:18,  3.58it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1988/2481 [09:59<02:21,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1989/2481 [09:59<02:38,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1990/2481 [10:00<02:50,  2.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1991/2481 [10:00<02:54,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1992/2481 [10:00<02:40,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1993/2481 [10:01<03:04,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1994/2481 [10:01<03:20,  2.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1995/2481 [10:01<02:58,  2.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1996/2481 [10:02<02:43,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1997/2481 [10:02<02:23,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1998/2481 [10:02<02:22,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1999/2481 [10:03<02:37,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2000/2481 [10:03<02:19,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 2000/2481 examples\n",
            "Sample - True: Travel, Predicted: Travel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2001/2481 [10:03<02:21,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2002/2481 [10:03<02:09,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2003/2481 [10:03<01:59,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2004/2481 [10:04<02:01,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2005/2481 [10:04<02:35,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2006/2481 [10:05<02:24,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2007/2481 [10:05<02:18,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2008/2481 [10:05<02:48,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2009/2481 [10:06<02:35,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2010/2481 [10:06<02:18,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2011/2481 [10:06<02:18,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2012/2481 [10:06<02:05,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2013/2481 [10:07<02:25,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2014/2481 [10:07<02:11,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2015/2481 [10:07<02:14,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2016/2481 [10:07<02:10,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2017/2481 [10:08<02:08,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2018/2481 [10:08<02:20,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2019/2481 [10:08<02:33,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2020/2481 [10:09<02:14,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2021/2481 [10:09<02:02,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2022/2481 [10:09<02:06,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2023/2481 [10:09<02:04,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2024/2481 [10:10<01:54,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2025/2481 [10:10<01:56,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2026/2481 [10:10<02:29,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2027/2481 [10:11<02:20,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2028/2481 [10:11<02:05,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2029/2481 [10:11<02:16,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2030/2481 [10:11<02:01,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2031/2481 [10:12<01:51,  4.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2032/2481 [10:12<01:45,  4.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2033/2481 [10:12<01:49,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2034/2481 [10:12<02:10,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2035/2481 [10:13<02:19,  3.19it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2036/2481 [10:13<02:32,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2037/2481 [10:14<02:35,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2038/2481 [10:14<02:29,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2039/2481 [10:14<02:11,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2040/2481 [10:14<02:06,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2041/2481 [10:15<02:03,  3.56it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2042/2481 [10:15<02:14,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2043/2481 [10:15<02:24,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2044/2481 [10:16<02:15,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2045/2481 [10:16<02:09,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2046/2481 [10:16<02:06,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2047/2481 [10:16<01:54,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2048/2481 [10:17<02:24,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2049/2481 [10:17<02:15,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2050/2481 [10:17<02:10,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2051/2481 [10:18<02:17,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2052/2481 [10:18<02:13,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2053/2481 [10:18<01:59,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2054/2481 [10:19<02:03,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2055/2481 [10:19<02:18,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2056/2481 [10:19<02:11,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2057/2481 [10:20<01:57,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2058/2481 [10:20<02:26,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2059/2481 [10:20<02:16,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2060/2481 [10:21<02:00,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2061/2481 [10:21<02:10,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2062/2481 [10:21<01:56,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2063/2481 [10:21<01:54,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2064/2481 [10:22<02:22,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2065/2481 [10:22<02:04,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2066/2481 [10:22<01:51,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2067/2481 [10:23<02:18,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2068/2481 [10:23<02:22,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2069/2481 [10:23<02:11,  3.13it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2070/2481 [10:24<02:04,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2071/2481 [10:24<01:59,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2072/2481 [10:24<02:07,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2073/2481 [10:24<01:53,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2074/2481 [10:25<01:51,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2075/2481 [10:25<01:42,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2076/2481 [10:25<01:55,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2077/2481 [10:25<01:44,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2078/2481 [10:26<01:45,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2079/2481 [10:26<01:57,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2080/2481 [10:26<01:46,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2081/2481 [10:27<01:46,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2082/2481 [10:27<01:58,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2083/2481 [10:27<01:47,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2084/2481 [10:27<01:38,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2085/2481 [10:28<01:55,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2086/2481 [10:28<02:03,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2087/2481 [10:28<02:13,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2088/2481 [10:29<02:19,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2089/2481 [10:29<02:09,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2090/2481 [10:29<02:02,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2091/2481 [10:30<02:09,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2092/2481 [10:30<02:02,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2093/2481 [10:30<02:13,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2094/2481 [10:31<02:07,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2095/2481 [10:31<01:52,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2096/2481 [10:31<01:41,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2097/2481 [10:32<02:08,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2098/2481 [10:32<02:16,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2099/2481 [10:32<01:57,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2100/2481 [10:33<02:19,  2.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 2100/2481 examples\n",
            "Sample - True: Education, Predicted: to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2101/2481 [10:33<02:25,  2.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2102/2481 [10:33<02:04,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2103/2481 [10:34<02:01,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2104/2481 [10:34<01:48,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2105/2481 [10:34<01:45,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2106/2481 [10:34<01:43,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2107/2481 [10:35<01:51,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2108/2481 [10:35<01:40,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2109/2481 [10:35<01:32,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2110/2481 [10:35<01:27,  4.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2111/2481 [10:36<01:40,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2112/2481 [10:36<02:05,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2113/2481 [10:36<01:49,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2114/2481 [10:37<01:45,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2115/2481 [10:37<01:54,  3.20it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2116/2481 [10:37<01:49,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2117/2481 [10:38<01:38,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2118/2481 [10:38<01:37,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2119/2481 [10:38<01:47,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2120/2481 [10:39<01:58,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2121/2481 [10:39<01:44,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2122/2481 [10:39<02:06,  2.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2123/2481 [10:40<01:56,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2124/2481 [10:40<01:42,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2125/2481 [10:40<02:05,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2126/2481 [10:41<01:55,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2127/2481 [10:41<01:42,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2128/2481 [10:41<01:33,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2129/2481 [10:41<01:43,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2130/2481 [10:42<01:33,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2131/2481 [10:42<01:32,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2132/2481 [10:42<01:42,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2133/2481 [10:42<01:39,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2134/2481 [10:43<01:51,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2135/2481 [10:43<01:49,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2136/2481 [10:43<01:37,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2137/2481 [10:44<01:28,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2138/2481 [10:44<01:43,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2139/2481 [10:44<01:50,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2140/2481 [10:45<01:58,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2141/2481 [10:45<01:59,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2142/2481 [10:45<01:44,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2143/2481 [10:45<01:32,  3.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2144/2481 [10:46<01:25,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2145/2481 [10:46<01:30,  3.72it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2146/2481 [10:46<01:42,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2147/2481 [10:47<01:50,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2148/2481 [10:47<01:45,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2149/2481 [10:47<01:40,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2150/2481 [10:48<02:00,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2151/2481 [10:48<01:50,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2152/2481 [10:48<01:37,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2153/2481 [10:49<01:56,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2154/2481 [10:49<01:50,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2155/2481 [10:49<01:42,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2156/2481 [10:50<01:31,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2157/2481 [10:50<01:22,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2158/2481 [10:50<01:36,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2159/2481 [10:50<01:34,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2160/2481 [10:51<01:34,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2161/2481 [10:51<01:31,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2162/2481 [10:51<01:23,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2163/2481 [10:51<01:17,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2164/2481 [10:52<01:22,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2165/2481 [10:52<01:25,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2166/2481 [10:52<01:18,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2167/2481 [10:52<01:18,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2168/2481 [10:53<01:32,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2169/2481 [10:53<01:38,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2170/2481 [10:54<01:45,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2171/2481 [10:54<01:31,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2172/2481 [10:54<01:29,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2173/2481 [10:54<01:21,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2174/2481 [10:55<01:22,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2175/2481 [10:55<01:24,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2176/2481 [10:55<01:17,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2177/2481 [10:55<01:18,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2178/2481 [10:56<01:28,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2179/2481 [10:56<01:20,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2180/2481 [10:56<01:20,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2181/2481 [10:56<01:19,  3.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2182/2481 [10:57<01:40,  2.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2183/2481 [10:57<01:55,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2184/2481 [10:58<01:38,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2185/2481 [10:58<01:53,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2186/2481 [10:59<01:53,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2187/2481 [10:59<01:37,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2188/2481 [10:59<01:39,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2189/2481 [10:59<01:44,  2.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2190/2481 [11:00<01:36,  3.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2191/2481 [11:00<01:50,  2.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2192/2481 [11:01<01:41,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2193/2481 [11:01<01:28,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2194/2481 [11:01<01:44,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2195/2481 [11:02<01:47,  2.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2196/2481 [11:02<01:32,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2197/2481 [11:02<01:34,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2198/2481 [11:02<01:28,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2199/2481 [11:03<01:18,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2200/2481 [11:03<01:11,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 2200/2481 examples\n",
            "Sample - True: Education, Predicted: Education\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2201/2481 [11:03<01:12,  3.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2202/2481 [11:03<01:12,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2203/2481 [11:04<01:31,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2204/2481 [11:04<01:21,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2205/2481 [11:04<01:30,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2206/2481 [11:05<01:27,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2207/2481 [11:05<01:18,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2208/2481 [11:05<01:11,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2209/2481 [11:05<01:11,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2210/2481 [11:06<01:19,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2211/2481 [11:06<01:36,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2212/2481 [11:07<01:23,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2213/2481 [11:07<01:19,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2214/2481 [11:07<01:36,  2.77it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2215/2481 [11:08<01:39,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2216/2481 [11:08<01:25,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2217/2481 [11:08<01:28,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2218/2481 [11:08<01:17,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2219/2481 [11:09<01:10,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2220/2481 [11:09<01:28,  2.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2221/2481 [11:09<01:17,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2222/2481 [11:10<01:09,  3.73it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2223/2481 [11:10<01:18,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2224/2481 [11:10<01:10,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2225/2481 [11:10<01:09,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2226/2481 [11:11<01:03,  3.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2227/2481 [11:11<01:13,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2228/2481 [11:11<01:12,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2229/2481 [11:12<01:11,  3.54it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2230/2481 [11:12<01:27,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2231/2481 [11:12<01:16,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2232/2481 [11:13<01:23,  2.99it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2233/2481 [11:13<01:25,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2234/2481 [11:13<01:14,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2235/2481 [11:14<01:11,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2236/2481 [11:14<01:08,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2237/2481 [11:14<01:14,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2238/2481 [11:14<01:05,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2239/2481 [11:15<01:00,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2240/2481 [11:15<01:00,  3.96it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2241/2481 [11:15<01:18,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2242/2481 [11:15<01:08,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2243/2481 [11:16<01:06,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2244/2481 [11:16<01:21,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2245/2481 [11:16<01:10,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2246/2481 [11:17<01:17,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2247/2481 [11:17<01:20,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2248/2481 [11:17<01:14,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2249/2481 [11:18<01:06,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2250/2481 [11:18<01:00,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2251/2481 [11:18<01:02,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2252/2481 [11:19<01:11,  3.21it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2253/2481 [11:19<01:03,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2254/2481 [11:19<01:17,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2255/2481 [11:20<01:11,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2256/2481 [11:20<01:07,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2257/2481 [11:20<01:13,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2258/2481 [11:20<01:09,  3.23it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2259/2481 [11:21<01:12,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2260/2481 [11:21<01:15,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2261/2481 [11:21<01:05,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2262/2481 [11:22<00:59,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2263/2481 [11:22<00:58,  3.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2264/2481 [11:22<01:13,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2265/2481 [11:23<01:08,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2266/2481 [11:23<01:02,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2267/2481 [11:23<01:03,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2268/2481 [11:24<01:09,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2269/2481 [11:24<01:05,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2270/2481 [11:24<01:08,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2271/2481 [11:24<01:00,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2272/2481 [11:25<00:54,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2273/2481 [11:25<00:50,  4.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2274/2481 [11:25<00:53,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2275/2481 [11:26<01:02,  3.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2276/2481 [11:26<00:59,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2277/2481 [11:26<01:11,  2.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2278/2481 [11:26<01:01,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2279/2481 [11:27<00:55,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2280/2481 [11:27<00:50,  4.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2281/2481 [11:27<00:56,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2282/2481 [11:27<00:51,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2283/2481 [11:28<00:51,  3.85it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2284/2481 [11:28<00:56,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2285/2481 [11:28<00:55,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2286/2481 [11:29<01:01,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2287/2481 [11:29<01:04,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2288/2481 [11:29<01:07,  2.87it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2289/2481 [11:30<01:09,  2.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2290/2481 [11:30<01:11,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2291/2481 [11:30<01:01,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2292/2481 [11:31<00:59,  3.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2293/2481 [11:31<01:04,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2294/2481 [11:31<00:59,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2295/2481 [11:32<01:09,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2296/2481 [11:32<01:08,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2297/2481 [11:32<00:58,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2298/2481 [11:33<00:55,  3.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2299/2481 [11:33<00:58,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2300/2481 [11:34<01:02,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 2300/2481 examples\n",
            "Sample - True: Entertainment, Predicted: thing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2301/2481 [11:34<00:58,  3.07it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2302/2481 [11:34<01:00,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2303/2481 [11:34<00:53,  3.35it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2304/2481 [11:35<00:51,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2305/2481 [11:35<00:46,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2306/2481 [11:35<00:51,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2307/2481 [11:35<00:46,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2308/2481 [11:36<00:46,  3.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2309/2481 [11:36<00:57,  2.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2310/2481 [11:36<00:53,  3.18it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2311/2481 [11:37<00:47,  3.57it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2312/2481 [11:37<00:51,  3.27it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2313/2481 [11:37<00:48,  3.43it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2314/2481 [11:37<00:43,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2315/2481 [11:38<00:40,  4.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2316/2481 [11:38<00:41,  4.01it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2317/2481 [11:38<00:53,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2318/2481 [11:39<00:50,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2319/2481 [11:39<00:52,  3.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2320/2481 [11:39<00:46,  3.49it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2321/2481 [11:39<00:41,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2322/2481 [11:40<00:41,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2323/2481 [11:40<00:38,  4.10it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2324/2481 [11:40<00:43,  3.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2325/2481 [11:41<00:40,  3.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2326/2481 [11:41<00:40,  3.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2327/2481 [11:41<00:42,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2328/2481 [11:41<00:38,  3.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2329/2481 [11:42<00:39,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2330/2481 [11:42<00:36,  4.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2331/2481 [11:42<00:38,  3.86it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2332/2481 [11:42<00:44,  3.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2333/2481 [11:43<00:40,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2334/2481 [11:43<00:43,  3.34it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2335/2481 [11:43<00:47,  3.06it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2336/2481 [11:44<00:50,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2337/2481 [11:44<00:47,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2338/2481 [11:44<00:42,  3.39it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2339/2481 [11:45<00:37,  3.75it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2340/2481 [11:45<00:34,  4.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2341/2481 [11:45<00:44,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2342/2481 [11:46<00:47,  2.91it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2343/2481 [11:46<00:54,  2.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2344/2481 [11:46<00:48,  2.81it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2345/2481 [11:47<00:44,  3.04it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2346/2481 [11:47<00:45,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2347/2481 [11:47<00:42,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2348/2481 [11:48<00:45,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2349/2481 [11:48<00:42,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2350/2481 [11:48<00:39,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2351/2481 [11:49<00:47,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2352/2481 [11:49<00:43,  3.00it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2353/2481 [11:49<00:37,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2354/2481 [11:49<00:36,  3.47it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2355/2481 [11:50<00:47,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2356/2481 [11:50<00:43,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2357/2481 [11:51<00:39,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2358/2481 [11:51<00:35,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2359/2481 [11:51<00:35,  3.45it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2360/2481 [11:51<00:31,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2361/2481 [11:52<00:31,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2362/2481 [11:52<00:36,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2363/2481 [11:52<00:32,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2364/2481 [11:52<00:30,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2365/2481 [11:53<00:31,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2366/2481 [11:53<00:29,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2367/2481 [11:53<00:29,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2368/2481 [11:53<00:27,  4.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2369/2481 [11:54<00:35,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2370/2481 [11:54<00:33,  3.28it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2371/2481 [11:54<00:32,  3.40it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2372/2481 [11:55<00:34,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2373/2481 [11:55<00:30,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2374/2481 [11:55<00:29,  3.62it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2375/2481 [11:55<00:29,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2376/2481 [11:56<00:35,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2377/2481 [11:56<00:30,  3.36it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2378/2481 [11:57<00:36,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2379/2481 [11:57<00:40,  2.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2380/2481 [11:58<00:40,  2.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2381/2481 [11:58<00:35,  2.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2382/2481 [11:58<00:35,  2.76it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2383/2481 [11:59<00:36,  2.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2384/2481 [11:59<00:31,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2385/2481 [11:59<00:32,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2386/2481 [11:59<00:30,  3.12it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2387/2481 [12:00<00:26,  3.51it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2388/2481 [12:00<00:24,  3.83it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2389/2481 [12:00<00:25,  3.66it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2390/2481 [12:00<00:24,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2391/2481 [12:01<00:22,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2392/2481 [12:01<00:22,  3.89it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2393/2481 [12:01<00:23,  3.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2394/2481 [12:01<00:22,  3.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2395/2481 [12:02<00:26,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2396/2481 [12:02<00:25,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2397/2481 [12:02<00:24,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2398/2481 [12:03<00:21,  3.79it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2399/2481 [12:03<00:20,  4.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2400/2481 [12:03<00:25,  3.14it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 2400/2481 examples\n",
            "Sample - True: Education, Predicted: .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2401/2481 [12:04<00:27,  2.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2402/2481 [12:04<00:26,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2403/2481 [12:04<00:22,  3.44it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2404/2481 [12:04<00:21,  3.55it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2405/2481 [12:05<00:20,  3.65it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2406/2481 [12:05<00:20,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2407/2481 [12:05<00:20,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2408/2481 [12:06<00:24,  2.94it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2409/2481 [12:06<00:25,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2410/2481 [12:06<00:21,  3.29it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2411/2481 [12:07<00:20,  3.41it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2412/2481 [12:07<00:24,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2413/2481 [12:07<00:20,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2414/2481 [12:08<00:19,  3.38it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2415/2481 [12:08<00:18,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2416/2481 [12:08<00:23,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2417/2481 [12:09<00:19,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2418/2481 [12:09<00:23,  2.70it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2419/2481 [12:09<00:23,  2.64it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2420/2481 [12:10<00:19,  3.09it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2421/2481 [12:10<00:17,  3.48it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2422/2481 [12:10<00:16,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2423/2481 [12:10<00:16,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2424/2481 [12:11<00:14,  3.92it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2425/2481 [12:11<00:15,  3.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2426/2481 [12:11<00:13,  4.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2427/2481 [12:11<00:13,  3.97it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2428/2481 [12:12<00:14,  3.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2429/2481 [12:12<00:17,  2.93it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2430/2481 [12:12<00:16,  3.11it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2431/2481 [12:13<00:14,  3.46it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2432/2481 [12:13<00:15,  3.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2433/2481 [12:13<00:16,  2.90it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2434/2481 [12:14<00:14,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2435/2481 [12:14<00:13,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2436/2481 [12:14<00:15,  2.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2437/2481 [12:15<00:16,  2.71it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2438/2481 [12:15<00:14,  2.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2439/2481 [12:15<00:12,  3.31it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2440/2481 [12:16<00:11,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2441/2481 [12:16<00:10,  3.98it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2442/2481 [12:16<00:10,  3.78it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2443/2481 [12:16<00:09,  4.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2444/2481 [12:16<00:08,  4.33it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2445/2481 [12:17<00:08,  4.15it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2446/2481 [12:17<00:09,  3.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2447/2481 [12:17<00:09,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2448/2481 [12:18<00:10,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2449/2481 [12:18<00:08,  3.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2450/2481 [12:18<00:08,  3.53it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2451/2481 [12:18<00:07,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2452/2481 [12:19<00:06,  4.16it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2453/2481 [12:19<00:06,  4.32it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2454/2481 [12:19<00:08,  3.22it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2455/2481 [12:20<00:07,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2456/2481 [12:20<00:07,  3.17it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2457/2481 [12:20<00:07,  3.03it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2458/2481 [12:20<00:06,  3.42it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2459/2481 [12:21<00:06,  3.50it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2460/2481 [12:21<00:07,  2.80it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2461/2481 [12:21<00:06,  3.24it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2462/2481 [12:22<00:06,  2.74it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2463/2481 [12:22<00:06,  2.68it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2464/2481 [12:23<00:06,  2.63it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2465/2481 [12:23<00:06,  2.59it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2466/2481 [12:23<00:04,  3.02it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2467/2481 [12:24<00:04,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2468/2481 [12:24<00:04,  3.08it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2469/2481 [12:24<00:04,  2.84it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2470/2481 [12:25<00:04,  2.30it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2471/2481 [12:25<00:03,  2.61it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2472/2481 [12:26<00:02,  3.05it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2473/2481 [12:26<00:02,  3.26it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2474/2481 [12:26<00:01,  3.60it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2475/2481 [12:26<00:01,  3.88it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2476/2481 [12:26<00:01,  3.82it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2477/2481 [12:27<00:01,  3.37it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2478/2481 [12:27<00:00,  3.67it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2479/2481 [12:27<00:00,  3.69it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2480/2481 [12:28<00:00,  2.95it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2481/2481 [12:28<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä PREDICTION ANALYSIS:\n",
            "Predicted label distribution: Counter({'Comedy': 527, 'Entertainment': 406, 'Professional': 351, 'Travel': 350, 'Education': 238, 'Health': 44, ',': 25, '.': 21, 'I': 15, 'the': 15, 'and': 14, 'a': 10, 'to': 9, 'of': 9, ':': 7, 'I‚Äôm': 6, 'in': 6, 'my': 6, 'for': 6, 'be': 5, 'is': 5, 'you': 5, '4:': 4, \"I'm\": 4, '###': 3, 'they': 3, 'like': 3, 'was': 3, \"'s\": 3, 'market': 3, 'want': 3, ')': 3, '3:': 3, '5:': 3, 'with': 3, 'it': 3, '**': 3, 'no': 3, \"'m\": 3, '*': 3, 'can': 3, 'or': 3, '‚Äôt': 3, 'on': 2, 'think': 2, 'not': 2, 'that': 2, 'get': 2, '-ji': 2, 'will': 2, '‚Äôve': 2, 'No': 2, 'Comment': 2, 'your': 2, '.,': 2, '10': 2, 'strategies': 2, 'If': 2, 'iterate': 2, 'down': 2, 'but': 2, 'what': 2, 'from': 2, 'say': 2, '4': 2, '2': 2, 'Top': 2, 'words': 1, 'used': 1, 'car': 1, 'ions,': 1, 'ei,': 1, 'Sannenzaka': 1, 'August,': 1, 'ally': 1, 'hours': 1, 'audiobook': 1, 'post': 1, 'husband': 1, '7': 1, \"'d\": 1, 'ogoku': 1, 'shaders': 1, 'would': 1, 'I‚Äôve': 1, 'went': 1, 'sim,': 1, 'uncaring.': 1, 'slides.': 1, 'helps!': 1, 'chools/article_3': 1, 'Canceled.\"': 1, '$1': 1, 'missing': 1, 'again': 1, 'Chashma': 1, 'job?': 1, 'software': 1, 'grandpa.': 1, 'this': 1, 'react': 1, 'initial': 1, 'methods](https://en': 1, 's.': 1, 'ji': 1, 'ÔøΩ': 1, 'ian': 1, '[https://www': 1, 'wagcIAR': 1, 'it‚Äôs': 1, 'driving': 1, 'bot.': 1, 'XP.': 1, 'free': 1, '2000-2005': 1, 'ruiters': 1, 'ist,': 1, 'discipline.': 1, 'give': 1, 'ate': 1, 'way': 1, 'fit': 1, '1)': 1, '‚ÄúPros‚Äù': 1, 'fine,': 1, 'We': 1, 'if': 1, 'GB': 1, 'JW': 1, 'never': 1, 'stuff': 1, 'it.': 1, '0d/](https': 1, 'at': 1, 'try.': 1, 'immigration': 1, 'looking': 1, 'assignments,': 1, 'different': 1, '3,': 1, 'refill': 1, 'awa': 1, 'train': 1, 'fuck': 1, 'start.': 1, 'more': 1, '‚Üí': 1, 'slack': 1, 'one': 1, 'does': 1, 'backend': 1, 'bonus.': 1, 'life': 1, 'avoid': 1, 'many': 1, '1:': 1, 'single': 1, 'lawyer': 1, 'idis](https://op': 1, 'unemployed': 1, 'employees': 1, 'job.': 1, 'AI': 1, 'https://www.japan': 1, 'boxes‚Äô': 1, '**Lesson:**': 1, 'available.': 1, '\\\\-kobe': 1, \"I've\": 1, 'ruling': 1, 'CHARACTER_CODES].map': 1, 'advance': 1, 'things': 1, 'about': 1, 'dive': 1, \"'t\": 1, 'ima': 1, 'so': 1, 'minute': 1, 'etc.': 1, 'am': 1, \"'Avialae'\": 1, '/articles/PMC100000': 1, '-2': 1, '$20': 1, '10/10)': 1, 'canister': 1, 'anymore.': 1, 'eway': 1, 'magnetic': 1, \"can't\": 1, 'accredited': 1, 'designed': 1, 'down,': 1, 'volts,': 1, '-If': 1, '-': 1, 'awa-go': 1, 'loop,': 1, 'off.': 1, 'experience': 1, 'breakfast': 1, 'take': 1, '2e2e3': 1, \"I'd\": 1, '‚Äôre': 1, 'stations': 1, 'ama': 1, 'am,': 1, 'industry.': 1, 'agent': 1, 'sustained': 1, 'reached,': 1, 'hobby,': 1, 'feedback': 1, 'see.': 1, 'need': 1, 'time': 1, 'use': 1, 'night': 1, 'Park,': 1, 'learning': 1, 'us.html': 1, 'new': 1, 'stealing': 1, 'level,': 1, 'cash': 1, '&check_out=202': 1, 'degrees.': 1, 'Vibe': 1, '[https://www.all': 1, 'bad,': 1, '‚Ä¢': 1, 'interactions.': 1, 'You': 1, '**Devlog:**': 1, 'well.': 1, 'fact': 1, 'shoes)': 1, 'offer': 1, 'because': 1, 'then': 1, 'too': 1, '1KjZQ': 1, 'camp.': 1, 'better': 1, 'Matsumoto,': 1, 'days,': 1, 'ik).': 1, '?‚Äù': 1, 'all': 1, 'account': 1, 'education': 1, '\"you': 1, '5': 1, '11:': 1, 'delivered': 1, 'lead': 1, 'tunnel.': 1, 'most': 1, 'iyomizu-dera': 1, '60%': 1, 'icans': 1, 'lot': 1, 'years.': 1, '2e2e2': 1, 'armour': 1, '?': 1, 'feedback,': 1, 'being': 1, 'couldn‚Äôt': 1, 'doing.': 1, 'C': 1, 'Europe.': 1, '‚Äôs': 1, '2nd': 1, 'Members': 1, 'j/ai_is_go': 1, '2%': 1, 'specializations**': 1, 'unpack': 1, 'part.': 1, 'some': 1, 'help': 1, 'I‚Äôd': 1, '80s': 1, 'role.': 1, '75k': 1, 'types': 1, 'an': 1, 'especially': 1, 'river,': 1, 'ed*,': 1, '‚Äôm': 1, 'ys': 1, 'rubbed': 1, 'villas': 1, 'person,': 1, 'those': 1, 'Udemy](https': 1, 'que': 1, 'converted': 1, 'add': 1, '+': 1, 'through': 1, \"'re\": 1, 'times.': 1, '\"\"\"': 1, '**4.': 1, 'person.': 1, 'series': 1, '10am': 1, 'Kanazawa': 1, 'ho-ji': 1, 'doing': 1, 'grounds': 1, 'speed': 1, 'mistake.': 1, 'stop': 1, 'remember': 1, 'reso': 1, 'NumPy,': 1, 'starts': 1, 'Protection': 1, 'point': 1, 'bank,': 1, 'are.**': 1, 'azawa': 1, 'consent': 1, 'Shrine,': 1, 'only': 1, 'FluffWisdom.com': 1, 'worked': 1, '‚Äôd': 1, 'thing.': 1, 'https://NoFluff': 1, 'Cannes,': 1, 'eling': 1, 'TRIP):': 1, 'are': 1, 'have': 1, 'Go': 1, 'theory': 1, 'LGA**': 1, 'by': 1, 'learned': 1, '25:': 1, 'there': 1, 'It‚Äôs': 1, 'job,': 1, 'is?': 1, 'up.': 1, 'risk': 1, 'takes': 1, 'course.': 1})\n",
            "\n",
            "‚úÖ Valid predictions: 1916/2481\n",
            "\n",
            "============================================================\n",
            "CLASSIFICATION EVALUATION RESULTS\n",
            "============================================================\n",
            "Overall Accuracy: 0.9520 (95.20%)\n",
            "Valid examples: 1916\n",
            "\n",
            "Per-Class Metrics:\n",
            "------------------------------------------------------------\n",
            "Professional | Precision: 0.889 | Recall: 0.963 | F1: 0.924 | Support: 324.0\n",
            "Comedy       | Precision: 0.939 | Recall: 1.000 | F1: 0.969 | Support: 495.0\n",
            "Entertainment | Precision: 0.993 | Recall: 0.904 | F1: 0.946 | Support: 446.0\n",
            "Travel       | Precision: 0.980 | Recall: 0.988 | F1: 0.984 | Support: 347.0\n",
            "Education    | Precision: 0.983 | Recall: 0.883 | F1: 0.930 | Support: 265.0\n",
            "Health       | Precision: 0.841 | Recall: 0.949 | F1: 0.892 | Support: 39.0\n",
            "\n",
            "Macro Average F1-Score: 0.9409\n",
            "Weighted Average F1-Score: 0.9519\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------------------------------------\n",
            "               Professional  Comedy  Entertainment  Travel  Education  Health\n",
            "Professional            312       9              0       1          1       1\n",
            "Comedy                    0     495              0       0          0       0\n",
            "Entertainment            14      19            403       6          3       1\n",
            "Travel                    1       1              1     343          0       1\n",
            "Education                24       2              1       0        234       4\n",
            "Health                    0       1              1       0          0      37\n",
            "\n",
            "Sample Predictions:\n",
            "------------------------------------------------------------\n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Professional | Predicted: Professional\n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Travel       | Predicted: Travel      \n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Education    | Predicted: Education   \n",
            "‚úì True: Travel       | Predicted: Travel      \n",
            "‚úì True: Entertainment | Predicted: Entertainment\n",
            "‚úì True: Professional | Predicted: Professional\n",
            "‚úì True: Entertainment | Predicted: Entertainment\n",
            "‚úì True: Entertainment | Predicted: Entertainment\n",
            "‚úì True: Comedy       | Predicted: Comedy      \n",
            "‚úì True: Health       | Predicted: Health      \n",
            "‚úì True: Education    | Predicted: Education   \n",
            "\n",
            "üéâ EVALUATION COMPLETED!\n",
            "Final test accuracy: 95.20%\n",
            "Categories found: ['Professional', 'Comedy', 'Entertainment', 'Travel', 'Education', 'Health']\n",
            "Valid predictions: 1916/2481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "def evaluate_classification_model(model, tokenizer, eval_dataset, device='cuda'):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation for multi-class classification\n",
        "    Returns accuracy, per-class metrics, confusion matrix\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    print(\"Running classification evaluation...\")\n",
        "\n",
        "    # First pass: collect all actual labels to understand the data\n",
        "    for i, example in enumerate(tqdm(eval_dataset, desc=\"Extracting labels\")):\n",
        "        text = example['text']\n",
        "\n",
        "        # Extract true label from the alpaca format\n",
        "        # Look for \"### Response:\" followed by the category\n",
        "        if \"### Response:\" in text:\n",
        "            response_start = text.find(\"### Response:\") + len(\"### Response:\")\n",
        "            response_text = text[response_start:].strip()\n",
        "\n",
        "            # Handle different possible formats\n",
        "            if response_text:\n",
        "                # Remove any end tokens and get the first word\n",
        "                true_label = response_text.replace('<|end_of_text|>', '').strip().split()[0]\n",
        "                true_labels.append(true_label)\n",
        "            else:\n",
        "                true_labels.append(\"Unknown\")\n",
        "        else:\n",
        "            true_labels.append(\"Unknown\")\n",
        "\n",
        "    # Analyze the actual labels in your data\n",
        "    print(\"\\nüìä ANALYZING ACTUAL LABELS IN DATASET:\")\n",
        "    label_counts = Counter(true_labels)\n",
        "    print(\"Found labels:\", label_counts)\n",
        "\n",
        "    # Get the actual class names from your data\n",
        "    class_names = [label for label, count in label_counts.most_common() if label != \"Unknown\"]\n",
        "    print(f\"Using class names: {class_names}\")\n",
        "\n",
        "    # Reset for prediction pass\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    print(f\"\\nRunning predictions on {len(eval_dataset)} examples...\")\n",
        "\n",
        "    for i, example in enumerate(tqdm(eval_dataset, desc=\"Making predictions\")):\n",
        "        text = example['text']\n",
        "\n",
        "        # Extract true label (same as above)\n",
        "        if \"### Response:\" in text:\n",
        "            response_start = text.find(\"### Response:\") + len(\"### Response:\")\n",
        "            response_text = text[response_start:].strip()\n",
        "            if response_text:\n",
        "                true_label = response_text.replace('<|end_of_text|>', '').strip().split()[0]\n",
        "            else:\n",
        "                true_label = \"Unknown\"\n",
        "        else:\n",
        "            true_label = \"Unknown\"\n",
        "\n",
        "        # Extract instruction and input for prediction\n",
        "        try:\n",
        "            instruction_start = text.find(\"### Instruction:\") + len(\"### Instruction:\")\n",
        "            instruction_end = text.find(\"### Input:\")\n",
        "            instruction = text[instruction_start:instruction_end].strip()\n",
        "\n",
        "            input_start = text.find(\"### Input:\") + len(\"### Input:\")\n",
        "            input_end = text.find(\"### Response:\")\n",
        "            input_text = text[input_start:input_end].strip()\n",
        "\n",
        "            # Format for prediction (without the response)\n",
        "            prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input_text}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "            # Tokenize and predict\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=5,   # Only need a few tokens for the category\n",
        "                    temperature=0.01,   # Very low temperature for consistent predictions\n",
        "                    do_sample=False,    # Greedy decoding\n",
        "                    pad_token_id=tokenizer.eos_token_id,\n",
        "                    eos_token_id=tokenizer.eos_token_id,\n",
        "                )\n",
        "\n",
        "            # Decode prediction\n",
        "            response = tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n",
        "            predicted_label = response.strip().split()[0] if response.strip() else \"Unknown\"\n",
        "\n",
        "            # Clean up prediction (remove any special tokens)\n",
        "            predicted_label = predicted_label.replace('<|end_of_text|>', '').strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing example {i}: {e}\")\n",
        "            predicted_label = \"Unknown\"\n",
        "\n",
        "        predictions.append(predicted_label)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "        # Show progress and sample predictions\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"\\nProcessed {i + 1}/{len(eval_dataset)} examples\")\n",
        "            print(f\"Sample - True: {true_label}, Predicted: {predicted_label}\")\n",
        "\n",
        "    # Filter out Unknown labels for metrics calculation\n",
        "    valid_indices = [i for i, (true, pred) in enumerate(zip(true_labels, predictions))\n",
        "                    if true != \"Unknown\" and pred in class_names]\n",
        "\n",
        "    if not valid_indices:\n",
        "        print(\"‚ùå No valid predictions found!\")\n",
        "        return None\n",
        "\n",
        "    filtered_true = [true_labels[i] for i in valid_indices]\n",
        "    filtered_pred = [predictions[i] for i in valid_indices]\n",
        "\n",
        "    print(f\"\\nüìä PREDICTION ANALYSIS:\")\n",
        "    pred_counts = Counter(predictions)\n",
        "    print(\"Predicted label distribution:\", pred_counts)\n",
        "\n",
        "    print(f\"\\n‚úÖ Valid predictions: {len(valid_indices)}/{len(predictions)}\")\n",
        "\n",
        "    # Calculate metrics on filtered data\n",
        "    accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "\n",
        "    # Create classification report\n",
        "    try:\n",
        "        report = classification_report(\n",
        "            filtered_true,\n",
        "            filtered_pred,\n",
        "            target_names=class_names,\n",
        "            labels=class_names,\n",
        "            zero_division=0,\n",
        "            output_dict=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating classification report: {e}\")\n",
        "        # Fallback: use only labels that appear in both true and predicted\n",
        "        common_labels = list(set(filtered_true) & set(filtered_pred))\n",
        "        report = classification_report(\n",
        "            filtered_true,\n",
        "            filtered_pred,\n",
        "            target_names=common_labels,\n",
        "            labels=common_labels,\n",
        "            zero_division=0,\n",
        "            output_dict=True\n",
        "        )\n",
        "        class_names = common_labels\n",
        "\n",
        "    # Create confusion matrix\n",
        "    try:\n",
        "        cm = confusion_matrix(filtered_true, filtered_pred, labels=class_names)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating confusion matrix: {e}\")\n",
        "        common_labels = list(set(filtered_true) & set(filtered_pred))\n",
        "        cm = confusion_matrix(filtered_true, filtered_pred, labels=common_labels)\n",
        "        class_names = common_labels\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CLASSIFICATION EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Valid examples: {len(filtered_true)}\")\n",
        "    print(\"\\nPer-Class Metrics:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for class_name in class_names:\n",
        "        if class_name in report:\n",
        "            precision = report[class_name]['precision']\n",
        "            recall = report[class_name]['recall']\n",
        "            f1 = report[class_name]['f1-score']\n",
        "            support = report[class_name]['support']\n",
        "            print(f\"{class_name:12} | Precision: {precision:.3f} | Recall: {recall:.3f} | F1: {f1:.3f} | Support: {support}\")\n",
        "\n",
        "    if 'macro avg' in report:\n",
        "        print(f\"\\nMacro Average F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
        "    if 'weighted avg' in report:\n",
        "        print(f\"Weighted Average F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"-\" * 60)\n",
        "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "    print(cm_df)\n",
        "\n",
        "    # Show some example predictions\n",
        "    print(\"\\nSample Predictions:\")\n",
        "    print(\"-\" * 60)\n",
        "    sample_size = min(15, len(filtered_true))\n",
        "    for i in range(sample_size):\n",
        "        status = \"‚úì\" if filtered_pred[i] == filtered_true[i] else \"‚úó\"\n",
        "        print(f\"{status} True: {filtered_true[i]:12} | Predicted: {filtered_pred[i]:12}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'classification_report': report,\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': predictions,\n",
        "        'true_labels': true_labels,\n",
        "        'filtered_predictions': filtered_pred,\n",
        "        'filtered_true_labels': filtered_true,\n",
        "        'class_names': class_names\n",
        "    }\n",
        "\n",
        "# Run evaluation on a small sample first to debug\n",
        "print(\"üß™ DEBUGGING WITH SMALL SAMPLE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test with just 10 examples first\n",
        "small_sample = test_dataset.select(range(min(10, len(test_dataset))))\n",
        "debug_results = evaluate_classification_model(model, tokenizer, small_sample)\n",
        "\n",
        "if debug_results:\n",
        "    print(\"\\n‚úÖ Debug successful! Running full evaluation...\")\n",
        "\n",
        "    # Run full evaluation on TEST SET\n",
        "    print(\"\\nüéØ FINAL TEST SET EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Test set size: {len(test_dataset)}\")\n",
        "    print(\"This is the FINAL evaluation on completely unseen data\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    test_results = evaluate_classification_model(model, tokenizer, test_dataset)\n",
        "\n",
        "    if test_results:\n",
        "        print(f\"\\nüéâ EVALUATION COMPLETED!\")\n",
        "        print(f\"Final test accuracy: {test_results['accuracy']*100:.2f}%\")\n",
        "        print(f\"Categories found: {test_results['class_names']}\")\n",
        "        print(f\"Valid predictions: {len(test_results['filtered_true_labels'])}/{len(test_results['true_labels'])}\")\n",
        "    else:\n",
        "        print(\"‚ùå Evaluation failed!\")\n",
        "else:\n",
        "    print(\"‚ùå Debug failed - check your model and data format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877da65a-f07b-4b19-d07b-2b387e1041b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted category: Professional<|end_of_text|>\n",
            "Expected: Professional\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted category: Travel<|end_of_text|>\n",
            "Expected: Travel\n",
            "Predicted category: Health<|end_of_text|>\n",
            "Expected: Health\n"
          ]
        }
      ],
      "source": [
        "# Test Example 2: Professional/Career Post\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "    \"Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, and top comments.\", # instruction (removed subreddit reference)\n",
        "    \"\"\"Post Title: Should I negotiate salary for my first job out of college?\n",
        "\n",
        "Post Content: I just graduated with a computer science degree and got offered a position at a tech startup. The salary is $75k but I've heard people saying you should always negotiate. I'm worried about seeming ungrateful or them rescinding the offer. What's the best approach here?\n",
        "\n",
        "Top Comments:\n",
        "Comment 1: Always negotiate! Worst they can say is no, and most companies expect it\n",
        "Comment 2: Research salary ranges in your area first - use Glassdoor, LinkedIn, etc.\n",
        "Comment 3: Don't be afraid to ask - they already want to hire you\n",
        "Comment 4: I regret not negotiating my first offer, left money on the table\n",
        "Comment 5: Be professional about it and have data to back up your request\"\"\", # input\n",
        "    \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=5,        # Just need the category\n",
        "    temperature=0.1,         # Low temperature for consistent output\n",
        "    do_sample=False,         # Greedy decoding\n",
        "    use_cache=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "result = tokenizer.batch_decode(outputs)\n",
        "\n",
        "# Extract just the prediction\n",
        "prediction_start = result[0].find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
        "prediction = result[0][prediction_start:].strip().split()[0]\n",
        "print(f\"Predicted category: {prediction}\")\n",
        "print(f\"Expected: Professional\")\n",
        "\n",
        "# Test Example 3: Travel Post\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "    \"Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, and top comments.\",\n",
        "    \"\"\"Post Title: First time visiting Japan - need advice for 2-week itinerary\n",
        "\n",
        "Post Content: Planning my first trip to Japan in April during cherry blossom season. Want to see both Tokyo and Kyoto but not sure how to split my time. Also wondering about JR Pass vs individual tickets. Any must-see spots or hidden gems?\n",
        "\n",
        "Top Comments:\n",
        "Comment 1: Definitely get the JR Pass for 2 weeks, it pays for itself\n",
        "Comment 2: Tokyo 7 days, Kyoto 5 days, leave 2 days for day trips\n",
        "Comment 3: Don't miss Fushimi Inari shrine in Kyoto - amazing at sunrise\n",
        "Comment 4: Book accommodations early for cherry blossom season\n",
        "Comment 5: Try to stay in Shibuya or Shinjuku for easy access to everything\"\"\",\n",
        "    \"\",\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=5, temperature=0.1, do_sample=False, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "result = tokenizer.batch_decode(outputs)\n",
        "prediction_start = result[0].find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
        "prediction = result[0][prediction_start:].strip().split()[0]\n",
        "print(f\"Predicted category: {prediction}\")\n",
        "print(f\"Expected: Travel\")\n",
        "\n",
        "# Test Example 4: Health Post\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "    \"Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, and top comments.\",\n",
        "    \"\"\"Post Title: Struggling with anxiety - what helps you cope?\n",
        "\n",
        "Post Content: I've been dealing with increased anxiety lately, especially around work presentations. My heart races, I get sweaty palms, and sometimes feel like I can't breathe. Looking for healthy coping strategies that have worked for others. Already considering therapy but want to hear personal experiences.\n",
        "\n",
        "Top Comments:\n",
        "Comment 1: Deep breathing exercises really help me in the moment\n",
        "Comment 2: Regular exercise has been a game-changer for my anxiety\n",
        "Comment 3: Therapy is worth it - CBT techniques are super helpful\n",
        "Comment 4: Meditation apps like Headspace helped me a lot\n",
        "Comment 5: Talk to your doctor too, sometimes medication can help alongside therapy\"\"\",\n",
        "    \"\",\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=5, temperature=0.1, do_sample=False, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "result = tokenizer.batch_decode(outputs)\n",
        "prediction_start = result[0].find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
        "prediction = result[0][prediction_start:].strip().split()[0]\n",
        "print(f\"Predicted category: {prediction}\")\n",
        "print(f\"Expected: Health\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "dbcee8dbdbe54422963277e1b78d86da",
            "bf2b249aa82e40da975b6153f5f3f23a",
            "2a77f01d23574998ac210e21ba8df388",
            "bae62f091ce544aa8f9f7be0a59967a7",
            "8d3e3f83f9014f959c019858703c9e38",
            "da4f1e8a9e5d419487cdd6bfdf3c70bb",
            "ca1a1b483c524eca854ae0c33390fff7",
            "5ee84e744a704a548c4538e81da896c9",
            "0ce47c3cd3504810bf5db124085d18f0",
            "e0c22fd4bea64b4797b08c3758907497",
            "b285d087c8d04bf6be5a093bb6e205d2",
            "c0300509d0e047a0a5d3437cdf97cd98",
            "6e154f7ebe0045549b444e0bdc01b1fa",
            "57514a41f5de4dc7be06e6a4fd0e2a71",
            "b2e4338298b544afb162aeeace94b2cd",
            "2f17bc8ad13547ebbf569a69f6acb1bf",
            "8da346002fcf4fd8b659f80e5a24dc84",
            "0563e07ddfc34be8b51de7c43746d2b8",
            "9ce948c39b42456b81b18cbb9bdbb8dc",
            "2170758a798242aca7194b021c109159",
            "e9531e7b586c4f4ea2b0cccafb7c83a5",
            "6b002109ee704689a6ec14b78e216b57",
            "4188bdb8919841d59d3123274bea0a32",
            "09e2725c28784c1bb3f98e1d224f4be1",
            "30dbb2d51b8b4c748c082c760c00b42e",
            "d62d5a91216046668c9dfb003682b6df",
            "5170b74af8bd4ebaaad54417dd024564",
            "7594ebfd068947eabd898f9ce59fb646",
            "93cac383a4bf4cddb0ede06d471a705d",
            "3b0675d5c4e444aba81b24857fa05bbf",
            "09b8b01aa6cd4f55bf3b0e9829fb6182",
            "cf304c4b317346208ad1ef557e34db46",
            "694c3600f35a412daeb22c9d057b6db9",
            "8d387ddbed824b5caf1a45fb0568dd42",
            "eaa77a61e722400e9ea0db84ad6dda89",
            "28b975ab7b3e43d99fc1d4039e42e683",
            "1bf4c14f6e644284833e29e2d5fd6f7f",
            "dd89c81e7df74712ac3000e077889210",
            "2574eaca48f4467ca72ef42083ec45b6",
            "cb317a604bfc43c58f3ef2df9531236b",
            "fcdb2d6bea3f4ba2b020ec22b2007422",
            "0c909013333d407a8a9b9322dead0e72",
            "e266665bbe0f48f99aedb2038c458ee2",
            "3e2cc753686e4ab380a0c48ffd231f6a",
            "a43301c8aaab4c4ab26ddf69fcb1794e",
            "875c679a67134bf9bf58f35e1f067b84",
            "0dc8b45b5d09465e8e0c354fb8ddeae0",
            "7156e74422b9490fb8274aea43b71c44",
            "72fe7d98c3a043c7bae9c95d2f14365b",
            "ad3ee502964246189c1308f32437fb8f",
            "ea5e645809894c36b6b17f9d9c6f4079",
            "460046b3a9c24d79bb074196fe4462e1",
            "3ebdb1a3feae40ab8354d15aa55bb47c",
            "ed9e86b8810c4bc8a21bba4658435d66",
            "31af7e674dc64784853883b71c638efd"
          ]
        },
        "outputId": "75720f79-db8c-4a72-d658-985e11bcbcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Huggingface token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/607 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbcee8dbdbe54422963277e1b78d86da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0300509d0e047a0a5d3437cdf97cd98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/671M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4188bdb8919841d59d3123274bea0a32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/yaamin6236/reddit-post-classifier-v3.0\n",
            "‚úÖ Model uploaded successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d387ddbed824b5caf1a45fb0568dd42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a43301c8aaab4c4ab26ddf69fcb1794e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tokenizer uploaded successfully!\n",
            "üöÄ Your model is now available at: https://huggingface.co/yaamin6236/reddit-post-classifier-v2.0\n"
          ]
        }
      ],
      "source": [
        "# Get token input from user\n",
        "from getpass import getpass\n",
        "\n",
        "hf_token = getpass(\"Enter your Huggingface token: \")\n",
        "\n",
        "# Push model to hub\n",
        "model.push_to_hub(\"yaamin6236/reddit-post-classifier-v3.0\", token=hf_token)\n",
        "print(\"‚úÖ Model uploaded successfully!\")\n",
        "\n",
        "# Push tokenizer to hub\n",
        "tokenizer.push_to_hub(\"yaamin6236/reddit-post-classifier-v3.0\", token=hf_token)\n",
        "print(\"‚úÖ Tokenizer uploaded successfully!\")\n",
        "\n",
        "print(\"üöÄ Your model is now available at: https://huggingface.co/yaamin6236/reddit-post-classifier-v2.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "fd618f4d-2144-4392-dfdb-9e58cebcd02f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, top comments, and subreddit context.\n",
            "\n",
            "### Input:\n",
            "Post Title: My boss asked me to stop singing \"Wonderwall\"\n",
            "\n",
            "Post Content: I said maybe...\n",
            "\n",
            "Subreddit: r/Jokes\n",
            "\n",
            "Top Comments:\n",
            "Comment 1: I see what you did there! Classic Oasis reference!\n",
            "Comment 2: This joke is so bad it's good\n",
            "Comment 3: Take my upvote and get out\n",
            "\n",
            "### Response:\n",
            "Comedy\n",
            "\n",
            "### Explanation\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "   from unsloth import FastLanguageModel\n",
        "   model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "       model_name = \"yaamin6236/reddit-post-classifier-v1.0\", # YOUR PUSHED MODEL\n",
        "       max_seq_length = max_seq_length,\n",
        "       dtype = dtype,\n",
        "       load_in_4bit = load_in_4bit,\n",
        "   )\n",
        "   FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "   alpaca_prompt.format(\n",
        "       \"Classify the following Reddit post into one of these categories: Comedy, Education, Health, Professional, or Travel. Base your classification on the post title, content, top comments, and subreddit context.\", # instruction\n",
        "       \"\"\"Post Title: My boss asked me to stop singing \"Wonderwall\"\n",
        "\n",
        "Post Content: I said maybe...\n",
        "\n",
        "Subreddit: r/Jokes\n",
        "\n",
        "Top Comments:\n",
        "Comment 1: I see what you did there! Classic Oasis reference!\n",
        "Comment 2: This joke is so bad it's good\n",
        "Comment 3: Take my upvote and get out\"\"\", # input\n",
        "       \"\", # output - leave this blank for generation!\n",
        "   )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8E8LHcnIY0c"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "VdrRoOe6IY0Z",
        "mNaUdKK4IY0Z",
        "H_vF1wpWIY0Z",
        "vITh0KVJ10qX",
        "zu5vHY4pLtKa",
        "t7FObRqMLyMK",
        "UeT_FTNXenge",
        "2DUe5VgpRAV5",
        "idAEIeSQ3xdS",
        "ekOmTR1hSNcr",
        "uMuVrWbjAzhc",
        "f422JgM9sdVT",
        "TCv4vXHd61i7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf29d39d59a4430b8a3ad3de755d3832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8062b8d1476d4a39ab13b3009ecd6833",
              "IPY_MODEL_90acea9536ee42838c96baf01325c897",
              "IPY_MODEL_b77cd302f8a94c868552f7bba6b451a1"
            ],
            "layout": "IPY_MODEL_1aeb004472244f94b143c96479ae5ce1"
          }
        },
        "8062b8d1476d4a39ab13b3009ecd6833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d441c7dda3b24431bebe91a35e64f472",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49faf8d3c6e746149b34394ab04dee0f",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "90acea9536ee42838c96baf01325c897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7290d71f006a4d158b8bdb90f108a60f",
            "max": 5964186429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c838f802b2849d0806e6d246c10286a",
            "value": 5964185861
          }
        },
        "b77cd302f8a94c868552f7bba6b451a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a64c011d004602a404958cb851ff46",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bd6b5e7430cc4a3a98df5271c2b64214",
            "value": "‚Äá5.96G/5.96G‚Äá[00:14&lt;00:00,‚Äá781MB/s]"
          }
        },
        "1aeb004472244f94b143c96479ae5ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d441c7dda3b24431bebe91a35e64f472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49faf8d3c6e746149b34394ab04dee0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7290d71f006a4d158b8bdb90f108a60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c838f802b2849d0806e6d246c10286a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46a64c011d004602a404958cb851ff46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6b5e7430cc4a3a98df5271c2b64214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b63870f1384f8cbd0fd0d8efcb5c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94dace842a48465cab27b97fdb571464",
              "IPY_MODEL_dc28cd96454b4aab863ab1136d65d5a5",
              "IPY_MODEL_03fb9538965b4ce0988642387b7482cc"
            ],
            "layout": "IPY_MODEL_90833d29f5464d8a92ec643314adaa4f"
          }
        },
        "94dace842a48465cab27b97fdb571464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb24c391d82d404ab44c4c51d4e30f5e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_203ec114306f40168efd3ea7fe64db6e",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "dc28cd96454b4aab863ab1136d65d5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc9e643fef394678b2b27b710be02c77",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9fbdf519a814f19a6a9e4ecbbe8f53e",
            "value": 235
          }
        },
        "03fb9538965b4ce0988642387b7482cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1517dc939349e9bf1b584053dec892",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_13784d6215a44125b56cbf74e349267f",
            "value": "‚Äá235/235‚Äá[00:00&lt;00:00,‚Äá25.3kB/s]"
          }
        },
        "90833d29f5464d8a92ec643314adaa4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb24c391d82d404ab44c4c51d4e30f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203ec114306f40168efd3ea7fe64db6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc9e643fef394678b2b27b710be02c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fbdf519a814f19a6a9e4ecbbe8f53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a1517dc939349e9bf1b584053dec892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13784d6215a44125b56cbf74e349267f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "212eacf56b4c4deea80fa408f3d02fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f8f80e00e9b4e9ebcc3155db47894cf",
              "IPY_MODEL_51618322c6d64d6984e11332d089c73a",
              "IPY_MODEL_65a0f52c9b7a4ba49800cf3758cad2bb"
            ],
            "layout": "IPY_MODEL_347a88e9470e40d4b503d35e9b7a2376"
          }
        },
        "7f8f80e00e9b4e9ebcc3155db47894cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7f946133cd4e7b8180c84b036309d1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a26572a2dd5043c6a014bb79a0e6b016",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "51618322c6d64d6984e11332d089c73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb33ff925f924256a6c04987a1106e53",
            "max": 50642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d55c65d67a654960a2c74d172847e1f1",
            "value": 50642
          }
        },
        "65a0f52c9b7a4ba49800cf3758cad2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee8c56007ad489690cb8c4d2cf43520",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6194b58307b64760b800a0711d286ed1",
            "value": "‚Äá50.6k/50.6k‚Äá[00:00&lt;00:00,‚Äá5.79MB/s]"
          }
        },
        "347a88e9470e40d4b503d35e9b7a2376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7f946133cd4e7b8180c84b036309d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26572a2dd5043c6a014bb79a0e6b016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb33ff925f924256a6c04987a1106e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d55c65d67a654960a2c74d172847e1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dee8c56007ad489690cb8c4d2cf43520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6194b58307b64760b800a0711d286ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea467cdf1554a2e825e68fc0ae579ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6ec20ed70614a60a97ecafd954ac40f",
              "IPY_MODEL_d2295836be21437f9f69415b72cd6271",
              "IPY_MODEL_e67e56ed4a664e50b4ccb852bd82ebc0"
            ],
            "layout": "IPY_MODEL_310acca300534061bf84cd22bd553c30"
          }
        },
        "c6ec20ed70614a60a97ecafd954ac40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99c36f5026c9420dbd9f339a1b6bc408",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf6db4c854904b1dacf14d1905a119e7",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "d2295836be21437f9f69415b72cd6271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981b9d8d38574fcebba818614502b167",
            "max": 459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c149b4e05b145a6a81777e8d1e6b69e",
            "value": 459
          }
        },
        "e67e56ed4a664e50b4ccb852bd82ebc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa145cdea2b54a28ba904bce60e7169d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9ce0844500fd4bd5a9e0865c2d6ba1d4",
            "value": "‚Äá459/459‚Äá[00:00&lt;00:00,‚Äá62.6kB/s]"
          }
        },
        "310acca300534061bf84cd22bd553c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c36f5026c9420dbd9f339a1b6bc408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6db4c854904b1dacf14d1905a119e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981b9d8d38574fcebba818614502b167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c149b4e05b145a6a81777e8d1e6b69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa145cdea2b54a28ba904bce60e7169d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce0844500fd4bd5a9e0865c2d6ba1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df2685904b87490b95f28db3984a3402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c06e0affb3284acbad401609bf2e2592",
              "IPY_MODEL_9da6621d86054745af71b1244cbe7b20",
              "IPY_MODEL_336a29c71ffd4b7cac8138db2b9157cc"
            ],
            "layout": "IPY_MODEL_4213358bef594c5cbcabd6f9a14449eb"
          }
        },
        "c06e0affb3284acbad401609bf2e2592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421e64d5d9b9443e9cc8b05f15f59e83",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_124e8ef0aaa641e9b92fddd18877aba5",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "9da6621d86054745af71b1244cbe7b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf41923583b64a2094b23d433766a2d4",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f159bda1256a4731a39604c586291995",
            "value": 17209920
          }
        },
        "336a29c71ffd4b7cac8138db2b9157cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ba0f377b674b17aa3f2be183b73f57",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a3dee5403e04add8bbbee0e193a1570",
            "value": "‚Äá17.2M/17.2M‚Äá[00:00&lt;00:00,‚Äá57.9MB/s]"
          }
        },
        "4213358bef594c5cbcabd6f9a14449eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421e64d5d9b9443e9cc8b05f15f59e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124e8ef0aaa641e9b92fddd18877aba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf41923583b64a2094b23d433766a2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f159bda1256a4731a39604c586291995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51ba0f377b674b17aa3f2be183b73f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3dee5403e04add8bbbee0e193a1570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a73baa0529454c8a8b8de7e811652c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0260f08ad5417ebb64c81e95743696",
              "IPY_MODEL_5e3562c43d844961a04fa5890fdd8938",
              "IPY_MODEL_7c58d90bfeee48a6ba918dd14df1e123"
            ],
            "layout": "IPY_MODEL_45555874afaa45cfbe15a0e230360f9b"
          }
        },
        "fe0260f08ad5417ebb64c81e95743696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da13980d4c0c4cba8ae8ab2176b97560",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42f68c6958d7458caa6e5c8994acdb43",
            "value": "Map:‚Äá100%"
          }
        },
        "5e3562c43d844961a04fa5890fdd8938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8f9a9b8da3464da81115a0ddff785b",
            "max": 24804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2f39b3ee1204b359ed46f7cb2c0b296",
            "value": 24804
          }
        },
        "7c58d90bfeee48a6ba918dd14df1e123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc5ac0342e9499eac166999885519cc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3d136251fac4baaab88c6c3a202128a",
            "value": "‚Äá24804/24804‚Äá[00:00&lt;00:00,‚Äá41144.74‚Äáexamples/s]"
          }
        },
        "45555874afaa45cfbe15a0e230360f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da13980d4c0c4cba8ae8ab2176b97560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f68c6958d7458caa6e5c8994acdb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8f9a9b8da3464da81115a0ddff785b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f39b3ee1204b359ed46f7cb2c0b296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdc5ac0342e9499eac166999885519cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d136251fac4baaab88c6c3a202128a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de09f4e2e203485a9df7a40579f4f7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5acdb8868d77498682e47455592374f3",
              "IPY_MODEL_7d2956212c864e68a4eae8089d560fc8",
              "IPY_MODEL_13b77ac9ea0846ac9b25d59e489bed9d"
            ],
            "layout": "IPY_MODEL_29b04953d17a4f40b9b694121b30d2de"
          }
        },
        "5acdb8868d77498682e47455592374f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538939042e254262a40e23c694613546",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0f1faa3b2bb249cface6c0074caf4baf",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]:‚Äá100%"
          }
        },
        "7d2956212c864e68a4eae8089d560fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b59c63d4b6744969bd73a4a14278806",
            "max": 19843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1613d0df04844bf6bf8212e9dba9f76c",
            "value": 19843
          }
        },
        "13b77ac9ea0846ac9b25d59e489bed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efa92f60256a45c8959be371a94b27d7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_282658b7f9d94d649671e84c7560396f",
            "value": "‚Äá19843/19843‚Äá[00:07&lt;00:00,‚Äá2764.62‚Äáexamples/s]"
          }
        },
        "29b04953d17a4f40b9b694121b30d2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538939042e254262a40e23c694613546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1faa3b2bb249cface6c0074caf4baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b59c63d4b6744969bd73a4a14278806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1613d0df04844bf6bf8212e9dba9f76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efa92f60256a45c8959be371a94b27d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282658b7f9d94d649671e84c7560396f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d65b26996bb4516a4bbe7f85963889a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1439359f5e64bfb869574109173aa3f",
              "IPY_MODEL_cac4872dd1794ed89c9bcbef29f4269c",
              "IPY_MODEL_e89e15874b71486cb0c3df6f2cedc080"
            ],
            "layout": "IPY_MODEL_ab9b9a2a33664173a68f2347a80ec277"
          }
        },
        "e1439359f5e64bfb869574109173aa3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf3148cff6c461f8193cf727904ee3c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e6bf85541ea428594b9efc395ea2038",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]:‚Äá100%"
          }
        },
        "cac4872dd1794ed89c9bcbef29f4269c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e096814ff9d4907ae4fde7cf2f321bc",
            "max": 2480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6852da25691f4d97b90ac06de29b4d00",
            "value": 2480
          }
        },
        "e89e15874b71486cb0c3df6f2cedc080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b88d8eeb274382ac2cbc8a9b61d3d6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f23921ab27be4ae897a8621fa85f0639",
            "value": "‚Äá2480/2480‚Äá[00:00&lt;00:00,‚Äá2894.83‚Äáexamples/s]"
          }
        },
        "ab9b9a2a33664173a68f2347a80ec277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf3148cff6c461f8193cf727904ee3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6bf85541ea428594b9efc395ea2038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e096814ff9d4907ae4fde7cf2f321bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6852da25691f4d97b90ac06de29b4d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5b88d8eeb274382ac2cbc8a9b61d3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23921ab27be4ae897a8621fa85f0639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbcee8dbdbe54422963277e1b78d86da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf2b249aa82e40da975b6153f5f3f23a",
              "IPY_MODEL_2a77f01d23574998ac210e21ba8df388",
              "IPY_MODEL_bae62f091ce544aa8f9f7be0a59967a7"
            ],
            "layout": "IPY_MODEL_8d3e3f83f9014f959c019858703c9e38"
          }
        },
        "bf2b249aa82e40da975b6153f5f3f23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4f1e8a9e5d419487cdd6bfdf3c70bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ca1a1b483c524eca854ae0c33390fff7",
            "value": "README.md:‚Äá100%"
          }
        },
        "2a77f01d23574998ac210e21ba8df388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee84e744a704a548c4538e81da896c9",
            "max": 607,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ce47c3cd3504810bf5db124085d18f0",
            "value": 607
          }
        },
        "bae62f091ce544aa8f9f7be0a59967a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c22fd4bea64b4797b08c3758907497",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b285d087c8d04bf6be5a093bb6e205d2",
            "value": "‚Äá607/607‚Äá[00:00&lt;00:00,‚Äá65.9kB/s]"
          }
        },
        "8d3e3f83f9014f959c019858703c9e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da4f1e8a9e5d419487cdd6bfdf3c70bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1a1b483c524eca854ae0c33390fff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee84e744a704a548c4538e81da896c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce47c3cd3504810bf5db124085d18f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0c22fd4bea64b4797b08c3758907497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b285d087c8d04bf6be5a093bb6e205d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0300509d0e047a0a5d3437cdf97cd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e154f7ebe0045549b444e0bdc01b1fa",
              "IPY_MODEL_57514a41f5de4dc7be06e6a4fd0e2a71",
              "IPY_MODEL_b2e4338298b544afb162aeeace94b2cd"
            ],
            "layout": "IPY_MODEL_2f17bc8ad13547ebbf569a69f6acb1bf"
          }
        },
        "6e154f7ebe0045549b444e0bdc01b1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8da346002fcf4fd8b659f80e5a24dc84",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0563e07ddfc34be8b51de7c43746d2b8",
            "value": "100%"
          }
        },
        "57514a41f5de4dc7be06e6a4fd0e2a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce948c39b42456b81b18cbb9bdbb8dc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2170758a798242aca7194b021c109159",
            "value": 1
          }
        },
        "b2e4338298b544afb162aeeace94b2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9531e7b586c4f4ea2b0cccafb7c83a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b002109ee704689a6ec14b78e216b57",
            "value": "‚Äá1/1‚Äá[00:06&lt;00:00,‚Äá‚Äá6.19s/it]"
          }
        },
        "2f17bc8ad13547ebbf569a69f6acb1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da346002fcf4fd8b659f80e5a24dc84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0563e07ddfc34be8b51de7c43746d2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ce948c39b42456b81b18cbb9bdbb8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2170758a798242aca7194b021c109159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9531e7b586c4f4ea2b0cccafb7c83a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b002109ee704689a6ec14b78e216b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4188bdb8919841d59d3123274bea0a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09e2725c28784c1bb3f98e1d224f4be1",
              "IPY_MODEL_30dbb2d51b8b4c748c082c760c00b42e",
              "IPY_MODEL_d62d5a91216046668c9dfb003682b6df"
            ],
            "layout": "IPY_MODEL_5170b74af8bd4ebaaad54417dd024564"
          }
        },
        "09e2725c28784c1bb3f98e1d224f4be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7594ebfd068947eabd898f9ce59fb646",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_93cac383a4bf4cddb0ede06d471a705d",
            "value": "adapter_model.safetensors:‚Äá"
          }
        },
        "30dbb2d51b8b4c748c082c760c00b42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0675d5c4e444aba81b24857fa05bbf",
            "max": 671149168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09b8b01aa6cd4f55bf3b0e9829fb6182",
            "value": 671149168
          }
        },
        "d62d5a91216046668c9dfb003682b6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf304c4b317346208ad1ef557e34db46",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_694c3600f35a412daeb22c9d057b6db9",
            "value": "‚Äá672M/?‚Äá[00:05&lt;00:00,‚Äá455MB/s]"
          }
        },
        "5170b74af8bd4ebaaad54417dd024564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7594ebfd068947eabd898f9ce59fb646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cac383a4bf4cddb0ede06d471a705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0675d5c4e444aba81b24857fa05bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b8b01aa6cd4f55bf3b0e9829fb6182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf304c4b317346208ad1ef557e34db46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694c3600f35a412daeb22c9d057b6db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d387ddbed824b5caf1a45fb0568dd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa77a61e722400e9ea0db84ad6dda89",
              "IPY_MODEL_28b975ab7b3e43d99fc1d4039e42e683",
              "IPY_MODEL_1bf4c14f6e644284833e29e2d5fd6f7f"
            ],
            "layout": "IPY_MODEL_dd89c81e7df74712ac3000e077889210"
          }
        },
        "eaa77a61e722400e9ea0db84ad6dda89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2574eaca48f4467ca72ef42083ec45b6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cb317a604bfc43c58f3ef2df9531236b",
            "value": "100%"
          }
        },
        "28b975ab7b3e43d99fc1d4039e42e683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcdb2d6bea3f4ba2b020ec22b2007422",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c909013333d407a8a9b9322dead0e72",
            "value": 1
          }
        },
        "1bf4c14f6e644284833e29e2d5fd6f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e266665bbe0f48f99aedb2038c458ee2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3e2cc753686e4ab380a0c48ffd231f6a",
            "value": "‚Äá1/1‚Äá[00:01&lt;00:00,‚Äá‚Äá1.53s/it]"
          }
        },
        "dd89c81e7df74712ac3000e077889210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2574eaca48f4467ca72ef42083ec45b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb317a604bfc43c58f3ef2df9531236b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcdb2d6bea3f4ba2b020ec22b2007422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c909013333d407a8a9b9322dead0e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e266665bbe0f48f99aedb2038c458ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2cc753686e4ab380a0c48ffd231f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a43301c8aaab4c4ab26ddf69fcb1794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_875c679a67134bf9bf58f35e1f067b84",
              "IPY_MODEL_0dc8b45b5d09465e8e0c354fb8ddeae0",
              "IPY_MODEL_7156e74422b9490fb8274aea43b71c44"
            ],
            "layout": "IPY_MODEL_72fe7d98c3a043c7bae9c95d2f14365b"
          }
        },
        "875c679a67134bf9bf58f35e1f067b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad3ee502964246189c1308f32437fb8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ea5e645809894c36b6b17f9d9c6f4079",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "0dc8b45b5d09465e8e0c354fb8ddeae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460046b3a9c24d79bb074196fe4462e1",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ebdb1a3feae40ab8354d15aa55bb47c",
            "value": 17209920
          }
        },
        "7156e74422b9490fb8274aea43b71c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9e86b8810c4bc8a21bba4658435d66",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_31af7e674dc64784853883b71c638efd",
            "value": "‚Äá32.0M/?‚Äá[00:01&lt;00:00,‚Äá23.8MB/s]"
          }
        },
        "72fe7d98c3a043c7bae9c95d2f14365b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3ee502964246189c1308f32437fb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5e645809894c36b6b17f9d9c6f4079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "460046b3a9c24d79bb074196fe4462e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ebdb1a3feae40ab8354d15aa55bb47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9e86b8810c4bc8a21bba4658435d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31af7e674dc64784853883b71c638efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}